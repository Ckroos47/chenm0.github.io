<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cm940324.github.io</id>
    <title>Oasis</title>
    <updated>2021-07-20T07:35:41.205Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cm940324.github.io"/>
    <link rel="self" href="https://cm940324.github.io/atom.xml"/>
    <subtitle>&lt;a href=&quot;https://cm940324.github.io/&quot; target=&quot;_blank&quot;&gt;code blog&lt;/a&gt;</subtitle>
    <logo>https://cm940324.github.io/images/avatar.png</logo>
    <icon>https://cm940324.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Oasis</rights>
    <entry>
        <title type="html"><![CDATA[@Excel参数大全]]></title>
        <id>https://cm940324.github.io/post/excel-args/</id>
        <link href="https://cm940324.github.io/post/excel-args/">
        </link>
        <updated>2021-07-19T09:05:37.000Z</updated>
        <content type="html"><![CDATA[<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>sort</td>
<td>int</td>
<td>Integer.MAX_VALUE</td>
<td>导出时在excel中排序</td>
</tr>
<tr>
<td>name</td>
<td>String</td>
<td>空</td>
<td>导出到Excel中的名字</td>
</tr>
<tr>
<td>dateFormat</td>
<td>String</td>
<td>空</td>
<td>日期格式, 如: yyyy-MM-dd</td>
</tr>
<tr>
<td>dictType</td>
<td>String</td>
<td>空</td>
<td>如果是字典类型，请设置字典的type值 (如: sys_user_sex)</td>
</tr>
<tr>
<td>readConverterExp</td>
<td>String</td>
<td>空</td>
<td>读取内容转表达式 (如: 0=男,1=女,2=未知)</td>
</tr>
<tr>
<td>separator</td>
<td>String</td>
<td>,</td>
<td>分隔符，读取字符串组内容</td>
</tr>
<tr>
<td>scale</td>
<td>int</td>
<td>-1</td>
<td>BigDecimal 精度 默认:-1(默认不开启BigDecimal格式化)</td>
</tr>
<tr>
<td>roundingMode</td>
<td>int</td>
<td>BigDecimal.ROUND_HALF_EVEN</td>
<td>BigDecimal 舍入规则 默认:BigDecimal.ROUND_HALF_EVEN</td>
</tr>
<tr>
<td>columnType</td>
<td>Enum</td>
<td>Type.STRING</td>
<td>导出类型（0数字 1字符串 2图片）</td>
</tr>
<tr>
<td>height</td>
<td>String</td>
<td>14</td>
<td>导出时在excel中每个列的高度 单位为字符</td>
</tr>
<tr>
<td>width</td>
<td>String</td>
<td>16</td>
<td>导出时在excel中每个列的宽 单位为字符</td>
</tr>
<tr>
<td>suffix</td>
<td>String</td>
<td>空</td>
<td>文字后缀,如% 90 变成90%</td>
</tr>
<tr>
<td>defaultValue</td>
<td>String</td>
<td>空</td>
<td>当值为空时,字段的默认值</td>
</tr>
<tr>
<td>prompt</td>
<td>String</td>
<td>空</td>
<td>提示信息</td>
</tr>
<tr>
<td>combo</td>
<td>String</td>
<td>Null</td>
<td>设置只能选择不能输入的列内容</td>
</tr>
<tr>
<td>targetAttr</td>
<td>String</td>
<td>空</td>
<td>另一个类中的属性名称,支持多级获取,以小数点隔开</td>
</tr>
<tr>
<td>isStatistics</td>
<td>boolean</td>
<td>false</td>
<td>是否自动统计数据,在最后追加一行统计数据总和</td>
</tr>
<tr>
<td>type</td>
<td>Enum</td>
<td>Type.ALL</td>
<td>字段类型（0：导出导入；1：仅导出；2：仅导入）</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JPA踩坑记录]]></title>
        <id>https://cm940324.github.io/post/jpa-qa/</id>
        <link href="https://cm940324.github.io/post/jpa-qa/">
        </link>
        <updated>2021-06-24T06:08:55.000Z</updated>
        <content type="html"><![CDATA[<h3 id="spring-data-jpa查询到的对象被set值后自动更新数据库">Spring data JPA查询到的对象被set值后，自动更新数据库</h3>
<p>做项目开发的时候遇到这样一个问题：数据库有临时表和正式表，数据审批通过后才会进入正式表，根据业务要求，页面的数据需要通过临时表对象来显示，当需要显示正式表数据时，先查询到临时表对象，再查询正式表对象，将正式表对象赋值给临时表对象用于页面显示，代码执行完毕后，发现数据库正式表数据覆盖了临时表数据，很纳闷，查看代码，在把正式表数据赋值给临时表对象后，并没有保存临时表对象的代码呀，数据库怎么会被更新？<br>
后来查看日志发现，当将正式表数据赋值给临时表时，有一条update语句执行了。查看资料后才知道，使用JPA查询后的对象处于持久态，持久态的对象属性在被set后，会自动执行update语句更新数据库。<br>
这才恍然大悟，基于这个原因，只要把持久态的对象转换为游离态或者是临时态，就可以解决问题。<br>
先理解下Hibernate 中对象的三种状态：<br>
(1)临时状态：通过new新建的对象，没有被持久化，也不在session缓存中<br>
(2)游离状态：已经被持久化，但不在session缓存中<br>
(3)持久状态：已经被持久化，也在session缓存中<br>
(持久化：数据库有这条数据)<br>
持久态到游离态的方法有：session.close()、session.evict(obj)、session.clear()<br>
close()：关闭session，整个session中的持久态对象都成为游离态<br>
clear()：清楚session中的所有缓存，所有持久化对象变为游离态<br>
evict(obj)：把某个持久化状态的对象从session中清除，该对象变为游离态</p>
<p>根据三个方法的介绍，最好的处理方式应该选择evict(obj)方法。</p>
<p>由于业务需求，我的解决方式是，新建一个临时态的临时表对象，将查询到的正式表对象赋值给临时态对象，这样就不会触发update语句，经测试，问题解决。</p>
<p>`	@PersistenceContext<br>
private EntityManager entityManager;</p>
<pre><code>Session session = entityManager.unwrap(Session.class);`</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springboot2的配置文件properties和yml的一些常用属性]]></title>
        <id>https://cm940324.github.io/post/springboot2-yml/</id>
        <link href="https://cm940324.github.io/post/springboot2-yml/">
        </link>
        <updated>2021-06-17T08:13:43.000Z</updated>
        <content type="html"><![CDATA[<p>＃================================================= ==================<br>
＃COMMON SPRING BOOT PROPERTIES</p>
<h2 id=""></h2>
<p>此样本文件作为指南提供。不要将它的#complete复制<br>
到您自己的应用程序中。^^^<br>
＃============================================== =====================</p>
<p>＃----------------------------------------<br>
#CORE PROPERTIES<br>
＃----- -----------------------------------<br>
debug = false ＃启用调试日志。<br>
trace = false ＃启用跟踪日志。</p>
<p>#logGING<br>
logging.config = ＃日志配置文件的位置。例如，Logback的<code>classpath：logback.xml</code>。<br>
logging.exception-conversion-word =％wEx ＃记录异常时使用的转换字。<br>
logging.file = ＃日志文件名（例如，<code>myapp.log</code>）。名称可以是精确位置或相对于当前目录。<br>
logging.file.max-history = 0 ＃要保留的归档日志文件的最大值。仅支持默认的logback设置。<br>
logging.file.max-size = 10MB ＃最大日志文件大小。仅支持默认的logback设置。<br>
logging.group。* =＃记录组以同时快速更改多个记录器。例如，<code>logging.level.db = org.hibernate，org.springframework.jdbc</code>。<br>
logging.level。* = ＃日志级别严重性映射。例如，<code>logging.level.org.springframework = DEBUG</code>。<br>
logging.path = ＃日志文件的位置。例如，<code>/ var / log</code>。<br>
logging.pattern.console = ＃用于输出到控制台的Appender模式。仅支持默认的Logback设置。<br>
logging.pattern.dateformat = yyyy-MM-dd HH：mm：ss.SSS ＃日志日期格式的Appender模式。仅支持默认的Logback设置。<br>
logging.pattern.file =＃用于输出到文件的Appender模式。仅支持默认的Logback设置。<br>
logging.pattern.level =％5p ＃日志级别的Appender模式。仅支持默认的Logback设置。<br>
logging.register-shutdown-hook = false ＃在日志记录系统初始化时注册一个关闭钩子。</p>
<p>＃AOP<br>
spring.aop.auto =真＃添加@EnableAspectJAutoProxy。<br>
spring.aop.proxy-target-class = true ＃是否要创建基于子类的（CGLIB）代理（true），而不是基于标准Java接口的代理（false）。</p>
<p>#IDENTITY （ContextIdApplicationContextInitializer）<br>
spring.application.name = #Application name。</p>
<p>#DINAND （SpringApplicationAdminJmxAutoConfiguration）<br>
spring.application.admin.enabled = false ＃是否为应用程序启用管理功能。<br>
spring.application.admin.jmx-name = org.springframework.boot：type = Admin，name = SpringApplication #JMX 应用程序管理员MBean的名称。</p>
<p>#AUTO-CONFIGURATION<br>
spring.autoconfigure.exclude = ＃要排除的自动配置类。</p>
<p>＃BANNER<br>
spring.banner.charset = UTF-8 ＃横幅文件编码。<br>
spring.banner.location = classpath：banner.txt ＃横幅文本资源位置。<br>
spring.banner.image.location = classpath：banner.gif ＃横幅图像文件位置（也可以使用jpg或png）。<br>
spring.banner.image.width = 76 ＃字符中的横幅图像的宽度。<br>
spring.banner.image.height = #crs 中横幅图像的高度（默认基于图像高度）。<br>
spring.banner.image.margin = 2 ＃字符中的左手图像边距。<br>
spring.banner.image.invert = false ＃是否应针对暗终端主题反转图像。</p>
<p>#SPRING CORE spring.beaninfo.ignore = true ＃是否跳过BeanInfo类的搜索。</p>
<p>#SPRING CACHE（CacheProperties）<br>
spring.cache.cache-names = #Cmama 分隔的要创建的缓存名称列表（如果底层缓存管理器支持）。<br>
spring.cache.caffeine.spec = ＃用于创建缓存的规范。有关规格格式的更多详细信息，请参阅CaffeineSpec。<br>
spring.cache.couchbase.expiration = ＃条目到期。默认情况下，条目永不过期。请注意，此值最终会转换为秒。<br>
spring.cache.ehcache.config = ＃用于初始化EhCache的配置文件的位置。<br>
spring.cache.infinispan.config = ＃用于初始化Infinispan的配置文件的位置。<br>
spring.cache.jcache.config = ＃用于初始化缓存管理器的配置文件的位置。<br>
spring.cache.jcache.provider = #CachingProvider实现的完全限定名称，用于检索符合JSR-107的缓存管理器。仅当类路径上有多个JSR-107实现时才需要。<br>
spring.cache.redis.cache-null-values = true ＃允许缓存空值。<br>
spring.cache.redis.key-prefix = ＃键前缀。<br>
spring.cache.redis.time-to-live = ＃条目到期。默认情况下，条目永不过期。<br>
spring.cache.redis.use-key-prefix = true＃写入Redis时是否使用密钥前缀。<br>
spring.cache.type = #Cache 类型。默认情况下，根据环境自动检测。</p>
<p>#SPRING CONFIG  - 仅使用环境属性（ConfigFileApplicationListener）<br>
spring.config.additional-location = ＃配置除默认值之外使用的文件位置。<br>
spring.config.location = ＃配置替换默认值的文件位置。<br>
spring.config.name = application ＃配置文件名。</p>
<p>#HAZELCAST（HazelcastProperties）<br>
spring.hazelcast.config = ＃用于初始化Hazelcast的配置文件的位置。</p>
<p>#PROJECT INFORMATION（ProjectInfoProperties）<br>
spring.info.build.encoding = UTF-8 ＃文件编码。<br>
spring.info.build.location = classpath：META-INF / build-info.properties ＃生成的build-info.properties文件的位置。<br>
spring.info.git.encoding = UTF-8 ＃文件编码。<br>
spring.info.git.location =类路径：git.properties 生成的git.properties文件＃所在。</p>
<p>＃JMX<br>
spring.jmx.default域 = ＃JMX域名。<br>
spring.jmx.enabled = true ＃将管理bean公开给JMX域。<br>
spring.jmx.server = mbeanServer ＃MBeanServer bean name。<br>
spring.jmx.unique-names = false ＃是否应确保唯一的运行时对象名称。</p>
<p>#Email （MailProperties）<br>
spring.mail.default-encoding = UTF-8 ＃默认MimeMessage编码。<br>
spring.mail.host = #SMTP 服务器主机。例如，<code>smtp.example.com</code>。<br>
spring.mail.jndi-name = ＃会话JNDI名称。设置时，优先于其他会话设置。<br>
spring.mail.password = #SMTP 服务器的登录密码。<br>
spring.mail.port = #SMTP 服务器端口。<br>
spring.mail.properties。* = ＃其他JavaMail会话属性。<br>
spring.mail.protocol = smtp ＃SMTP服务器使用的协议。<br>
spring.mail.test-connection = false＃是否在启动时测试邮件服务器是否可用。<br>
spring.mail.username = #SMTP 服务器的登录用户。</p>
<p>#APICING SETTINGS（SpringApplication）<br>
spring.main.allow-bean-definition-overriding = false ＃是否允许通过注册与现有定义同名的定义来覆盖bean定义。<br>
spring.main.banner-mode = console ＃模式用于在应用程序运行时显示横幅。<br>
spring.main.sources = 要包含在ApplicationContext中的<br>
#Sources （类名，包名或XML资源位置）。spring.main.web-application-type = ＃用于显式请求特定类型的Web应用程序的标志。如果未设置，则基于类路径自动检测。</p>
<p>#FILE ENCODING（FileEncodingApplicationListener）<br>
spring.mandatory-file-encoding = ＃应用程序必须使用的预期字符编码。</p>
<p>#INTERINGIZATION （MessageSourceProperties）<br>
spring.messages.always-use-message-format = false ＃是否始终应用MessageFormat规则，甚至解析不带参数的消息。<br>
spring.messages.basename = messages ＃逗号分隔的basenames列表（本质上是一个完全限定的类路径位置），每个都遵循ResourceBundle约定，轻松支持基于斜杠的位置。<br>
spring.messages.cache-duration = ＃加载的资源包文件缓存持续时间。未设置时，捆绑包将永久缓存。如果未指定持续时间后缀，则将使用秒。<br>
spring.messages.encoding = UTF-8 ＃消息包编码。<br>
spring.messages.fallback-to-system-locale = true ＃如果找不到特定区域设置的文件，是否回退到系统区域设置。<br>
spring.messages.use-code-as-default-message = false ＃是否使用消息代码作为默认消息而不是抛出“NoSuchMessageException”。仅在开发期间推荐。</p>
<p>＃OUTPUT<br>
spring.output.ansi.enabled =检测＃配置的ANSI输出。</p>
<p>#PID FILE（ApplicationPidFileWriter）<br>
spring.pid.fail-on-write-error = ＃如果使用ApplicationPidFileWriter但它无法写入PID文件，则失败。<br>
spring.pid.file = ＃要写入的PID文件的位置（如果使用ApplicationPidFileWriter）。</p>
<p>＃PROFILES<br>
spring.profiles.active = ＃逗号分隔的有源配置文件列表。可以通过命令行开关覆盖。<br>
spring.profiles.include = ＃无条件地激活指定的逗号分隔的配置文件列表（如果使用YAML，则激活配置文件列表）。</p>
<p>＃Quartz调度器（QuartzProperties）<br>
spring.quartz.auto-启动 =真＃是否自动启动初始化后的调度。<br>
spring.quartz.jdbc.comment-prefix =  - #SQL 初始化脚本中单行注释的前缀。<br>
spring.quartz.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.quartz.jdbc.schema = classpath：org / quartz / impl / jdbcjobstore / tables_ @ @ platform @@ .sql ＃用于初始化数据库模式的SQL文件的路径。<br>
spring.quartz.job-store-type = memory ＃Quartz作业存储类型。<br>
spring.quartz.overwrite-existing-jobs = false ＃配置的作业是否应覆盖现有的作业定义。<br>
spring.quartz.properties。* = ＃其他Quartz Scheduler属性。<br>
spring.quartz.scheduler-name = quartzScheduler ＃调度程序的名称。<br>
spring.quartz.startup-delay = 0s ＃一旦初始化完成，调度程序启动之后的延迟。<br>
spring.quartz.wait-for-jobs-to-complete-on-shutdown = false ＃是否等待在关闭时运行的作业完成。</p>
<p>#REACTOR （ReactorCoreProperties）<br>
spring.reactor.stacktrace -mode.enabled = false #Reactor 是否应该在运行时收集堆栈跟踪信息。</p>
<p>#SENDGRID（SendGridAutoConfiguration）<br>
spring.sendgrid.api-key = ＃SendGrid API密钥。<br>
spring.sendgrid.proxy.host = ＃SendGrid代理主机。<br>
spring.sendgrid.proxy.port = ＃SendGrid代理端口。</p>
<p>#TASK EXECUTION（TaskExecutionProperties）<br>
spring.task.execution.pool.allow-core-thread-timeout = true ＃是否允许核心线程超时。这可以实现池的动态增长和收缩。<br>
spring.task.execution.pool.core-size = 8 ＃核心线程数。<br>
spring.task.execution.pool.keep-alive = 60s ＃终止之前线程可能保持空闲的时间限制。<br>
spring.task.execution.pool.max-size = ＃允许的最大线程数。如果任务正在填满队列，则池可以扩展到该大小以适应负载。如果队列无限制，则忽略。<br>
spring.task.execution.pool.queue-capacity =＃队列容量。无限制的容量不会增加池，因此会忽略“max-size”属性。<br>
spring.task.execution.thread-name-prefix = task- ＃用于新创建的线程名称的前缀。</p>
<p>#TASK SCHEDULING（TaskSchedulingProperties）<br>
spring.task.scheduling.pool.size = 1 ＃允许的最大线程数。<br>
spring.task.scheduling.thread-name-prefix = scheduling- ＃用于新创建的线程名称的前缀。</p>
<p>＃----------------------------------------<br>
＃WEB PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#EmbEDDED SERVER CONFIGURATION（ServerProperties）<br>
server.address = ＃服务器应绑定到的网络地址。<br>
server.compression.enabled = false ＃是否启用了响应压缩。<br>
server.compression.excluded-user-agents = ＃逗号分隔的用户代理列表，不应压缩响应。<br>
server.compression.mime-types = text / html，text / xml，text / plain，text / css，text / javascript，application / javascript，application / json，application / xml ＃逗号分隔的MIME类型列表应该是压缩。<br>
server.compression.min-response-size = 2KB＃执行压缩所需的最小“Content-Length”值。<br>
server.connection-timeout = ＃连接器在关闭连接之前等待另一个HTTP请求的时间。未设置时，将使用连接器的特定于容器的默认值。使用值-1表示没有（即无限）超时。<br>
server.error.include-exception = false ＃包含“exception”属性。<br>
server.error.include-stacktrace = never ＃何时包含“stacktrace”属性。<br>
server.error.path = / error ＃错误控制器的路径。<br>
server.error.whitelabel.enabled = true＃是否在服务器出错时启用浏览器中显示的默认错误页面。<br>
server.http2.enabled = false ＃是否启用HTTP / 2支持，如果当前环境支持它。<br>
server.jetty.acceptors = -1 ＃要使用的接受者线程数。当值为-1（默认值）时，接受器的数量是从操作环境派生的。<br>
server.jetty.accesslog.append = false ＃追加到日志。<br>
server.jetty.accesslog.date-format = dd / MMM / yyyy：HH：mm：ss Z ＃请求日志的时间戳格式。<br>
server.jetty.accesslog.enabled = false ＃启用访问日志。<br>
server.jetty.accesslog.extended-format = false＃启用扩展NCSA格式。<br>
server.jetty.accesslog.file-date-format = ＃日期文件名中的日期格式。<br>
server.jetty.accesslog.filename = ＃日志文件名。如果未指定，则日志重定向到“System.err”。<br>
server.jetty.accesslog.locale = ＃请求日志的区域设置。<br>
server.jetty.accesslog.log-cookies = false ＃启用请求cookie的记录。<br>
server.jetty.accesslog.log-latency = false ＃启用请求处理时间的记录。<br>
server.jetty.accesslog.log-server = false ＃启用请求主机名的日志记录。<br>
server.jetty.accesslog.retention-period = 31＃删除旋转日志文件之前的天数。<br>
server.jetty.accesslog.time-zone = GMT ＃请求日志的时区。<br>
server.jetty.max-http-post-size = 200000B #HTTP post或put内容的最大大小。<br>
server.jetty.selectors = -1 ＃要使用的选择器线程数。当值为-1（默认值）时，选择器的数量是从操作环境派生的。<br>
server.max-http-header-size = 8KB #HTTP 邮件头的最大大小。<br>
server.port = 8080 ＃服务器HTTP端口。<br>
server.server-header = ＃用于Server响应头的值（如果为空，则不发送头）。<br>
server.use-forward-headers = ＃是否应将X-Forwarded- <em>标头应用于HttpRequest。<br>
server.servlet.context-parameters。</em> = ＃Servlet context init参数。<br>
server.servlet.context-path = ＃应用程序的上下文路径。<br>
server.servlet.application-display-name = application ＃显示<br>
应用程序的名称。server.servlet.jsp.class-name = org.apache.jasper.servlet.JspServlet ＃用于JSP的servlet的类名。<br>
server.servlet.jsp.init-parameters。* = ＃用于配置JSP servlet的Init参数。<br>
server.servlet.jsp.registered = true＃是否已注册JSP servlet。<br>
server.servlet.session.cookie.comment = ＃会话cookie的评论。<br>
server.servlet.session.cookie.domain = ＃会话cookie的域名。<br>
server.servlet.session.cookie.http-only = ＃是否对会话cookie使用“HttpOnly”cookie。<br>
server.servlet.session.cookie.max-age = ＃会话cookie的最大年龄。如果未指定持续时间后缀，则将使用秒。<br>
server.servlet.session.cookie.name = ＃会话cookie名称。<br>
server.servlet.session.cookie.path = ＃会话cookie的路径。<br>
server.servlet.session.cookie.secure =＃是否始终将会话cookie标记为安全。<br>
server.servlet.session.persistent = false ＃是否在重新启动之间保留会话数据。<br>
server.servlet.session.store-dir = ＃用于存储会话数据的目录。<br>
server.servlet.session.timeout = 30m ＃会话超时。如果未指定持续时间后缀，则将使用秒。<br>
server.servlet.session.tracking-modes = ＃会话跟踪模式。<br>
server.ssl.ciphers = ＃支持的SSL密码。<br>
server.ssl.client-auth = ＃客户端身份验证模式。<br>
server.ssl.enabled = true ＃是否启用SSL支持。<br>
server.ssl.enabled-protocols = ＃启用SSL协议。<br>
server.ssl.key-alias = ＃标识密钥库中密钥的别名。<br>
server.ssl.key-password = ＃用于访问密钥库中密钥的密码。<br>
server.ssl.key-store = ＃保存SSL证书的密钥库的路径（通常是jks文件）。<br>
server.ssl.key-store-password = ＃用于访问密钥库的密码。<br>
server.ssl.key-store-provider = ＃密钥库的提供者。<br>
server.ssl.key-store-type = ＃密钥库的类型。<br>
server.ssl.protocol = TLS ＃要使用的SSL协议。<br>
server.ssl.trust-store = ＃持有SSL证书的信任存储。<br>
server.ssl.trust-store-password = ＃用于访问信任库的密码。<br>
server.ssl.trust-store-provider = ＃信任存储的提供者。<br>
server.ssl.trust-store-type = ＃信任库的类型。<br>
server.tomcat.accept-count = 100 ＃当所有可能的请求处理线程都在使用时，传入连接请求的最大队列长度。<br>
server.tomcat.accesslog.buffered = true ＃是否缓冲输出，使其仅定期刷新。<br>
server.tomcat.accesslog.directory = logs＃创建日志文件的目录。可以绝对或相对于Tomcat基础目录。<br>
server.tomcat.accesslog.enabled = false ＃启用访问日志。<br>
server.tomcat.accesslog.file-date-format = .yyyy-MM-dd ＃要放在日志文件名中的日期格式。<br>
server.tomcat.accesslog.pattern = common ＃访问日志的格式模式。<br>
server.tomcat.accesslog.prefix = access_log ＃日志文件名前缀。<br>
server.tomcat.accesslog.rename-on-rotate = false ＃是否延迟在文件名中包含日期戳，直到旋转时间。<br>
server.tomcat.accesslog.request-attributes-enabled = false＃设置请求的IP地址，主机名，协议和端口的请求属性。<br>
server.tomcat.accesslog.rotate = true ＃是否启用访问日志轮换。<br>
server.tomcat.accesslog.suffix = .log ＃日志文件名后缀。<br>
server.tomcat.additional-tld-skip-patterns = ＃逗号分隔的其他模式列表，这些模式匹配要忽略的TLD扫描的jar。<br>
server.tomcat.background-processor-delay = 10s #backgroundProcess 方法调用之间的延迟。如果未指定持续时间后缀，则将使用秒。<br>
server.tomcat.basedir = #Tomcat 基目录。如果未指定，则使用临时目录。<br>
server.tomcat.internal-proxies = 10 \。\ d {1,3} \。\ d {1,3} \。\ d {1,3} | \<br>
。192 \ 168 \ d {1,3} \ d {1,3} | \<br>
。169 \ 254 \ d {1,3} \ d {1,3} | \<br>
。127 \ d {1,3} \ d {1,3} \ d {1,3} | \<br>
172 \ 1 [6-9] {1} \ d {1,3} \ d {1,3} |。。\<br>
172 \ 2 [0-9] {1} \ d {1,3} \ d {1,3} |。。\<br>
172 \。3 [0-1] {1} \。\ d {1,3} \。\ d {1,3} \<br>
0：0：0：0：0：0：0：1 \<br>
:: 1 ＃正则表达式匹配要信任的代理。<br>
server.tomcat.max-connections = 10000 ＃服务器在任何给定时间接受和处理的最大连接数。<br>
server.tomcat.max-http-post-size = 2MB #HTTP 帖子内容的最大大小。<br>
server.tomcat.max-swallow-size = 2MB ＃要吞咽的请求正文的最大数量。<br>
server.tomcat.max-threads = 200 ＃最大工作线程数。<br>
server.tomcat.min-spare-threads = 10 ＃最小工作线程数。<br>
server.tomcat.port-header = X-Forwarded-Port＃用于覆盖原始端口值的HTTP头的名称。<br>
server.tomcat.protocol-header = ＃包含传入协议的头文件，通常命名为“X-Forwarded-Proto”。<br>
server.tomcat.protocol-header-https-value = https ＃协议标头的值，指示传入请求是否使用SSL。<br>
server.tomcat.redirect-context-root = true ＃是否应通过在路径中附加/来重定向对上下文根的请求。<br>
server.tomcat.remote-ip-header = ＃从中提取远程IP的HTTP头的名称。例如，<code>X-FORWARDED-FOR</code>。<br>
server.tomcat.resource.allow-caching = true＃是否允许此Web应用程序使用静态资源缓存。<br>
server.tomcat.resource.cache-ttl = ＃静态资源缓存的生存时间。<br>
server.tomcat.uri-encoding = UTF-8 ＃用于解码URI的字符编码。<br>
server.tomcat.use-relative-redirects = ＃通过调用sendRedirect生成的HTTP 1.1和更高版本的位置标头是使用相对还是绝对重定向。<br>
server.undertow.accesslog.dir = #Undertow 访问日志目录。<br>
server.undertow.accesslog.enabled = false ＃是否启用访问日志。<br>
server.undertow.accesslog.pattern = common ＃访问日志的格式模式。<br>
server.undertow.accesslog.prefix = access_log。＃日志文件名前缀。<br>
server.undertow.accesslog.rotate = true ＃是否启用访问日志轮换。<br>
server.undertow.accesslog.suffix = log ＃日志文件名后缀。<br>
server.undertow.buffer-size = ＃每个缓冲区的大小。<br>
server.undertow.direct-buffers = ＃是否在Java堆外部分配缓冲区。默认值源自JVM可用的最大内存量。<br>
server.undertow.eager-filter-init = true ＃是否应在启动时初始化servlet过滤器。<br>
server.undertow.io-threads =＃为worker创建的I / O线程数。默认值源自可用处理器的数量。<br>
server.undertow.max-http-post-size = -1B #HTTP 帖子内容的最大大小。当值为-1时，默认值为大小无限制。<br>
server.undertow.worker-threads = ＃工作线程数。默认值是I / O线程数的8倍。</p>
<p>#FREEMARKER（FreeMarkerProperties）<br>
spring.freemarker.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.freemarker.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.freemarker.cache = false ＃是否启用模板缓存。<br>
spring.freemarker.charset = UTF-8 ＃模板编码。<br>
spring.freemarker.check-template-location = true ＃是否检查模板位置是否存在。<br>
spring.freemarker.content-type = text / html ＃Content-Type value。<br>
spring.freemarker.enabled = true ＃是否为此技术启用MVC视图分辨率。<br>
spring.freemarker.expose-request-attributes = false ＃是否应在与模板合并之前将所有请求属性添加到模型中。<br>
spring.freemarker.expose-session-attributes = false ＃是否应在与模板合并之前将所有HttpSession属性添加到模型中。<br>
spring.freemarker.expose-spring-macro-helpers = true ＃是否公开一个RequestContext供Spring的宏库使用，名称为“springMacroRequestContext”。<br>
spring.freemarker.prefer-file-system-access = true ＃是否更喜欢文件系统访问以进行模板加载。文件系统访问可以热检测模板更改。<br>
spring.freemarker.prefix = ＃在构建URL时添加前缀以查看名称的前缀。<br>
spring.freemarker.request-context-attribute = ＃所有视图的<br>
RequestContext属性的名称。spring.freemarker.settings。* = ＃众所周知的FreeMarker密钥，传递给FreeMarker的配置。<br>
spring.freemarker.suffix = .ftl ＃在构建URL时附加到视图名称的后缀。<br>
spring.freemarker.template-loader-path = classpath：/ templates /＃逗号分隔的模板路径列表。<br>
spring.freemarker.view-names = ＃可以解析的视图名称的白名单。</p>
<p>#GLOVY TEMPLATES（GroovyTemplateProperties）<br>
spring.groovy.template.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.groovy.template.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.groovy.template.cache = false ＃是否启用模板缓存。<br>
spring.groovy.template.charset = UTF-8 ＃模板编码。<br>
spring.groovy.template.check-template-location = true＃是否检查模板位置是否存在。<br>
spring.groovy.template.configuration。* = ＃请参阅GroovyMarkupConfigurer<br>
spring.groovy.template.content-type = text / html ＃Content-Type value。<br>
spring.groovy.template.enabled = true ＃是否为此技术启用MVC视图分辨率。<br>
spring.groovy.template.expose-request-attributes = false ＃是否应在与模板合并之前将所有请求属性添加到模型中。<br>
spring.groovy.template.expose-session-attributes = false ＃在与模板合并之前是否应将所有HttpSession属性添加到模型中。<br>
spring.groovy.template.expose-spring-macro-helpers = true ＃是否公开一个RequestContext供Spring的宏库使用，名称为“springMacroRequestContext”。<br>
spring.groovy.template.prefix = ＃在构建URL时添加前缀以查看名称的前缀。<br>
spring.groovy.template.request-context-attribute = ＃所有视图的<br>
RequestContext属性的名称。spring.groovy.template.resource-loader-path = classpath：/ templates / ＃Template path。<br>
spring.groovy.template.suffix = .tpl ＃在构建URL时附加到视图名称的后缀。<br>
spring.groovy.template.view-names =＃可以解析的视图名称的白名单。</p>
<p>#SPRING HATEOAS（HateoasProperties）<br>
spring.hateoas.use-hal-as-default-json-media-type = true ＃是否应将application / hal + json响应发送给接受application / json的请求。</p>
<p>#HTTP （HttpProperties）<br>
spring.http.converters.preferred-json-mapper = ＃用于HTTP消息转换的首选JSON映射器。默认情况下，根据环境自动检测。<br>
spring.http.encoding.charset = UTF-8 #HTTP 请求和响应的字符集。如果未明确设置，则添加到“Content-Type”标头。<br>
spring.http.encoding.enabled = true ＃是否启用http编码支持。<br>
spring.http.encoding.force = ＃是否在HTTP请求和响应上强制编码到已配置的字符集。<br>
spring.http.encoding.force-request =＃是否在HTTP请求中强制编码到配置的字符集。如果未指定“force”，则默认为true。<br>
spring.http.encoding.force-response = ＃是否在HTTP响应中强制编码到配置的字符集。<br>
spring.http.encoding.mapping = ＃用于编码映射的Locale。<br>
spring.http.log-request-details = false ＃是否允许在DEBUG和TRACE级别记录（可能敏感的）请求详细信息。</p>
<p>#MULTIPART （MultipartProperties）<br>
spring.servlet.multipart.enabled = true ＃是否启用分段上传支持。<br>
spring.servlet.multipart.file-size-threshold = 0B ＃将文件写入磁盘后的阈值。<br>
spring.servlet.multipart.location = ＃上传文件的中间位置。<br>
spring.servlet.multipart.max-file-size = 1MB ＃最大文件大小。<br>
spring.servlet.multipart.max-request-size = 10MB ＃最大请求大小。<br>
spring.servlet.multipart.resolve-lazily = false ＃是否在文件或参数访问时懒惰地解析多部分请求。</p>
<p>#JACKSON （JacksonProperties）<br>
spring.jackson.date-format = ＃日期格式字符串或完全限定的日期格式类名。例如，<code>yyyy-MM-dd HH：mm：ss</code>。<br>
spring.jackson.default-property-inclusion = ＃控制序列化期间包含的属性。配置了Jackson的JsonInclude.Include枚举中的一个值。<br>
spring.jackson.deserialization。* = #Jackson on / off功能会影响Java对象的反序列化方式。<br>
spring.jackson.generator。* = ＃Jackson开/关功能的发电机。<br>
spring.jackson.joda-date-time-format =#Joda日期时间格式字符串。如果未配置，如果使用格式字符串配置，则使用“date-format”作为后备。<br>
spring.jackson.locale = ＃用于格式化的区域设置。<br>
spring.jackson.mapper。* = #Jackson 通用开/关功能。<br>
spring.jackson.parser。* = ＃Jackson开启/关闭解析器的功能。<br>
spring.jackson.property-naming-strategy = #Jackson PropertyNamingStrategy的常数之一。也可以是PropertyNamingStrategy子类的完全限定类名。<br>
spring.jackson.serialization。* = #Jacker on / off功能会影响Java对象的序列化方式。<br>
spring.jackson.time-zone =＃格式化日期时使用的时区。例如，“America / Los_Angeles”或“GMT + 10”。<br>
spring.jackson.visibility。* = #Jackson 可见性阈值，可用于限制自动检测哪些方法（和字段）。</p>
<p>#GSON（GsonProperties）<br>
spring.gson.date-format = ＃序列化Date对象时使用的格式。<br>
spring.gson.disable -html-escaping = ＃是否禁用HTML字符的转义，例如'&lt;'，'&gt;'等<br>
spring.gson.disable-inner-class-serialization = ＃是否在内容类中排除内部类序列化。<br>
spring.gson.enable-complex-map-key-serialization = ＃是否启用复杂映射键（即非基元）的序列化。<br>
spring.gson.exclude-fields-without-expose-annotation = ＃是否排除所有不考虑序列化或反序列化但没有“Expose”注释的字段。<br>
spring.gson.field-naming-policy = ＃在序列化和反序列化期间应该应用于对象字段的命名策略。<br>
spring.gson.generate-non-executable-json = ＃是否通过在输出前添加一些特殊文本来生成不可执行的JSON。<br>
spring.gson.lenient = ＃是否宽容解析不符合RFC 4627的<br>
JSON.chring.gson.long-serialization-policy = ＃长和长类型的序列化策略。<br>
spring.gson.pretty-printing = ＃是否输出适合页面的序列化JSON以进行漂亮的打印。<br>
spring.gson.serialize-nulls = ＃是否序列化空字段。</p>
<p>#JERSEY （JerseyProperties）<br>
spring.jersey.application-path = ＃作为应用程序基URI的路径。如果指定，则覆盖“@ApplicationPath”的值。<br>
spring.jersey.filter.order = 0 ＃Jersey过滤链顺序。<br>
spring.jersey.init。* = ＃通过servlet或过滤器传递给Jersey的Init参数。<br>
spring.jersey.servlet.load-on-startup = -1 ＃加载Jersey servlet的启动优先级。<br>
spring.jersey.type = servlet ＃Jersey集成类型。</p>
<p>#SPRING LDAP（LdapProperties）<br>
spring.ldap.anonymous-read-only = false ＃只读操作是否应使用匿名环境。<br>
spring.ldap.base = #Base 后缀，所有操作都应该来自该后缀。<br>
spring.ldap.base-environment。* = #LDAP 规范设置。<br>
spring.ldap.password = ＃服务器的登录密码。<br>
spring.ldap.urls = ＃服务器的LDAP URL。<br>
spring.ldap.username = ＃登录服务器的用户名。</p>
<p>＃EMBEDDED LDAP（EmbeddedLdapProperties）<br>
spring.ldap.embedded.base-dn = ＃基本DN列表。<br>
spring.ldap.embedded.credential.username = ＃嵌入式LDAP用户名。<br>
spring.ldap.embedded.credential.password = ＃嵌入式LDAP密码。<br>
spring.ldap.embedded.ldif = classpath：schema.ldif #Schema （LDIF）脚本资源引用。<br>
spring.ldap.embedded.port = 0 ＃嵌入式LDAP端口。<br>
spring.ldap.embedded.validation.enabled = true ＃是否启用LDAP模式验证。<br>
spring.ldap.embedded.validation.schema = ＃自定义架构的路径。</p>
<p>#MUSTACHE TEMPLATES（MustacheAutoConfiguration）<br>
spring.mustache.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.mustache.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.mustache.cache = false ＃是否启用模板缓存。<br>
spring.mustache.charset = UTF-8 ＃模板编码。<br>
spring.mustache.check-template-location = true ＃是否检查模板位置是否存在。<br>
spring.mustache.content-type = text / html ＃Content-Type value。<br>
spring.mustache.enabled = true ＃是否为此技术启用MVC视图分辨率。<br>
spring.mustache.expose-request-attributes = false ＃在与模板合并之前是否应将所有请求属性添加到模型中。<br>
spring.mustache.expose-session-attributes = false ＃在与模板合并之前是否应将所有HttpSession属性添加到模型中。<br>
spring.mustache.expose-spring-macro-helpers = true ＃是否公开一个RequestContext供Spring的宏库使用，名称为“springMacroRequestContext”。<br>
spring.mustache.prefix= classpath：/ templates / ＃适用于模板名称的前缀。<br>
spring.mustache.request-context-attribute = ＃所有视图的<br>
RequestContext属性的名称。spring.mustache.suffix = .mustache ＃后缀应用于模板名称。<br>
spring.mustache.view-names = ＃可以解析的视图名称的白名单。</p>
<p>#SPRING MVC（WebMvcProperties）<br>
spring.mvc.async.request-timeout = ＃异步请求处理<br>
超时之前的时间。spring.mvc.contentnegotiation.favor-parameter = false ＃是否应使用请求参数（默认为“format”）来确定请求的媒体类型。<br>
spring.mvc.contentnegotiation.favor-path-extension = false ＃是否应使用URL路径中的路径扩展来确定所请求的媒体类型。<br>
spring.mvc.contentnegotiation.media-types。* = ＃映射内容协商的媒体类型的文件扩展名。例如，yml到text / yaml。<br>
spring.mvc.contentnegotiation.parameter-name =＃启用“favor-parameter”时要使用的查询参数名称。<br>
spring.mvc.date-format = ＃要使用的日期格式。例如，<code>dd / MM / yyyy</code>。<br>
spring.mvc.dispatch-trace-request = false ＃是否将TRACE请求分派给FrameworkServlet doService方法。<br>
spring.mvc.dispatch-options-request = true ＃是否将OPTIONS请求分派给FrameworkServlet doService方法。<br>
spring.mvc.favicon.enabled = true ＃是否启用favicon.ico的解析。<br>
spring.mvc.formcontent.filter.enabled = true ＃是否启用Spring的FormContentFilter。<br>
spring.mvc.hiddenmethod.filter.enabled = true＃是否启用Spring的HiddenHttpMethodFilter。<br>
spring.mvc.ignore-default-model-on-redirect = true ＃在重定向场景中是否应忽略“默认”模型的内容。<br>
spring.mvc.locale = ＃要使用的语言环境。默认情况下，“Accept-Language”标头会覆盖此区域设置。<br>
spring.mvc.locale-resolver = accept-header ＃定义应如何解析语言环境。<br>
spring.mvc.log-resolved-exception = false ＃是否启用由“HandlerExceptionResolver”解析的异常的警告日志记录，“DefaultHandlerExceptionResolver”除外。<br>
spring.mvc.message-codes-resolver-format =＃格式化消息代码的策略。例如，<code>PREFIX_ERROR_CODE</code>。<br>
spring.mvc.pathmatch.use-registered-suffix-pattern = false ＃后缀模式匹配是否仅适用于使用“spring.mvc.contentnegotiation.media-types。<em>”注册的扩展。<br>
spring.mvc.pathmatch.use-suffix-pattern = false ＃将模式与请求匹配时是否使用后缀模式匹配（“。</em>”）。<br>
spring.mvc.servlet.load-on-startup = -1 ＃加载调度程序servlet的启动优先级。<br>
spring.mvc.servlet.path = / ＃调度程序servlet的路径。<br>
spring.mvc.static-path-pattern = / ** ＃用于静态资源的路径模式。<br>
spring.mvc.throw-exception-if-no-handler-found = false ＃如果没有找到Handler来处理请求，是否应该抛出“NoHandlerFoundException”。<br>
spring.mvc.view.prefix = #Spring MVC视图前缀。<br>
spring.mvc.view.suffix = #Spring MVC视图后缀。</p>
<p>#SPRING RESOURCES HANDLING（ResourceProperties）<br>
spring.resources.add-mappings = true ＃是否启用默认资源处理。<br>
spring.resources.cache.cachecontrol.cache-private = ＃表示响应消息仅供单个用户使用，不得由共享高速缓存存储。<br>
spring.resources.cache.cachecontrol.cache-public = ＃表示任何缓存都可以存储响应。<br>
spring.resources.cache.cachecontrol.max-age = ＃应该缓存响应的最长时间，如果未指定持续时间后缀，则以秒为单位。<br>
spring.resources.cache.cachecontrol.must-revalidate =＃表示一旦它变得陈旧，缓存一定不能使用响应而不用服务器重新验证它。<br>
spring.resources.cache.cachecontrol.no-cache = ＃表示只有在与服务器重新验证时才能重用缓存的响应。<br>
spring.resources.cache.cachecontrol.no-store = ＃表示在任何情况下都不缓存响应。<br>
spring.resources.cache.cachecontrol.no-transform = ＃表明他们不应该转换响应内容的中介（缓存和其他人）。<br>
spring.resources.cache.cachecontrol.proxy-revalidate = ＃与“must-revalidate”指令的含义相同，但它不适用于私有缓存。<br>
spring.resources.cache.cachecontrol.s-max-age = ＃共享缓存应缓存响应的最长时间，如果未指定持续时间后缀，则以秒为单位。<br>
spring.resources.cache.cachecontrol.stale-if-error = ＃遇到错误时可以使用响应的最长时间，如果未指定持续时间后缀，则以秒为单位。<br>
spring.resources.cache.cachecontrol.stale-while-revalidate = ＃响应变为失效后可以响应的最长时间，如果未指定持续时间后缀，<br>
则以秒为单位。spring.resources.cache.period = ＃资源处理程序所服务资源的缓存周期。如果未指定持续时间后缀，则将使用秒。<br>
spring.resources.chain.cache= true ＃是否在资源链中启用缓存。<br>
spring.resources.chain.compressed = false ＃是否启用已压缩资源的解析（gzip，brotli）。<br>
spring.resources.chain.enabled = ＃是否启用Spring资源处理链。默认情况下，禁用，除非至少启用了一个策略。<br>
spring.resources.chain.html-application-cache = false ＃是否启用HTML5应用程序缓存清单重写。<br>
spring.resources.chain.strategy.content.enabled = false ＃是否启用内容版本策略。<br>
spring.resources.chain.strategy.content.paths = / **＃逗号分隔的模式列表，应用于内容版本策略。<br>
spring.resources.chain.strategy.fixed.enabled = false ＃是否启用固定版本策略。<br>
spring.resources.chain.strategy.fixed.paths = / ** ＃以逗号分隔的模式列表应用于固定版本策略。<br>
spring.resources.chain.strategy.fixed.version = ＃用于固定版本策略的版本字符串。<br>
spring.resources.static-locations = classpath：/ META-INF / resources /，classpath：/ resources /，classpath：/ static /，classpath：/ public / ＃静态资源的位置。</p>
<p>#SPRING SESSION（SessionProperties）<br>
spring.session.store-type = ＃会话存储类型。<br>
spring.session.timeout = ＃会话超时。如果未指定持续时间后缀，则将使用秒。<br>
spring.session.servlet.filter-order = -2147483598 ＃会话存储库过滤顺序。<br>
spring.session.servlet.filter-dispatcher-types = async，error，request ＃会话存储库过滤器调度程序类型。</p>
<p>#SPRING SESSION HAZELCAST（HazelcastSessionProperties）<br>
spring.session.hazelcast.flush-mode = on-save #sessions flush mode。<br>
spring.session.hazelcast.map-name = spring：session：sessions ＃用于存储会话的地图的名称。</p>
<p>#SPRING SESSION JDBC（JdbcSessionProperties）<br>
spring.session.jdbc.cleanup-cron = 0 * * * * * #cron 表达式用于过期的会话清理作业。<br>
spring.session.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.session.jdbc.schema = classpath中：组织/ springframework的/会话/ JDBC / schema- @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。<br>
spring.session.jdbc.table-name = SPRING_SESSION ＃用于存储会话的数据库表的名称。</p>
<p>#SPRING SESSION MONGODB（MongoSessionProperties）<br>
spring.session.mongodb.collection-name = sessions ＃用于存储会话的集合名称。</p>
<p>#SPRING SESSION REDIS（RedisSessionProperties）<br>
spring.session.redis.cleanup-cron = 0 * * * * * #cron 表达式用于过期的会话清理作业。<br>
spring.session.redis.flush-mode = on-save #sessions flush mode。<br>
spring.session.redis.namespace = spring：session ＃用于存储会话的密钥的命名空间。</p>
<p>#THYMELEAF（ThymeleafAutoConfiguration）<br>
spring.thymeleaf.cache = true ＃是否启用模板缓存。<br>
spring.thymeleaf.check-template = true ＃是否在呈现模板之前检查模板是否存在。<br>
spring.thymeleaf.check-template-location = true ＃是否检查模板位置是否存在。<br>
spring.thymeleaf.enabled = true ＃是否为Web框架启用Thymeleaf视图解析。<br>
spring.thymeleaf.enable-spring-el-compiler = false ＃在SpringEL表达式中启用SpringEL编译器。<br>
spring.thymeleaf.encoding = UTF-8 ＃模板文件编码。<br>
spring.thymeleaf.excluded-view-names = ＃逗号分隔的视图名称列表（允许的模式）应从分辨率中排除。<br>
spring.thymeleaf.mode = HTML ＃要应用于模板的模板模式。另请参见Thymeleaf的TemplateMode枚举。<br>
spring.thymeleaf.prefix = classpath：/ templates / ＃在构建URL时添加前缀以查看名称的前缀。<br>
spring.thymeleaf.reactive.chunked-mode-view-names = ＃逗号分隔的视图名称列表（允许的模式），当设置了最大块大小时，它应该是在CHUNKED模式下执行的唯一列表。<br>
spring.thymeleaf.reactive.full-mode-view-names =＃逗号分隔的视图名称列表（允许的模式），即使设置了最大块大小，也应该在FULL模式下执行。<br>
spring.thymeleaf.reactive.max-chunk-size = 0B ＃用于写入响应的数据缓冲区的最大大小。<br>
spring.thymeleaf.reactive.media-types = ＃视图技术支持的媒体类型。<br>
spring.thymeleaf.render-hidden-markers-before-checkboxes = false ＃是否应在复选框元素本身之前呈现隐藏的表单输入作为复选框的标记。<br>
spring.thymeleaf.servlet.content-type = text / html ＃Content-Type写入HTTP响应的值。<br>
spring.thymeleaf.servlet.produce-partial-output-while-processing = true#Thymeleaf是否应尽快开始编写部分输出或缓冲直到模板处理完成。<br>
spring.thymeleaf.suffix = .html ＃在构建URL时附加到视图名称的后缀。<br>
spring.thymeleaf.template-resolver-order = ＃链中模板解析器的顺序。<br>
spring.thymeleaf.view-names = ＃逗号分隔的视图名称列表（允许的模式），可以解析。</p>
<p>#SPRING WEBFLUX（WebFluxProperties）<br>
spring.webflux.date-format = ＃要使用的日期格式。例如，<code>dd / MM / yyyy</code>。<br>
spring.webflux.hiddenmethod.filter.enabled = true ＃是否启用Spring的HiddenHttpMethodFilter。<br>
spring.webflux.static-path-pattern = / ** ＃用于静态资源的路径模式。</p>
<p>#SPRING WEB SERVICES（WebServicesProperties）<br>
spring.webservices.path = / services ＃作为服务基URI的路径。<br>
spring.webservices.servlet.init = ＃Servlet init参数传递给Spring Web Services。<br>
spring.webservices.servlet.load-on-startup = -1 ＃加载Spring Web Services servlet的启动优先级。<br>
spring.webservices.wsdl-locations = ＃逗号分隔的WSDL位置列表以及要作为bean公开的随附XSD。</p>
<p>＃----------------------------------------<br>
＃SECURITY PROPERTIES<br>
＃----- -----------------------------------<br>
＃SECURITY（SecurityProperties）<br>
spring.security.filter.order = -100 ＃安全过滤器链顺序。<br>
spring.security.filter.dispatcher-types = async，error，request ＃安全过滤器链调度程序类型。<br>
spring.security.user.name = user ＃默认用户名。<br>
spring.security.user.password = ＃默认用户名的密码。<br>
spring.security.user.roles = ＃授予默认用户名的角色。</p>
<p>＃SECURITY OAUTH2 CLIENT（OAuth2ClientProperties）<br>
spring.security.oauth2.client.provider。* = ＃OAuth提供商详细信息。<br>
spring.security.oauth2.client.registration。* = ＃OAuth客户注册。</p>
<p>＃SECURITY OAUTH2 RESOURCE SERVER（OAuth2ResourceServerProperties）<br>
spring.security.oauth2.resourceserver.jwt.jwk-set-uri = ＃JSON用于验证JWT令牌的Web Key URI。<br>
spring.security.oauth2.resourceserver.jwt.issuer-uri = OpenID Connect Provider声明为其颁发者标识符的URI。</p>
<p>＃----------------------------------------<br>
＃DATA PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#FLYWAY （FlywayProperties）<br>
spring.flyway.baseline-description = &lt;&lt; Flyway Baseline &gt;&gt; ＃描述在应用基线时标记现有模式。<br>
spring.flyway.baseline-on-migrate = false ＃是否在迁移非空架构时自动调用基线。<br>
spring.flyway.baseline-version = 1 ＃用于在执行基线时标记现有模式的版本。<br>
spring.flyway.check-location = true ＃是否检查迁移脚本位置是否存在。<br>
spring.flyway.clean-disabled = false ＃是否禁用数据库清理。<br>
spring.flyway.clean-on-validation-error = false＃发生验证错误时是否自动调用clean。<br>
spring.flyway.connect-retries = 0 ＃尝试连接数据库时的最大重试次数。<br>
spring.flyway.enabled = true ＃是否启用flyway。<br>
spring.flyway.encoding = UTF-8 #SQL 迁移的编码。<br>
spring.flyway.group = false ＃是否在应用它们时在同一事务中将所有挂起的迁移组合在一起。<br>
spring.flyway.ignore-future-migrations = true ＃在读取架构历史记录表时是否忽略未来的迁移。<br>
spring.flyway.ignore-ignored-migrations = false＃是否在读取模式历史记录表时忽略忽略的迁移。<br>
spring.flyway.ignore-missing-migrations = false ＃是否在读取模式历史记录表时忽略缺少的迁移。<br>
spring.flyway.ignore-pending-migrations = false ＃在读取架构历史记录表时是否忽略挂起的迁移。<br>
spring.flyway.init-sqls = ＃在获取连接后立即执行以初始化连接的SQL语句。<br>
spring.flyway.installed-by = ＃用户名在架构历史记录表中记录为已应用迁移。<br>
spring.flyway.locations = classpath：db / migration＃迁移脚本的位置。可以包含特殊的“{vendor}”占位符以使用特定于供应商的位置。<br>
spring.flyway.mixed = false ＃是否允许在同一迁移中混合事务和非事务语句。<br>
spring.flyway.out-of-order = false ＃是否允许迁移无序运行。<br>
spring.flyway.password = ＃要迁移的数据库的登录密码。<br>
spring.flyway.placeholder-prefix = $ { ＃迁移脚本中占位符的前缀。<br>
spring.flyway.placeholder-replacement = true ＃在迁移脚本中执行占位符替换。<br>
spring.flyway.placeholder-suffix =}＃迁移脚本中占位符的后缀。<br>
spring.flyway.placeholders = ＃占位符及其替换应用于sql迁移脚本。<br>
spring.flyway.repeatable-sql-migration-prefix = R ＃可重复SQL迁移的文件名前缀。<br>
spring.flyway.schemas = ＃由<br>
Flyway 管理的方案名称（区分大小写）。spring.flyway.skip-default-callbacks = false ＃是否跳过默认回调。如果为true，则仅使用自定义回调。<br>
spring.flyway.skip-default-resolvers = false ＃是否跳过默认的解析器。如果为true，则仅使用自定义解析程序。<br>
spring.flyway.sql-migration-prefix = V.#SQL迁移的文件名前缀。<br>
spring.flyway.sql-migration-separator = __ #SQL迁移的文件名分隔符。<br>
spring.flyway.sql-migration-suffixes = .sql #SQL迁移的文件名后缀。<br>
spring.flyway.table = flyway_schema_history ＃<br>
将由 Flyway 使用的架构架构历史记录表的名称。spring.flyway.target = ＃应考虑迁移的目标版本。<br>
spring.flyway.url = 要迁移的数据库的JDBC url。如果未设置，则使用主要配置的数据源。<br>
spring.flyway.user = ＃要迁移的数据库的登录用户。<br>
spring.flyway.validate-on-migrate = true ＃是否在执行迁移时自动调用validate。</p>
<p>#LIQUIBASE（LiquibaseProperties）<br>
spring.liquibase.change-log = classpath：/db/changelog/db.changelog-master.yaml# 更改日志配置路径。<br>
spring.liquibase.check-change-log-location = true ＃是否检查更改日志位置是否存在。<br>
spring.liquibase.contexts = ＃逗号分隔的运行时上下文列表。<br>
spring.liquibase.database-change-log-lock-table = DATABASECHANGELOGLOCK ＃用于跟踪并发Liquibase用法的表的名称。<br>
spring.liquibase.database-change-log-table = DATABASECHANGELOG ＃用于跟踪更改历史<br>
记录的表的名称。spring.liquibase.default-模式= ＃默认数据库架构。<br>
spring.liquibase.drop-first = false ＃是否首先删除数据库模式。<br>
spring.liquibase.enabled = true ＃是否启用Liquibase支持。<br>
spring.liquibase.labels = ＃逗号分隔的运行时标签列表。<br>
spring.liquibase.liquibase-schema = #Schema用于Liquibase对象。<br>
spring.liquibase.liquibase-tablespace = ＃用于Liquibase对象的表空间。<br>
spring.liquibase.parameters。* = ＃更改日志参数。<br>
spring.liquibase.password = ＃要迁移的数据库的登录密码。<br>
spring.liquibase.rollback-file = ＃执行更新时写入回滚SQL的文件。<br>
spring.liquibase.test-rollback-on-update = false ＃是否应在执行更新之前测试回滚。<br>
spring.liquibase.url = ＃JDBC要迁移的数据库的URL。如果未设置，则使用主要配置的数据源。<br>
spring.liquibase.user = ＃要迁移的数据库的登录用户。</p>
<p>＃COUCHBASE（CouchbaseProperties）<br>
spring.couchbase.bootstrap-hosts = #Couchbase 节点（主机或IP地址）来自引导程序。<br>
spring.couchbase.bucket.name = default ＃要连接的存储桶的名称。<br>
spring.couchbase.bucket.password =   ＃桶的密码。<br>
spring.couchbase.env.endpoints.key-value = 1 ＃针对键/值服务的每个节点的套接字数。<br>
spring.couchbase.env.endpoints.queryservice.min-endpoints = 1 ＃每个节点的最小套接字数。<br>
spring.couchbase.env.endpoints.queryservice.max-endpoints = 1 ＃每个节点的最大套接字数。<br>
spring.couchbase.env.endpoints.viewservice.min-endpoints = 1 ＃每个节点的最小套接字数。<br>
spring.couchbase.env.endpoints.viewservice.max-endpoints = 1 ＃每个节点的最大套接字数。<br>
spring.couchbase.env.ssl.enabled = ＃是否启用SSL支持。除非另有说明，否则在提供“keyStore”时自动启用。<br>
spring.couchbase.env.ssl.key-store = ＃保存证书的JVM密钥库的路径。<br>
spring.couchbase.env.ssl.key-store-password = ＃用于访问密钥库的密码。<br>
spring.couchbase.env.timeouts.connect = 5000ms ＃桶连接超时。<br>
spring.couchbase.env.timeouts.key-value = 2500ms ＃对特定密钥超时执行的阻止操作。<br>
spring.couchbase.env.timeouts.query = 7500ms ＃N1QL查询操作超时。<br>
spring.couchbase.env.timeouts.socket-connect = 1000ms #Socket 连接超时。<br>
spring.couchbase.env.timeouts.view = 7500ms ＃常规和地理空间视图操作超时。</p>
<p>#DAO （PersistenceExceptionTranslationAutoConfiguration）<br>
spring.dao.exceptiontranslation.enabled = true ＃是否启用PersistenceExceptionTranslationPostProcessor。</p>
<p>#CASSANDRA （CassandraProperties）<br>
spring.data.cassandra.cluster-name = #Cassandra 集群的名称。<br>
spring.data.cassandra.compression = none ＃Cassandra二进制协议支持的压缩。<br>
spring.data.cassandra.connect-timeout = #Socket 选项：连接超时。<br>
spring.data.cassandra.consistency-level = ＃查询一致性级别。<br>
spring.data.cassandra.contact-points = localhost ＃群集节点地址。<br>
spring.data.cassandra.fetch-size = ＃查询默认提取大小。<br>
spring.data.cassandra.jmx-enabled = false＃是否启用JMX报告。<br>
spring.data.cassandra.keyspace-name = ＃要使用的Keyspace名称。<br>
spring.data.cassandra.port = #Cassandra 服务器的端口。<br>
spring.data.cassandra.password = ＃服务器的登录密码。<br>
spring.data.cassandra.pool.heartbeat-interval = 30s #Heartbeat interval，在此之后，在空闲连接上发送消息以确保它仍然存在。如果未指定持续时间后缀，则将使用秒。<br>
spring.data.cassandra.pool.idle-timeout = 120s ＃删除空闲连接之前的空闲超时。如果未指定持续时间后缀，则将使用秒。<br>
spring.data.cassandra.pool.max队列大小= 256 ＃如果没有可用连接，则排队的最大请求数。<br>
spring.data.cassandra.pool.pool-timeout = 5000ms ＃尝试从主机池获取连接时的池超时。<br>
spring.data.cassandra.read-timeout = #Socket 选项：读取超时。<br>
spring.data.cassandra.repositories.type = auto ＃要启用的Cassandra存储库的类型。<br>
spring.data.cassandra.serial-consistency-level = ＃查询串行一致性级别。<br>
spring.data.cassandra.schema-action = none ＃启动时要采取的架构操作。<br>
spring.data.cassandra.ssl = false ＃启用SSL支持。<br>
spring.data.cassandra.username = ＃服务器的登录用户。</p>
<p>#DATA COUCHBASE（CouchbaseDataProperties）<br>
spring.data.couchbase.auto-index = false ＃自动创建视图和索引。<br>
spring.data.couchbase.consistency = read-your-own-writes ＃在生成的查询中默认应用的一致性。<br>
spring.data.couchbase.repositories.type = auto ＃要启用的Couchbase存储库的类型。</p>
<p>#ELASTICSEARCH（ElasticsearchProperties）<br>
spring.data.elasticsearch.cluster-name = elasticsearch ＃Elasticsearch集群名称。<br>
spring.data.elasticsearch.cluster-nodes = ＃逗号分隔的集群节点地址列表。<br>
spring.data.elasticsearch.properties。* = ＃用于配置客户端的其他属性。<br>
spring.data.elasticsearch.repositories.enabled = true ＃是否启用Elasticsearch存储库。</p>
<p>#DATA JDBC spring.data.jdbc.repositories.enabled = true ＃是否启用JDBC存储库。</p>
<p>#DATA LDAP spring.data.ldap.repositories.enabled = true ＃是否启用LDAP存储库。</p>
<p>#MONGODB（MongoProperties）<br>
spring.data.mongodb.authentication-database = ＃认证数据库名称。<br>
spring.data.mongodb.database = ＃数据库名称。<br>
spring.data.mongodb.field-naming-strategy = ＃要使用的FieldNamingStrategy的完全限定名称。<br>
spring.data.mongodb.grid-fs-database = ＃GridFS数据库名称。<br>
spring.data.mongodb.host = #Mongo 服务器主机。无法使用URI设置。<br>
spring.data.mongodb.password = #mongo 服务器的登录密码。无法使用URI设置。<br>
spring.data.mongodb.port = #Mongo 服务器端口。无法使用URI设置。<br>
spring.data.mongodb.repositories.type = auto ＃要启用的Mongo存储库的类型。<br>
spring.data.mongodb.uri = mongodb：// localhost / test ＃Mongo数据库URI。无法使用主机，端口和凭据进行设置。<br>
spring.data.mongodb.username = #mongo 服务器的登录用户。无法使用URI设置。</p>
<p>#DATA REDIS<br>
spring.data.redis.repositories.enabled = true ＃是否启用Redis存储库。</p>
<p>＃NEO4J（Neo4jProperties）<br>
spring.data.neo4j.auto-index = none ＃自动索引模式。<br>
spring.data.neo4j.embedded.enabled = true ＃如果嵌入式驱动程序可用，是否启用嵌入模式。<br>
spring.data.neo4j.open-in-view = true ＃注册OpenSessionInViewInterceptor。将Neo4j会话绑定到线程以进行整个请求处理。<br>
spring.data.neo4j.password = ＃服务器的登录密码。<br>
spring.data.neo4j.repositories.enabled = true ＃是否启用Neo4j存储库。<br>
spring.data.neo4j.uri = 驱动程序使用的#URL 。默认情况下自动检测。<br>
spring.data.neo4j.username = ＃服务器的登录用户。</p>
<p>#DATA REST（RepositoryRestProperties）<br>
spring.data.rest.base-path = #Spring Data REST用于公开存储库资源的基本路径。<br>
spring.data.rest.default-media-type = ＃未指定时用作默认值的内容类型。<br>
spring.data.rest.default-page-size = ＃默认页面大小。<br>
spring.data.rest.detection-strategy = default ＃用于确定暴露哪些存储库的策略。<br>
spring.data.rest.enable-enum-translation = ＃是否通过Spring Data REST默认资源包启用枚举值转换。<br>
spring.data.rest.limit-param-name =#URL查询字符串参数的名称，指示一次返回多少结果。<br>
spring.data.rest.max-page-size = ＃最大页面大小。<br>
spring.data.rest.page-param-name = #URL 查询字符串参数的名称，指示要返回的页面。<br>
spring.data.rest.return-body-on-create = ＃是否在创建实体后返回响应正文。<br>
spring.data.rest.return-body-on-update = ＃更新实体后是否返回响应正文。<br>
spring.data.rest.sort-param-name = #URL 查询字符串参数的名称，指示对结果进行排序的方向。</p>
<p>#SOLR （SolrProperties）<br>
spring.data.solr.host = http：//127.0.0.1：8983 / solr #Solr host。如果设置了“zk-host”，则忽略。<br>
spring.data.solr.repositories.enabled = true ＃是否启用Solr存储库。<br>
spring.data.solr.zk-host = ＃ZooKeeper主机地址，格式为HOST：PORT。</p>
<p>＃DATA WEB（SpringDataWebProperties）<br>
spring.data.web.pageable.default页大小 = 20 ＃缺省页大小。<br>
spring.data.web.pageable.max-page-size = 2000 ＃要接受的最大页面大小。<br>
spring.data.web.pageable.one-indexed-parameters = false ＃是否公开和假设从1开始的页码索引。<br>
spring.data.web.pageable.page-parameter = page ＃页面索引参数名称。<br>
spring.data.web.pageable.prefix = ＃<br>
常用前缀，用于页码和页面大小参数。spring.data.web.pageable.qualifier-delimiter = _＃限定符与实际页码和大小属性之间使用的分隔符。<br>
spring.data.web.pageable.size-parameter = size ＃页面大小参数名称。<br>
spring.data.web.sort.sort-parameter = sort ＃排序参数名称。</p>
<p>#DATASOURCE （DataSourceAutoConfiguration＆DataSourceProperties）<br>
spring.datasource.continue-on-error = false ＃初始化数据库时是否发生错误时停止。<br>
spring.datasource.data = #Data （DML）脚本资源引用。<br>
spring.datasource.data-username = ＃用于执行DML脚本的数据库<br>
的用户名（如果不同）。spring.datasource.data-password = ＃执行DML脚本的数据库的密码（如果不同）。<br>
spring.datasource.dbcp2。* = ＃Commons DBCP2特定设置<br>
spring.datasource.driver-class-name =#JDBC驱动程序的完全限定名称。默认情况下，基于URL自动检测。<br>
spring.datasource.generate-unique-name = false ＃是否生成随机数据源名称。<br>
spring.datasource.hikari。* = ＃Hikari特定设置<br>
spring.datasource.initialization-mode = embedded ＃使用可用的DDL和DML脚本初始化数据源。<br>
spring.datasource.jmx-enabled = false ＃是否启用JMX支持（如果由基础池提供）。<br>
spring.datasource.jndi-name = ＃JNDI数据源的位置。设置时将忽略类，URL，用户名和密码。<br>
spring.datasource.name =＃数据源的名称。使用嵌入式数据库时默认为“testdb”。<br>
spring.datasource.password = ＃数据库的登录密码。<br>
spring.datasource.platform = all ＃在DDL或DML脚本中使用的平台（例如架构 -  $ {platform} .sql或data  -  $ {platform} .sql）。<br>
spring.datasource.schema = #Schema （DDL）脚本资源引用。<br>
spring.datasource.schema-username = ＃执行DDL脚本的数据库<br>
的用户名（如果不同）。spring.datasource.schema-password = ＃执行DDL脚本的数据库的密码（如果不同）。<br>
spring.datasource.separator =;#SQL初始化脚本中的语句分隔符。<br>
spring.datasource.sql-script-encoding = #SQL 脚本编码。<br>
spring.datasource.tomcat。* = ＃Tomcat数据源特定设置<br>
spring.datasource.type = ＃要使用的连接池实现的完全限定名称。默认情况下，它是从类路径中自动检测到的。<br>
spring.datasource.url = ＃JDBC数据库的URL。<br>
spring.datasource.username = ＃登录数据库的用户名。<br>
spring.datasource.xa.data-source-class-name = #XA 数据源完全限定名称。<br>
spring.datasource.xa.properties =＃传递给XA数据源的属性。</p>
<p>#JEST （Elasticsearch HTTP客户端）（JestProperties）<br>
spring.elasticsearch.jest.connection-timeout = 3s ＃连接超时。<br>
spring.elasticsearch.jest.multi-threaded = true ＃是否从多个执行线程启用连接请求。<br>
spring.elasticsearch.jest.password = ＃登录密码。<br>
spring.elasticsearch.jest.proxy.host = #HTTP 客户端应使用的代理主机。<br>
spring.elasticsearch.jest.proxy.port = #HTTP 客户端应使用的代理端口。<br>
spring.elasticsearch.jest.read-timeout = 3s ＃读取超时。<br>
spring.elasticsearch.jest.uris = http：// localhost：9200＃逗号分隔的Elasticsearch实例列表。<br>
spring.elasticsearch.jest.username = ＃登录用户名。</p>
<p>#Elasticsearch REST客户端（RestClientProperties）<br>
spring.elasticsearch.rest.password = ＃凭据密码。<br>
spring.elasticsearch.rest.uris = http：// localhost：9200 ＃要使用的以逗号分隔的Elasticsearch实例列表。<br>
spring.elasticsearch.rest.username = ＃凭据用户名。</p>
<p>＃H2 Web控制台（H2ConsoleProperties）<br>
spring.h2.console.enabled = false ＃是否启用控制台。<br>
spring.h2.console.path = / h2-console ＃控制台可用的路径。<br>
spring.h2.console.settings.trace = false ＃是否启用跟踪输出。<br>
spring.h2.console.settings.web-allow-others = false ＃是否启用远程访问。</p>
<p>＃InfluxDB（InfluxDbProperties）<br>
spring.influx.password = ＃登录密码。<br>
spring.influx.url = 要连接的InfluxDB实例的URL。<br>
spring.influx.user = ＃登录用户。</p>
<p>＃JOOQ （JooqProperties）<br>
spring.jooq.sql-dialect = #SQL 方言使用。默认情况下自动检测。</p>
<p>#JDBC （JdbcProperties）<br>
spring.jdbc.template.fetch-size = -1 ＃需要更多行时应从数据库中提取的行数。<br>
spring.jdbc.template.max-rows = -1 ＃最大行数。<br>
spring.jdbc.template.query-timeout = ＃查询超时。默认是使用JDBC驱动程序的默认配置。如果未指定持续时间后缀，则将使用秒。</p>
<p>＃JPA （JpaBaseConfiguration，HibernateJpaAutoConfiguration）<br>
spring.data.jpa.repositories.bootstrap-mode = default #JAPA 存储库的Bootstrap模式。<br>
spring.data.jpa.repositories.enabled = true ＃是否启用JPA存储库。<br>
spring.jpa.database = ＃要操作的目标数据库，默认情况下自动检测。也可以使用“databasePlatform”属性进行设置。<br>
spring.jpa.database-platform = ＃要操作的目标数据库的名称，默认情况下自动检测。也可以使用“Database”枚举来设置。<br>
spring.jpa.generate-ddl = false ＃是否在启动时初始化架构。<br>
spring.jpa.hibernate.ddl-auto = ＃DDL模式。这实际上是“hibernate.hbm2ddl.auto”属性的快捷方式。使用嵌入式数据库时未默认为“create-drop”，并且未检测到架构管理器。否则，默认为“none”。<br>
spring.jpa.hibernate.naming.implicit-strategy = ＃隐式命名策略的完全限定名称。<br>
spring.jpa.hibernate.naming.physical-strategy = ＃物理命名策略的完全限定名称。<br>
spring.jpa.hibernate.use-new-id-generator-mappings = ＃是否将Hibernate的较新的IdentifierGenerator用于AUTO，TABLE和SEQUENCE。<br>
spring.jpa.mapping-resources =＃Mapping资源（相当于persistence.xml中的“mapping-file”条目）。<br>
spring.jpa.open-in-view = true ＃注册OpenEntityManagerInViewInterceptor。将JPA EntityManager绑定到线程以进行整个请求处理。<br>
spring.jpa.properties。* = ＃要在JPA提供程序上设置的其他本机属性。<br>
spring.jpa.show -sql = false ＃是否启用SQL语句的日志记录。</p>
<p>#JTA （JtaAutoConfiguration）<br>
spring.jta.enabled = true ＃是否启用JTA支持。<br>
spring.jta.log-dir = #Transaction logs目录。<br>
spring.jta.transaction-manager-id = #Transaction manager唯一标识符。</p>
<p>#ATOMIKOS（AtomikosProperties）<br>
spring.jta.atomikos.connectionfactory.borrow-connection-timeout = 30 ＃从池中借用连接的超时（以秒为单位）。<br>
spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag = true ＃是否在创建会话时忽略事务处理标志。<br>
spring.jta.atomikos.connectionfactory.local-transaction-mode = false ＃是否需要本地事务。<br>
spring.jta.atomikos.connectionfactory.maintenance-interval = 60 ＃池维护线程运行之间的时间（以秒为单位）。<br>
spring.jta.atomikos.connectionfactory.max-idle-time = 60＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.atomikos.connectionfactory.max-lifetime = 0 ＃连接在被销毁之前可以合并的时间（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.connectionfactory.max-pool-size = 1 ＃池的最大大小。<br>
spring.jta.atomikos.connectionfactory.min-pool-size = 1 ＃池的最小大小。<br>
spring.jta.atomikos.connectionfactory.reap-timeout = 0 ＃借用连接的reap超时（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.connectionfactory.unique-resource-name = jmsConnectionFactory＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.atomikos.connectionfactory.xa-connection-factory-class-name = #XAConnectionFactory的供应商特定实现。<br>
spring.jta.atomikos.connectionfactory.xa-properties = ＃供应商特定的XA属性。<br>
spring.jta.atomikos.datasource.borrow-connection-timeout = 30 ＃从池中借用连接的超时时间（秒）。<br>
spring.jta.atomikos.datasource.concurrent-connection-validation = ＃是否使用并发连接验证。<br>
spring.jta.atomikos.datasource.default-isolation-level = ＃池提供的连接的默认隔离级别。<br>
spring.jta.atomikos.datasource.login-timeout = ＃用于建立数据库连接的超时（以秒为单位）。<br>
spring.jta.atomikos.datasource.maintenance-interval = 60 ＃池维护线程运行之间的时间（以秒为单位）。<br>
spring.jta.atomikos.datasource.max-idle-time = 60 ＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.atomikos.datasource.max-lifetime = 0 ＃连接在被销毁之前可以合并的时间（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.datasource.max-pool-size = 1 ＃池的最大大小。<br>
spring.jta.atomikos.datasource.min-pool-size = 1＃池的最小大小。<br>
spring.jta.atomikos.datasource.reap-timeout = 0 ＃借用连接的reap超时（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.datasource.test-query = ＃用于在返回连接之前验证连接的SQL查询或语句。<br>
spring.jta.atomikos.datasource.unique-resource-name = dataSource ＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.atomikos.datasource.xa-data-source-class-name = #XAConnectionFactory的供应商特定实现。<br>
spring.jta.atomikos.datasource.xa-properties = ＃供应商特定的XA属性。<br>
spring.jta.atomikos.properties.allow-sub-transactions = true ＃指定是否允许子事务。<br>
spring.jta.atomikos.properties.checkpoint-interval = 500 ＃检查点之间的间隔，表示为两个检查点之间的日志写入次数。<br>
spring.jta.atomikos.properties.default -jta -timeout = 10000ms #JTA 事务的默认超时。<br>
spring.jta.atomikos.properties.default-max-wait-time-on-shutdown = 9223372036854775807 ＃正常关闭（no-force）等待事务完成的时间。<br>
spring.jta.atomikos.properties.enable-logging = true ＃是否启用磁盘日志记录。<br>
spring.jta.atomikos.properties.force-shutdown-on-vm-exit = false ＃虚拟机关闭是否应触发事务核心的强制关闭。<br>
spring.jta.atomikos.properties.log-base-dir = ＃应存储日志文件的目录。<br>
spring.jta.atomikos.properties.log-base-name = tmlog ＃Transactions日志文件基名。<br>
spring.jta.atomikos.properties.max-actives = 50 ＃最大活动事务数。<br>
spring.jta.atomikos.properties.max-timeout = 300000ms ＃事务允许的最大超时时间。<br>
spring.jta.atomikos.properties.recovery.delay = 10000ms ＃两次恢复扫描之间的延迟。<br>
spring.jta.atomikos.properties.recovery.forget- orphaned -log-entries-delay = 86400000ms ＃恢复之后的延迟可以清除挂起（'孤立'）日志条目。<br>
spring.jta.atomikos.properties.recovery.max-retries = 5 ＃在抛出异常之前提交事务的重试次数。<br>
spring.jta.atomikos.properties.recovery.retry-interval = 10000ms ＃重试尝试之间的延迟。<br>
spring.jta.atomikos.properties.serial-jta-transactions = true ＃是否应尽可能加入子事务。<br>
spring.jta.atomikos.properties.service = ＃应该启动的事务管理器实现。<br>
spring.jta.atomikos.properties.threaded-two-phase-commit = false ＃是否对参与资源使用不同（和并发）线程进行两阶段提交。<br>
spring.jta.atomikos.properties.transaction-manager-unique-name = ＃事务管理器的唯一名称。</p>
<p>＃BITRONIX<br>
spring.jta.bitronix.connectionfactory.acquire-increment = 1 ＃在增长池时创建的连接数。<br>
spring.jta.bitronix.connectionfactory.acquisition-interval = 1 ＃获取无效连接后再次尝试获取连接之前等待的时间（以秒为单位）。<br>
spring.jta.bitronix.connectionfactory.acquisition-timeout = 30 ＃从池中获取连接的超时时间（秒）。<br>
spring.jta.bitronix.connectionfactory.allow-local-transactions = true ＃事务管理器是否应该允许混合XA和非XA事务。<br>
spring.jta.bitronix.connectionfactory.apply-transaction-timeout = false＃是否应在登记时在XAResource上设置事务超时。<br>
spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled = true ＃是否应自动登记和退出资源。<br>
spring.jta.bitronix.connectionfactory.cache-producer-consumers = true ＃是否应该缓存生产者和消费者。<br>
spring.jta.bitronix.connectionfactory.class-name = #XA 资源的底层实现类名。<br>
spring.jta.bitronix.connectionfactory.defer-connection-release = true ＃提供程序是否可以在同一连接上运行多个事务并支持事务交错。<br>
spring.jta.bitronix.connectionfactory.disabled= ＃是否禁用此资源，这意味着暂时禁止从其池中获取连接。<br>
spring.jta.bitronix.connectionfactory.driver-properties = ＃应在底层实现上设置的属性。<br>
spring.jta.bitronix.connectionfactory.failed = ＃将此资源生成器标记为失败。<br>
spring.jta.bitronix.connectionfactory.ignore-recovery-failures = false ＃是否应忽略恢复失败。<br>
spring.jta.bitronix.connectionfactory.max-idle-time = 60 ＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.bitronix.connectionfactory.max-pool-size = 10＃池的最大大小。0表示没有限制。<br>
spring.jta.bitronix.connectionfactory.min-pool-size = 0 ＃池的最小大小。<br>
spring.jta.bitronix.connectionfactory.password = ＃用于连接JMS提供程序的密码。<br>
spring.jta.bitronix.connectionfactory.share-transaction-connections = false ＃是否可以在事务上下文中共享处于ACCESSIBLE状态的连接。<br>
spring.jta.bitronix.connectionfactory.test-connections = true ＃从池中获取时是否应测试连接。<br>
spring.jta.bitronix.connectionfactory.two-pc-ordering-position = 1＃在两阶段提交期间此资源应采取的位置（始终是第一个是Integer.MIN_VALUE，总是最后一个是Integer.MAX_VALUE）。<br>
spring.jta.bitronix.connectionfactory.unique-name = jmsConnectionFactory ＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.bitronix.connectionfactory.use -tm<br>
-join = true ＃启动XAResources时是否应该使用TMJOIN。spring.jta.bitronix.connectionfactory.user = ＃用于连接到JMS提供程序的用户。<br>
spring.jta.bitronix.datasource.acquire-increment = 1 ＃在增长池时创建的连接数。<br>
spring.jta.bitronix.datasource.acquisition-interval = 1＃在获取无效连接后再次尝试获取连接之前等待的时间（以秒为单位）。<br>
spring.jta.bitronix.datasource.acquisition-timeout = 30 ＃从池中获取连接的超时时间（秒）。<br>
spring.jta.bitronix.datasource.allow-local-transactions = true ＃事务管理器是否应该允许混合XA和非XA事务。<br>
spring.jta.bitronix.datasource.apply-transaction-timeout = false ＃是否应在XAResource登记时设置事务超时。<br>
spring.jta.bitronix.datasource.automatic-enlisting-enabled = true ＃是否应自动登记和退出资源。<br>
spring.jta.bitronix.datasource.class-name = #XA 资源的底层实现类名。<br>
spring.jta.bitronix.datasource.cursor-holdability = ＃连接的默认光标可保持性。<br>
spring.jta.bitronix.datasource.defer-connection-release = true ＃数据库是否可以在同一连接上运行多个事务并支持事务交错。<br>
spring.jta.bitronix.datasource.disabled = ＃是否禁用此资源，这意味着暂时禁止从其池中获取连接。<br>
spring.jta.bitronix.datasource.driver-properties = ＃应在底层实现上设置的属性。<br>
spring.jta.bitronix.datasource.enable -jdbc4-connection-test = ＃从池中获取连接时是否调用Connection.isValid（）。<br>
spring.jta.bitronix.datasource.failed = ＃将此资源生成器标记为失败。<br>
spring.jta.bitronix.datasource.ignore-recovery-failures = false ＃是否应忽略恢复失败。<br>
spring.jta.bitronix.datasource.isolation-level = ＃连接的默认隔离级别。<br>
spring.jta.bitronix.datasource.local-auto-commit = ＃本地事务的默认自动提交模式。<br>
spring.jta.bitronix.datasource.login-timeout =＃建立数据库连接的超时时间（秒）。<br>
spring.jta.bitronix.datasource.max-idle-time = 60 ＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.bitronix.datasource.max-pool-size = 10 ＃池的最大大小。0表示没有限制。<br>
spring.jta.bitronix.datasource.min-pool-size = 0 ＃池的最小大小。<br>
spring.jta.bitronix.datasource.prepared-statement-cache-size = 0 ＃<br>
预准备语句缓存的目标大小。0禁用缓存。spring.jta.bitronix.datasource.share-transaction-connections = false＃是否可以在事务上下文中共享处于ACCESSIBLE状态的连接。<br>
spring.jta.bitronix.datasource.test-query = ＃用于在返回连接之前验证连接的SQL查询或语句。<br>
spring.jta.bitronix.datasource.two-pc-ordering-position = 1 ＃此资源在两阶段提交期间应采取的位置（始终首先是Integer.MIN_VALUE，并且始终是最后一个是Integer.MAX_VALUE）。<br>
spring.jta.bitronix.datasource.unique-name = dataSource ＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.bitronix.datasource.use -tm -join = true ＃启动XAResources时是否应该使用TMJOIN。<br>
spring.jta.bitronix.properties.allow-multiple-lrc = false ＃是否允许多个LRC资源登记到同一事务中。<br>
spring.jta.bitronix.properties.asynchronous2-pc = false ＃是否启用异步执行两阶段提交。<br>
spring.jta.bitronix.properties.background-recovery-interval-seconds = 60 ＃在后台运行恢复过程的时间间隔（以秒为单位）。<br>
spring.jta.bitronix.properties.current-node-only-recovery = true ＃是否仅恢复当前节点。<br>
spring.jta.bitronix.properties.debug-zero-resource-transaction = false＃是否记录创建和提交没有单个登记资源的事务调用堆栈。<br>
spring.jta.bitronix.properties.default-transaction-timeout = 60 ＃默认事务超时，以秒为单位。<br>
spring.jta.bitronix.properties.disable-jmx = false ＃是否启用JMX支持。<br>
spring.jta.bitronix.properties.exception-analyzer = ＃设置要使用的异常分析器实现的完全限定名称。<br>
spring.jta.bitronix.properties.filter-log-status = false ＃是否启用日志过滤，以便只写入强制日志。<br>
spring.jta.bitronix.properties.force-batching-enabled = true＃是否批量磁盘强制。<br>
spring.jta.bitronix.properties.forced-write-enabled = true ＃是否强制将日志记录到磁盘。<br>
spring.jta.bitronix.properties.graceful-shutdown-interval = 60 ＃TM在关闭时中止事务之前等待事务完成的最大秒数。<br>
spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name = ＃TransactionSynchronizationRegistry的JNDI名称。<br>
spring.jta.bitronix.properties.jndi-user-transaction-name = ＃UserTransaction的JNDI名称。<br>
spring.jta.bitronix.properties.journal = disk ＃期刊的名称。可以是'disk'，'null'或类名。<br>
spring.jta.bitronix.properties.log-part1-filename = btm1.tlog ＃日志的第一个片段的名称。<br>
spring.jta.bitronix.properties.log-part2-filename = btm2.tlog ＃日志的第二个片段的名称。<br>
spring.jta.bitronix.properties.max-log-size-in-mb = 2 ＃日志片段的最大大小（兆字节）。<br>
spring.jta.bitronix.properties.resource-configuration-filename = ＃ResourceLoader配置文件名。<br>
spring.jta.bitronix.properties.server-id = #ASCII ID必须唯一标识此TM实例。默认为机器的IP地址。<br>
spring.jta.bitronix.properties.skip-corrupted-logs = false#Skip损坏的事务日志条目。<br>
spring.jta.bitronix.properties.warn-about-zero-resource-transaction = true ＃是否为没有单个登记资源的事务记录警告。</p>
<p>＃EMBEDDED MONGODB（EmbeddedMongoProperties）<br>
spring.mongodb.embedded.features = sync_delay ＃逗号分隔的要启用的功能列表。<br>
spring.mongodb.embedded.storage.database-dir = ＃用于数据存储的目录。<br>
spring.mongodb.embedded.storage.oplog-size = #oplog的最大大小。<br>
spring.mongodb.embedded.storage.repl-set-name = ＃副本集的名称。<br>
spring.mongodb.embedded.version = 3.5.5 ＃要使用的Mongo版本。</p>
<p>#REDIS（RedisProperties）<br>
spring.redis.cluster.max -redirects = ＃在群集中执行命令时要遵循的最大重定向数。<br>
spring.redis.cluster.nodes = ＃逗号分隔的“host：port”对列表引导自。<br>
spring.redis.database = 0 ＃连接工厂使用的数据库索引。<br>
spring.redis.url = ＃连接URL。覆盖主机，端口和密码。用户被忽略。示例：redis：// user：password@example.com ：6379<br>
spring.redis.host = localhost ＃Redis服务器主机。<br>
spring.redis.jedis.pool.max-active = 8＃池在给定时间可以分配的最大连接数。使用负值无限制。<br>
spring.redis.jedis.pool.max-idle = 8 ＃池中“空闲”连接的最大数量。使用负值表示无限数量的空闲连接。<br>
spring.redis.jedis.pool.max -wait = -1ms ＃在池耗尽时，在抛出异常之前连接分配应该阻塞的最长时间。使用负值无限期阻止。<br>
spring.redis.jedis.pool.min-idle = 0 ＃目标是池中维护的最小空闲连接数。此设置仅在其为正时才有效。<br>
spring.redis.lettuce.pool.max-active = 8＃池在给定时间可以分配的最大连接数。使用负值无限制。<br>
spring.redis.lettuce.pool.max-idle = 8 ＃池中“空闲”连接的最大数量。使用负值表示无限数量的空闲连接。<br>
spring.redis.lettuce.pool.max -wait = -1ms ＃在池耗尽时，在抛出异常之前连接分配应阻塞的最长时间。使用负值无限期阻止。<br>
spring.redis.lettuce.pool.min-idle = 0 ＃目标是池中维护的最小空闲连接数。此设置仅在其为正时才有效。<br>
spring.redis.lettuce.shutdown-timeout = 100ms＃关机超时。<br>
spring.redis.password = ＃redis服务器的登录密码。<br>
spring.redis.port = 6379 #Redis服务器端口。<br>
spring.redis.sentinel.master = #Redis服务器的名称。<br>
spring.redis.sentinel.nodes = ＃逗号分隔的“host：port”对列表。<br>
spring.redis.ssl = false ＃是否启用SSL支持。<br>
spring.redis.timeout = ＃连接超时。</p>
<p>#TRANSACTION （TransactionProperties）<br>
spring.transaction.default-timeout = ＃默认事务超时。如果未指定持续时间后缀，则将使用秒。<br>
spring.transaction.rollback-on-commit-failure = ＃是否回滚提交失败。</p>
<p>＃----------------------------------------<br>
＃INTEGRATION PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#ACTIVEMQ（ActiveMQProperties）<br>
spring.activemq.broker-url = ActiveMQ代理的URL。默认情况下自动生成。<br>
spring.activemq.close-timeout = 15s ＃在考虑结束完成之前等待的时间。<br>
spring.activemq.in-memory = true ＃默认代理URL是否应该在内存中。如果已指定显式代理，则忽略。<br>
spring.activemq.non-blocking-redelivery = false ＃是否在从回滚事务重新传递消息之前停止消息传递。这意味着启用此消息顺序时不会保留消息顺序。<br>
spring.activemq.password = ＃代理的登录密码。<br>
spring.activemq.send-timeout = 0ms ＃等待消息发送响应的时间。将其设置为0以永远等待。<br>
spring.activemq.user = ＃代理的登录用户。<br>
spring.activemq.packages.trust-all = ＃是否信任所有包。<br>
spring.activemq.packages.trusted = ＃逗号分隔的要信任的特定包列表（不信任所有包时）。<br>
spring.activemq.pool.block-if-full = true ＃是否阻止请求连接并且池已满。将其设置为false以改为抛出“JMSException”。<br>
spring.activemq.pool.block-if-full-timeout = -1ms＃如果池仍然满，则在抛出异常之前阻塞。<br>
spring.activemq.pool.enabled = false ＃是否应创建JmsPoolConnectionFactory，而不是常规ConnectionFactory。<br>
spring.activemq.pool.idle-timeout = 30s ＃连接空闲超时。<br>
spring.activemq.pool.max-connections = 1 ＃最大池化连接数。<br>
spring.activemq.pool.max-sessions-per-connection = 500 ＃池中每个连接的最大池化会话数。<br>
spring.activemq.pool.time-between-expiration-check = -1ms ＃在空闲连接驱逐线程的运行之间休眠的时间。当为负时，没有空闲连接驱逐线程运行。<br>
spring.activemq.pool.use-anonymous-producer = true ＃是否只使用一个匿名“MessageProducer”实例。将其设置为false以在每次需要时创建一个“MessageProducer”。</p>
<p>#ARTEMIS （ArtemisProperties）<br>
spring.artemis.embedded.cluster-password = ＃群集密码。默认情况下在启动时随机生成。<br>
spring.artemis.embedded.data-directory = #Journal 文件目录。如果关闭持久性，则没有必要。<br>
spring.artemis.embedded.enabled = true ＃如果Artemis服务器API可用，是否启用嵌入模式。<br>
spring.artemis.embedded.persistent = false ＃是否启用持久存储。<br>
spring.artemis.embedded.queues = ＃逗号分隔的队列，在启动时创建。<br>
spring.artemis.embedded.server-id =＃服务器ID。默认情况下，使用自动递增的计数器。<br>
spring.artemis.embedded.topics = ＃在启动时要创建的以逗号分隔的主题列表。<br>
spring.artemis.host = localhost ＃Artemis broker主机。<br>
spring.artemis.mode = ＃Artemis部署模式，默认情况下自动检测。<br>
spring.artemis.password = ＃代理的登录密码。<br>
spring.artemis.pool.block-if-full = true ＃是否在请求连接且池已满时阻止。将其设置为false以改为抛出“JMSException”。<br>
spring.artemis.pool.block-if-full-timeout = -1ms ＃如果池仍然满，则在抛出异常之前阻塞。<br>
spring.artemis.pool.enabled = false ＃是否应创建JmsPoolConnectionFactory，而不是常规ConnectionFactory。<br>
spring.artemis.pool.idle-timeout = 30s ＃连接空闲超时。<br>
spring.artemis.pool.max-connections = 1 ＃池化连接的最大数量。<br>
spring.artemis.pool.max-sessions-per-connection = 500 ＃池中每个连接的最大池化会话数。<br>
spring.artemis.pool.time-between-expiration-check = -1ms ＃在空闲连接驱逐线程的运行之间休眠的时间。当为负时，没有空闲连接驱逐线程运行。<br>
spring.artemis.pool.use-anonymous-producers = true＃是否只使用一个匿名“MessageProducer”实例。将其设置为false以在每次需要时创建一个“MessageProducer”。<br>
spring.artemis.port = 61616 #Artemis 经纪人端口。<br>
spring.artemis.user = ＃代理的登录用户。</p>
<p>#SPRING BATCH（BatchProperties）<br>
spring.batch.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.batch.job.enabled = true ＃在启动时执行上下文中的所有Spring Batch作业。<br>
spring.batch.job.names = ＃逗号分隔的要在启动时执行的作业名称列表（例如，<code>job1，job2</code>）。默认情况下，将执行上下文中找到的所有作业。<br>
spring.batch.schema = classpath中：组织/ springframework的/批号/核心/ schema- @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。<br>
spring.batch.table-prefix =＃所有批次元数据表的表前缀。</p>
<p>#SPRING INTEGRATION（IntegrationProperties）<br>
spring.integration.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.integration.jdbc.schema = classpath中：组织/ springframework的/集成/ JDBC / schema- @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。</p>
<p>#JMS （JmsProperties）<br>
spring.jms.cache.consumers = false ＃是否缓存消息使用者。<br>
spring.jms.cache.enabled = true ＃是否缓存会话。<br>
spring.jms.cache.producers = true ＃是否缓存消息生成器。<br>
spring.jms.cache.session-cache-size = 1 ＃会话缓存的大小（根据JMS会话类型）。<br>
spring.jms.jndi-name = ＃连接工厂JNDI名称。设置时，优先于其他连接工厂自动配置。<br>
spring.jms.listener.acknowledge-mode = ＃容器的确认模式。默认情况下，侦听器使用自动确认进行事务处理。<br>
spring.jms.listener.auto-startup = true ＃启动时自动启动容器。<br>
spring.jms.listener.concurrency = ＃最小并发使用者数。<br>
spring.jms.listener.max-concurrency = ＃最大并发使用者数。<br>
spring.jms.pub-sub-domain = false ＃默认目标类型是否为topic。<br>
spring.jms.template.default-destination = ＃用于没有目标参数的发送和接收操作的默认目标。<br>
spring.jms.template.delivery-delay = ＃用于发送呼叫的传递延迟。<br>
spring.jms.template.delivery-mode =＃交付模式。设置时启用QoS（服务质量）。<br>
spring.jms.template.priority = ＃发送时消息的优先级。设置时启用QoS（服务质量）。<br>
spring.jms.template.qos-enabled = ＃发送消息时是否启用显式QoS（服务质量）。<br>
spring.jms.template.receive-timeout = ＃用于接收呼叫的超时。<br>
spring.jms.template.time-to-live = ＃发送时消息的生存时间。设置时启用QoS（服务质量）。</p>
<p>#APACHE KAFKA（KafkaProperties）<br>
spring.kafka.admin.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.admin.fail-fast = false ＃如果代理在启动时不可用，是否快速失败。<br>
spring.kafka.admin.properties。* = ＃用于配置客户端的其他特定于管理员的属性。<br>
spring.kafka.admin.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.admin.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.admin.ssl.key-store-password =＃存储密钥库文件的密码。<br>
spring.kafka.admin.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.admin.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.admin.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.admin.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.admin.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。除非被覆盖，否则适用于所有组件。<br>
spring.kafka.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.consumer.auto-commit-interval = ＃如果'enable.auto.commit'设置为true，则将消费者偏移自动提交给Kafka的频率。<br>
spring.kafka.consumer.auto-offset-reset = ＃当Kafka中没有初始偏移量或者服务器上不再存在当前偏移量时该怎么办。<br>
spring.kafka.consumer.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。为消费者覆盖全球财产。<br>
spring.kafka.consumer.client-id =#ID在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.consumer.enable-auto-commit = ＃是否在后台定期提交消费者的偏移量。<br>
spring.kafka.consumer.fetch-max-wait = ＃如果没有足够的数据立即满足“fetch-min-size”给出的要求，服务器在回答获取请求之前会阻塞的最长时间。<br>
spring.kafka.consumer.fetch-min-size = ＃服务器应为获取请求返回的最小数据量。<br>
spring.kafka.consumer.group-id = ＃唯一字符串，用于标识此使用者所属的使用者组。<br>
spring.kafka.consumer.heartbeat间隔= ＃心跳与消费者协调员之间的预期时间。<br>
spring.kafka.consumer.key-deserializer = #Deserializer 类的键。<br>
spring.kafka.consumer.max-poll-records = ＃一次调用poll（）时返回的最大记录数。<br>
spring.kafka.consumer.properties。* = ＃用于配置客户端的其他特定于使用者的属性。<br>
spring.kafka.consumer.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.consumer.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.consumer.ssl.key-store-password =＃存储密钥库文件的密码。<br>
spring.kafka.consumer.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.consumer.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.consumer.ssl.trust-store-location = ＃信任存储文件的位置。<br>
spring.kafka.consumer.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.consumer.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.consumer.value-deserializer = #Deserializer 类的值。<br>
spring.kafka.jaas.control-flag = required ＃登录配置的控制标志。<br>
spring.kafka.jaas.enabled = false ＃是否启用JAAS配置。<br>
spring.kafka.jaas.login-module = com.sun.security.auth.module.Krb5LoginModule ＃登录模块。<br>
spring.kafka.jaas.options = ＃其他JAAS选项。<br>
spring.kafka.listener.ack-count = ＃当ackMode为“COUNT”或“COUNT_TIME”时，偏移提交之间的记录数。<br>
spring.kafka.listener.ack-mode = ＃Listener AckMode。请参阅spring-kafka文档。<br>
spring.kafka.listener.ack-time = ＃当ackMode为“TIME”或“COUNT_TIME”时，偏移提交之间的时间。<br>
spring.kafka.listener.client-id =＃侦听器的使用者client.id属性的前缀。<br>
spring.kafka.listener.concurrency = ＃在侦听器容器中运行的线程数。<br>
spring.kafka.listener.idle-event-interval = ＃发布空闲消费者事件（未收到数据）之间的时间。<br>
spring.kafka.listener.log-container-config = ＃是否在初始化期间记录容器配置（INFO级别）。<br>
spring.kafka.listener.monitor-interval = ＃检查无响应的消费者之间的时间。如果未指定持续时间后缀，则将使用秒。<br>
spring.kafka.listener.no-poll-threshold =#Multiplier应用于“pollTimeout”以确定消费者是否无响应。<br>
spring.kafka.listener.poll-timeout = ＃轮询消费者时使用的超时。<br>
spring.kafka.listener.type = single ＃Listener类型。<br>
spring.kafka.producer.acks = ＃生产者要求领导者在考虑完成请求之前收到的确认数。<br>
spring.kafka.producer.batch-size = ＃默认批量大小。<br>
spring.kafka.producer.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。为生产者覆盖全球财产。<br>
spring.kafka.producer.buffer-memory = ＃生产者可用于缓冲等待发送到服务器的记录的总内存大小。<br>
spring.kafka.producer.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.producer.compression-type = ＃生产者生成的所有数据的压缩类型。<br>
spring.kafka.producer.key-serializer = ＃密码的Serializer类。<br>
spring.kafka.producer.properties。* = ＃用于配置客户端的其他特定于生产者的属性。<br>
spring.kafka.producer.retries = ＃大于零时，启用重试失败的发送。<br>
spring.kafka.producer.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.producer.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.producer.ssl.key-store-password = ＃存储密钥库文件的密码。<br>
spring.kafka.producer.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.producer.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.producer.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.producer.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.producer.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.producer.transaction-id-prefix = ＃非空时，为生产者启用事务支持。<br>
spring.kafka.producer.value-serializer = #Serializer 类的值。<br>
spring.kafka.properties。* = ＃用于配置客户端的生产者和使用者<br>
共有的附加属性。spring.kafka.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.ssl.key-store-password =＃存储密钥库文件的密码。<br>
spring.kafka.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.streams.application-id = #Kafka streams application.id property; 默认spring.application.name。<br>
spring.kafka.streams.auto-startup = true ＃是否自动启动流工厂bean。<br>
spring.kafka.streams.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。覆盖流的全局属性。<br>
spring.kafka.streams.cache-max-size-buffering = ＃用于跨所有线程缓冲的最大内存大小。<br>
spring.kafka.streams.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.streams.properties。* = ＃用于配置流的其他Kafka属性。<br>
spring.kafka.streams.replication-factor =＃流处理应用程序创建的更改日志主题和重新分区主题的复制因子。<br>
spring.kafka.streams.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.streams.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.streams.ssl.key-store-password = ＃存储密钥库文件的密码。<br>
spring.kafka.streams.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.streams.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.streams.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.streams.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.streams.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.streams.state-dir = ＃状态存储的目录位置。<br>
spring.kafka.template.default-topic = ＃发送消息的默认主题。</p>
<p>#RABBIT（RabbitProperties）<br>
spring.rabbitmq.addresses = ＃逗号分隔的客户端应连接的地址列表。<br>
spring.rabbitmq.cache.channel.checkout-timeout = ＃达到缓存大小后等待获取通道的持续时间。<br>
spring.rabbitmq.cache.channel.size = ＃要在缓存中保留的通道数。<br>
spring.rabbitmq.cache.connection.mode = channel ＃连接工厂缓存模式。<br>
spring.rabbitmq.cache.connection.size = ＃缓存的连接数。<br>
spring.rabbitmq.connection-timeout = ＃连接超时。将其设置为零以永远等待。<br>
spring.rabbitmq.dynamic = true ＃是否创建AmqpAdmin bean。<br>
spring.rabbitmq.host = localhost ＃RabbitMQ主机。<br>
spring.rabbitmq.listener.direct.acknowledge-mode = ＃容器的确认模式。<br>
spring.rabbitmq.listener.direct.auto-startup = true ＃是否在启动时自动启动容器。<br>
spring.rabbitmq.listener.direct.consumers-per-queue = ＃每个队列的消费者数量。<br>
spring.rabbitmq.listener.direct.default-requeue-rejected = ＃默认情况下，拒绝的交付是否重新排队。<br>
spring.rabbitmq.listener.direct.idle-event-interval =＃应该发布空闲容器事件的频率。<br>
spring.rabbitmq.listener.direct.missing-queues-fatal = false ＃如果容器声明的队列在代理上不可用，则是否失败。<br>
spring.rabbitmq.listener.direct.prefetch = ＃每个消费者可能未完成的未确认消息的最大数量。<br>
spring.rabbitmq.listener.direct.retry.enabled = false ＃是否启用发布重试。<br>
spring.rabbitmq.listener.direct.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。<br>
spring.rabbitmq.listener.direct.retry.max-attempts = 3＃传递邮件的最大尝试次数。<br>
spring.rabbitmq.listener.direct.retry.max -interval = 10000ms ＃尝试之间的最长持续时间。<br>
spring.rabbitmq.listener.direct.retry.multiplier = 1 ＃乘数应用于先前的重试间隔。<br>
spring.rabbitmq.listener.direct.retry.stateless = true ＃重试是无状态还是有状态。<br>
spring.rabbitmq.listener.simple.acknowledge-mode = ＃容器的确认模式。<br>
spring.rabbitmq.listener.simple.auto-startup = true ＃是否在启动时自动启动容器。<br>
spring.rabbitmq.listener.simple.concurrency =＃侦听器调用者线程的最小数量。<br>
spring.rabbitmq.listener.simple.default-requeue-rejected = ＃默认情况下，拒绝的交付是否重新排队。<br>
spring.rabbitmq.listener.simple.idle-event-interval = ＃应该发布空闲容器事件的频率。<br>
spring.rabbitmq.listener.simple.max-concurrency = ＃侦听器调用者线程的最大数量。<br>
spring.rabbitmq.listener.simple.missing-queues-fatal = true ＃如果容器声明的队列在代理上不可用，则是否失败和/或如果在运行时删除一个或多个队列，是否停止容器。<br>
spring.rabbitmq.listener.simple.prefetch =＃每个消费者可能未完成的未确认消息的最大数量。<br>
spring.rabbitmq.listener.simple.retry.enabled = false ＃是否启用发布重试。<br>
spring.rabbitmq.listener.simple.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。<br>
spring.rabbitmq.listener.simple.retry.max-attempts = 3 ＃传递邮件的最大尝试次数。<br>
spring.rabbitmq.listener.simple.retry.max -interval = 10000ms ＃尝试之间的最长持续时间。<br>
spring.rabbitmq.listener.simple.retry.multiplier = 1 ＃乘数应用于上一个重试间隔。<br>
spring.rabbitmq.listener.simple.retry.stateless = true ＃重试是无状态还是有状态。<br>
spring.rabbitmq.listener.simple.transaction-size = ＃确认模式为AUTO时要在acks之间处理的消息数。如果大于预取，则预取将增加到此值。<br>
spring.rabbitmq.listener.type = simple ＃Listener容器类型。<br>
spring.rabbitmq.password = guest ＃登录以对代理进行身份验证。<br>
spring.rabbitmq.port = 5672 ＃RabbitMQ端口。<br>
spring.rabbitmq.publisher-confirms = false ＃是否启用发布者确认。<br>
spring.rabbitmq.publisher-returns = false＃是否启用发布者返回。<br>
spring.rabbitmq.requested-heartbeat = ＃请求心跳超时; 零，没有。如果未指定持续时间后缀，则将使用秒。<br>
spring.rabbitmq.ssl.algorithm = #SSL 算法使用。默认情况下，由Rabbit客户端库配置。<br>
spring.rabbitmq.ssl.enabled = false ＃是否启用SSL支持。<br>
spring.rabbitmq.ssl.key-store = ＃保存SSL证书的密钥库的路径。<br>
spring.rabbitmq.ssl.key-store-password = ＃用于访问密钥库的密码。<br>
spring.rabbitmq.ssl.key-store-type = PKCS12 ＃密钥库类型。<br>
spring.rabbitmq.ssl.trust-store = ＃持有SSL证书的信任存储。<br>
spring.rabbitmq.ssl.trust-store-password = ＃用于访问信任库的密码。<br>
spring.rabbitmq.ssl.trust-store-type = JKS #Trust store type。<br>
spring.rabbitmq.ssl.validate-server-certificate = true ＃是否启用服务器端证书验证。<br>
spring.rabbitmq.ssl.verify-hostname = true ＃是否启用主机名验证。<br>
spring.rabbitmq.template.default-receive-queue = ＃从明确指定none时接收消息的默认队列的名称。<br>
spring.rabbitmq.template.exchange =＃用于发送操作的默认交换的名称。<br>
spring.rabbitmq.template.mandatory = ＃是否启用强制消息。<br>
spring.rabbitmq.template.receive-timeout = ＃receive（）<code>操作的超时。 spring.rabbitmq.template.reply-timeout = #outoutout用于</code>sendAndReceive（）`操作。<br>
spring.rabbitmq.template.retry.enabled = false ＃是否启用发布重试。<br>
spring.rabbitmq.template.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。<br>
spring.rabbitmq.template.retry.max-attempts = 3 ＃传递邮件的最大尝试次数。<br>
spring.rabbitmq.template.retry.max -interval = 10000ms ＃尝试之间的最长持续时间。<br>
spring.rabbitmq.template.retry.multiplier = 1 ＃乘数应用于先前的重试间隔。<br>
spring.rabbitmq.template.routing-key = ＃用于发送操作的默认路由密钥的值。<br>
spring.rabbitmq.username = guest ＃登录用户以对代理进行身份验证。<br>
spring.rabbitmq.virtual-host = ＃连接到代理时使用的虚拟主机。</p>
<p>＃----------------------------------------<br>
＃ACTUATOR PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#MANAGEMENT HTTP SERVER（ManagementServerProperties）<br>
management.server.add-application-context-header = false ＃在每个响应中添加“X-Application-Context”HTTP标头。<br>
management.server.address = ＃管理端点应绑定到的网络地址。需要自定义management.server.port。<br>
management.server.port = ＃管理端点HTTP端口（默认情况下使用与应用程序相同的端口）。配置其他端口以使用特定于管理的SSL。<br>
management.server.servlet.context-path = ＃管理端点context-path（例如，<code>/ management</code>）。需要自定义management.server.port。<br>
management.server.ssl.ciphers= ＃支持的SSL密码。<br>
management.server.ssl.client-auth = ＃客户端身份验证模式。<br>
management.server.ssl.enabled = true ＃是否启用SSL支持。<br>
management.server.ssl.enabled-protocols = ＃启用SSL协议。<br>
management.server.ssl.key-alias = ＃标识密钥库中密钥的别名。<br>
management.server.ssl.key-password = ＃用于访问密钥库中密钥的密码。<br>
management.server.ssl.key-store = ＃保存SSL证书的密钥库的路径（通常是jks文件）。<br>
management.server.ssl.key-store-password =＃用于访问密钥库的密码。<br>
management.server.ssl.key-store-provider = ＃密钥库的提供者。<br>
management.server.ssl.key-store-type = ＃密钥库的类型。<br>
management.server.ssl.protocol = TLS ＃要使用的SSL协议。<br>
management.server.ssl.trust-store = ＃持有SSL证书的信任存储。<br>
management.server.ssl.trust-store-password = ＃用于访问信任库的密码。<br>
management.server.ssl.trust-store-provider = ＃信任存储的提供者。<br>
management.server.ssl.trust-store-type = ＃信任库的类型。</p>
<p>#CLOUDFOUNDRY<br>
management.cloudfoundry.enabled = true ＃是否启用扩展的Cloud Foundry执行器端点。<br>
management.cloudfoundry.skip-ssl-validation = false ＃是否跳过Cloud Foundry执行器端点安全调用的SSL验证。</p>
<p>#ENDPOINTS GENERAL CONFIGURATION<br>
management.endpoints.enabled-by-default = ＃默认情况下是否启用或禁用所有端点。</p>
<p>#ENDPOINTS JMX CONFIGURATION（JmxEndpointProperties）<br>
management.endpoints.jmx.domain = org.springframework.boot #Endpoints JMX域名。如果设置，则回退到'spring.jmx.default-domain'。<br>
management.endpoints.jmx.exposure.include = * ＃应包含的端点ID或所有的“<em>”。<br>
management.endpoints.jmx.exposure.exclude = ＃应排除的端点ID或所有的'</em>'。<br>
management.endpoints.jmx.static-names = ＃附加的静态属性，附加到表示端点的MBean的所有ObjectName。</p>
<p>#ENDPOINTS WEB CONFIGURATION（WebEndpointProperties）<br>
management.endpoints.web.exposure.include = health，info ＃应包含的端点ID或所有的“<em>”。<br>
management.endpoints.web.exposure.exclude = ＃应排除的端点ID或所有的'</em>'。<br>
management.endpoints.web.base-path = / actuator #Web端点的基本路径。相对于server.servlet.context-path或management.server.servlet.context-path，如果配置了management.server.port。<br>
management.endpoints.web.path-mapping = ＃端点ID与应公开它们的路径之间的映射。</p>
<p>#ENDPOINTS CORS CONFIGURATION（CorsEndpointProperties）<br>
management.endpoints.web.cors.allow-credentials = ＃是否支持凭据。未设置时，不支持凭据。<br>
management.endpoints.web.cors.allowed-headers = ＃逗号分隔的请求中允许的标头列表。'<em>'允许所有标题。<br>
management.endpoints.web.cors.allowed-methods = ＃逗号分隔的允许方法列表。'</em>'允许所有方法。未设置时，默认为GET。<br>
management.endpoints.web.cors.allowed-origins = ＃逗号分隔的原始列表允许。'*'允许所有来源。未设置时，将禁用CORS支持。<br>
management.endpoints.web.cors.exposed-headers = ＃逗号分隔的标题列表，包含在响应中。<br>
management.endpoints.web.cors.max-age = 1800s ＃客户端缓存来自飞行前请求的响应的时间。如果未指定持续时间后缀，则将使用秒。</p>
<p>#AUDIT EVENTS ENDPOINT（AuditEventsEndpoint）<br>
management.endpoint.auditevents.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.auditevents.enabled = true ＃是否启用auditevents端点。</p>
<p>#BEANS ENDPOINT（BeansEndpoint）<br>
management.endpoint.beans.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.beans.enabled = true ＃是否启用beans端点。</p>
<p>#CACHES ENDPOINT（CachesEndpoint）<br>
management.endpoint.caches.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.caches.enabled = true ＃是否启用缓存端点。</p>
<p>＃条件报告ENDPOINT（ConditionsReportEndpoint）<br>
management.endpoint.conditions.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.conditions.enabled = true ＃是否启用条件端点。</p>
<p>#CONFIGURATION PROPERTIES REPORT ENDPOINT（ConfigurationPropertiesReportEndpoint，ConfigurationPropertiesReportEndpointProperties）<br>
management.endpoint.configprops.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.configprops.enabled = true ＃是否启用configprops端点。<br>
management.endpoint.configprops.keys-to-sanitize = password，secret，key，token，。* credentials。*，vcap_services，sun.java.command ＃应该清理的密钥。键可以是属性结尾的简单字符串或正则表达式。</p>
<p>#ENVEST ENDPOINT（EnvironmentEndpoint，EnvironmentEndpointProperties）<br>
management.endpoint.env.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.env.enabled = true ＃是否启用env端点。<br>
management.endpoint.env.keys-to-sanitize = password，secret，key，token，。* credentials。*，vcap_services，sun.java.command ＃应该清理的密钥。键可以是属性结尾的简单字符串或正则表达式。</p>
<p>#FLYWAY ENDPOINT（FlywayEndpoint）<br>
management.endpoint.flyway.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.flyway.enabled = true ＃是否启用flyway端点。</p>
<p>#HEEC ENDPOINT（HealthEndpoint，HealthEndpointProperties）<br>
management.endpoint.health.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.health.enabled = true ＃是否启用运行状况端点。<br>
management.endpoint.health.roles = ＃用于确定是否授权用户显示详细信息的角色。为空时，所有经过身份验证的用户都被授权。<br>
management.endpoint.health.show-details = never ＃何时显示完整的健康详细信息。</p>
<p>#HEAP DUMP ENDPOINT（HeapDumpWebEndpoint）<br>
management.endpoint.heapdump.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.heapdump.enabled = true ＃是否启用heapdump端点。</p>
<p>#HTTP TRACE ENDPOINT（HttpTraceEndpoint）<br>
management.endpoint.httptrace.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.httptrace.enabled = true ＃是否启用httptrace端点。</p>
<p>#INFO ENDPOINT（InfoEndpoint）<br>
info = ＃要添加到信息端点的任意属性。<br>
management.endpoint.info.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.info.enabled = true ＃是否启用信息端点。</p>
<p>#INTEGRATION GRAPH ENDPOINT（IntegrationGraphEndpoint）<br>
management.endpoint.integrationgraph.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.integrationgraph.enabled = true ＃是否启用集成图终结点。</p>
<p>#JOLOKIA ENDPOINT（JolokiaProperties）<br>
management.endpoint.jolokia.config。* = ＃Jolokia设置。有关更多详细信息，请参阅Jolokia的文档。<br>
management.endpoint.jolokia.enabled = true ＃是否启用jolokia端点。</p>
<p>#LIQUIBASE ENDPOINT（LiquibaseEndpoint）<br>
management.endpoint.liquibase.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.liquibase.enabled = true ＃是否启用liquibase端点。</p>
<p>#log FILE ENDPOINT（＃LOG LogFileWebEndpoint，LogFileWebEndpointProperties）<br>
management.endpoint.logfile.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.logfile.enabled = true ＃是否启用日志文件端点。<br>
management.endpoint.logfile.external-file = ＃要访问的外部日志文件。如果日志文件由输出重定向而不是日志记录系统本身写入，则可以使用。</p>
<p>＃LOGGERS ENDPOINT（LoggersEndpoint）<br>
management.endpoint.loggers.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.loggers.enabled = true ＃是否启用记录器端点。</p>
<p>#REQUEST MAPPING ENDPOINT（MappingsEndpoint）<br>
management.endpoint.mappings.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.mappings.enabled = true ＃是否启用映射端点。</p>
<p>#METRICS ENDPOINT（MetricsEndpoint）<br>
management.endpoint.metrics.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.metrics.enabled = true ＃是否启用指标端点。</p>
<p>#PROMETHEUS ENDPOINT（PrometheusScrapeEndpoint）<br>
management.endpoint.prometheus.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.prometheus.enabled = true ＃是否启用prometheus端点。</p>
<p>#STEEDEDED TASKS ENDPOINT（ScheduledTasksEndpoint）<br>
management.endpoint.scheduledtasks.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.scheduledtasks.enabled = true ＃是否启用scheduledtasks端点。</p>
<p>#SESSIONS ENDPOINT（SessionsEndpoint）<br>
management.endpoint.sessions.enabled = true ＃是否启用会话端点。</p>
<p>#SHUTDOWN ENDPOINT（ShutdownEndpoint）<br>
management.endpoint.shutdown.enabled = false ＃是否启用关闭端点。</p>
<p>#THREAD DUMP ENDPOINT（ThreadDumpEndpoint）<br>
management.endpoint.threaddump.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.threaddump.enabled = true ＃是否启用threaddump端点。</p>
<p>＃HEALTH INDICATORS<br>
management.health.db.enabled = true ＃是否启用数据库运行状况检查。<br>
management.health.cassandra.enabled = true ＃是否启用Cassandra运行状况检查。<br>
management.health.couchbase.enabled = true ＃是否启用Couchbase运行状况检查。<br>
management.health.defaults.enabled = true ＃是否启用默认健康指标。<br>
management.health.diskspace.enabled = true ＃是否启用磁盘空间运行状况检查。<br>
management.health.diskspace.path = ＃用于计算可用磁盘空间的路径。<br>
management.health.diskspace.threshold = 10MB＃应该可用的最小磁盘空间。<br>
management.health.elasticsearch.enabled = true ＃是否启用Elasticsearch运行状况检查。<br>
management.health.elasticsearch.indices = ＃逗号分隔的索引名称。<br>
management.health.elasticsearch.response-timeout = 100ms ＃等待集群响应的时间。<br>
management.health.influxdb.enabled = true ＃是否启用InfluxDB运行状况检查。<br>
management.health.jms.enabled = true ＃是否启用JMS运行状况检查。<br>
management.health.ldap.enabled = true ＃是否启用LDAP运行状况检查。<br>
management.health.mail.enabled = true＃是否启用邮件健康检查。<br>
management.health.mongo.enabled = true ＃是否启用MongoDB运行状况检查。<br>
management.health.neo4j.enabled = true ＃是否启用Neo4j运行状况检查。<br>
management.health.rabbit.enabled = true ＃是否启用RabbitMQ运行状况检查。<br>
management.health.redis.enabled = true ＃是否启用Redis运行状况检查。<br>
management.health.solr.enabled = true ＃是否启用Solr运行状况检查。<br>
management.health.status.http-mapping = ＃将健康状态映射到HTTP状态代码。默认情况下，已注册的运行状况映射到合理的默认值（例如，UP映射到200）。<br>
management.health.status.order = DOWN，OUT_OF_SERVICE，UP，UNKNOWN ＃以逗号分隔的健康状态列表，按严重程度排序。</p>
<p>#HTTP TRACING（HttpTraceProperties）<br>
management.trace.http.enabled = true ＃是否启用HTTP请求 - 响应跟踪。<br>
management.trace.http.include =请求标头，响应标头，cookie，错误＃要包含在跟踪中的项目。</p>
<p>#INFO CONTRIBUTORS（InfoContributorProperties）<br>
management.info.build.enabled = true ＃是否启用构建信息。<br>
management.info.defaults.enabled = true ＃是否启用默认信息贡献者。<br>
management.info.env.enabled = true ＃是否启用环境信息。<br>
management.info.git.enabled = true ＃是否启用git信息。<br>
management.info.git.mode = simple ＃用于公开git信息的模式。</p>
<p>#METRICS<br>
management.metrics.distribution.maximum-expected-value。* = ＃预计将以指定名称开始计量ID的最大值。<br>
management.metrics.distribution.minimum-expected-value。* = ＃预计将以指定名称开始的仪表ID的最小值。<br>
management.metrics.distribution.percentiles。* = ＃特定计算的非可聚合百分位数，用于以指定名称开始的仪表ID发送到后端。<br>
＃以指定名称开头的仪表ID的特定SLA边界。最长的比赛获胜。management.metrics.enable。* =management.metrics.distribution.percentiles-histogram。* = ＃是否以指定名称开头的米ID应发布百分位直方图。<br>
management.metrics.distribution.sla。* =<br>
＃是否应启用以指定名称开头的仪表ID。最长的匹配获胜，关键的“all”也可以用于配置所有的米。<br>
management.metrics.export.appoptics.api-token = #AppOptics API令牌。<br>
management.metrics.export.appoptics.batch-size = 500 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.appoptics.connect-timeout = 5s ＃对此后端的请求的连接超时。<br>
management.metrics.export.appoptics.enabled= true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.appoptics.host-tag = instance ＃将指标发送到AppOptics时将映射到“@host”的标记。<br>
management.metrics.export.appoptics.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.appoptics.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.appoptics.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.appoptics.uri = https://api.appoptics.com/v1/measurements# 将指标发送到的URI。<br>
management.metrics.export.atlas.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.atlas.config-refresh-frequency = 10s ＃从LWC服务刷新配置设置的频率。<br>
management.metrics.export.atlas.config-time-to-live = 150s #LWC服务订阅的生存时间。<br>
management.metrics.export.atlas.config-uri = http：// localhost：7101 / lwc / api / v1 / expressions / local-dev #Atlas LWC端点的URI，用于检索当前订阅。<br>
management.metrics.export.atlas.connect-timeout = 1s＃对此后端的请求的连接超时。<br>
management.metrics.export.atlas.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.atlas.eval-uri = http：// localhost：7101 / lwc / api / v1 / evaluate ＃用于评估订阅数据的Atlas LWC端点的URI。<br>
management.metrics.export.atlas.lwc-enabled = false ＃是否启用流式传输到Atlas LWC。<br>
management.metrics.export.atlas.meter-time-to-live = 15m ＃没有任何活动的米的生存时间。在此期限之后，仪表将被视为已过期且不会报告。<br>
management.metrics.export.atlas.num-threads = 2＃指标发布计划程序使用的线程数。<br>
management.metrics.export.atlas.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.atlas.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.atlas.uri = http：// localhost：7101 / api / v1 / publish #Atlas服务器的URI。<br>
management.metrics.export.datadog.api-key = ＃Datadog API密钥。<br>
management.metrics.export.datadog.application-key = ＃Datadog应用程序密钥。不是严格要求，但通过向Datadog发送仪表描述，类型和基本单位来改进Datadog体验。<br>
management.metrics.export.datadog.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.datadog.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.datadog.descriptions = true ＃是否将描述元数据发布到Datadog。将其关闭以最小化发送的元数据量。<br>
management.metrics.export.datadog.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.datadog.host-tag = instance＃将指标发送到Datadog时将映射到“主机”的标记。<br>
management.metrics.export.datadog.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.datadog.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.datadog.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.datadog.uri = https://app.datadoghq.com#management.metrics.export.dynatrace.api-token =#idex将指标发送到。如果需要将指标发布到到Datadog的内部代理，则可以使用此方法定义代理的位置。<br>
#Dynatrace身份验证令牌。<br>
management.metrics.export.dynatrace.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.dynatrace.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.dynatrace.device-id = 将度量标准导出到Dynatrace的自定义设备的ID。<br>
management.metrics.export.dynatrace.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.dynatrace.num-threads = 2＃指标发布计划程序使用的线程数。<br>
management.metrics.export.dynatrace.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.dynatrace.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.dynatrace.technology-type = java ＃导出的指标的技术类型。用于在Dynatrace UI中对逻辑技术名称下的度量标准进行分组。<br>
management.metrics.export.dynatrace.uri = 将指标发送到的URI。应该用于SaaS，自我管理的实例或通过内部代理途径。<br>
management.metrics.export.elastic.auto-create-index = true＃是否自动创建索引（如果不存在）。<br>
management.metrics.export.elastic.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.elastic.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.elastic.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.elastic.host = http：// localhost：9200 ＃将指标导出到的主机。<br>
management.metrics.export.elastic.index = metrics ＃将指标导出到的索引。<br>
management.metrics.export.elastic.index-date-format＃时间戳字段的名称。= yyyy-MM ＃用于滚动索引的索引日期格式。附加到索引名称后面加一个' - '。<br>
management.metrics.export.elastic.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.elastic.password = ＃弹性服务器的登录密码。<br>
management.metrics.export.elastic.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.elastic.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.elastic.timestamp-field-name = @timestamp management.metrics.export.elastic.user-name =<br>
＃弹性服务器的登录用户。<br>
management.metrics.export.ganglia.addressing-mode = multicast ＃UDP寻址模式，单播或多播。<br>
management.metrics.export.ganglia.duration- units =毫秒＃用于报告持续时间的基本时间单位。<br>
management.metrics.export.ganglia.enabled = true ＃是否启用向Ganglia导出指标。<br>
management.metrics.export.ganglia.host = localhost ＃Ganglia服务器的主机，用于接收导出的指标。<br>
management.metrics.export.ganglia.port = 8649 ＃Ganglia服务器端口，用于接收导出的指标。<br>
management.metrics.export.ganglia.protocol-version = 3.1 ＃Ganglia协议版本。必须是3.1或3.0。<br>
management.metrics.export.ganglia.rate- units = seconds ＃用于报告费率的基本时间单位。<br>
management.metrics.export.ganglia.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.ganglia.time-to-live = 1 ＃生活在Ganglia上的指标的时间。将多播生存时间设置为大于主机之间的跳数（路由器）的数量。<br>
management.metrics.export.graphite.duration-units =毫秒＃用于报告持续时间的基本时间单位。<br>
management.metrics.export.graphite.enabled = true＃是否启用将指标导出到Graphite。<br>
management.metrics.export.graphite.host = localhost ＃Graphite服务器的主机，用于接收导出的指标。<br>
management.metrics.export.graphite.port = 2004 ＃Graphite服务器的端口，用于接收导出的指标。<br>
management.metrics.export.graphite.protocol = pickled ＃在将数据发送到Graphite时使用的协议。<br>
management.metrics.export.graphite.rate-units = seconds ＃用于报告费率的基本时间单位。<br>
management.metrics.export.graphite.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.graphite.tags-as-prefix =＃对于默认命名约定，将指定的标记键转换为度量标准前缀的一部分。<br>
management.metrics.export.humio.api-token = ＃Humio API令牌。<br>
management.metrics.export.humio.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.humio.connect-timeout = 5s ＃对此后端的请求的连接超时。<br>
management.metrics.export.humio.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.humio.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.humio.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.humio.repository = sandbox ＃要将指标发布到的存储库的名称。<br>
management.metrics.export.humio.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.humio.tags。* = ＃Humio标签，用于描述将存储指标的数据源。Humio标签是与Micrometer标签不同的概念。千分尺的标签用于沿尺寸边界划分度量。<br>
management.metrics.export.humio.uri = https://cloud.humio.com#idex将指标发送到。如果您需要将指标发布到Humio的内部代理，您可以使用此方法定义代理的位置。<br>
management.metrics.export.influx.auto-create-db = true ＃在尝试向其发布指标之前，是否创建Influx数据库是否存在。<br>
management.metrics.export.influx.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.influx.compressed = true ＃是否对发布到Influx的度量批次启用GZIP压缩。<br>
management.metrics.export.influx.connect-timeout = 1s＃对此后端的请求的连接超时。<br>
management.metrics.export.influx.consistency = one ＃为每个点写一致性。<br>
management.metrics.export.influx.db = mydb ＃将指标发送到Influx时将映射到“主机”的标记。<br>
management.metrics.export.influx.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.influx.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.influx.password = ＃Influx服务器的登录密码。<br>
management.metrics.export.influx.read-timeout = 10s＃读取此后端请求的超时时间。<br>
management.metrics.export.influx.retention-duration = ＃Influx应在当前数据库中保留数据的时间段。<br>
management.metrics.export.influx.retention-shard-duration = ＃分片组覆盖的时间范围。<br>
management.metrics.export.influx.retention-policy = ＃要使用的保留策略（如果未指定，则Influx写入DEFAULT保留策略）。<br>
management.metrics.export.influx.retention-replication-factor = ＃在群集中存储了多少份数据副本。<br>
management.metrics.export.influx.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.influx.uri = http：// localhost：8086 ＃Influx服务器的URI。<br>
management.metrics.export.influx.user-name = ＃Influx服务器的登录用户。<br>
management.metrics.export.jmx.domain = metrics ＃Metrics JMX域名。<br>
management.metrics.export.jmx.enabled = true ＃是否已启用将度量标准导出到JMX。<br>
management.metrics.export.jmx.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.kairos.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.kairos.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.kairos.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.kairos.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.kairos.password = #KairosDB服务器的登录密码。<br>
management.metrics.export.kairos.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.kairos.step = 1m＃要使用的步长（即报告频率）。<br>
management.metrics.export.kairos.uri = localhost：8080 / api / v1 /  datapoints #KairosDB服务器的URI。<br>
management.metrics.export.kairos.user-name = #KairosDB服务器的登录用户。<br>
management.metrics.export.newrelic.account-id = ＃新Relic帐户ID。<br>
management.metrics.export.newrelic.api-key = #New Relic API密钥。<br>
management.metrics.export.newrelic.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.newrelic.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.newrelic.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.newrelic.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.newrelic.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.newrelic.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.newrelic.uri = https：//insights-collector.newrelic.com #idex 将指标发送到。<br>
management.metrics.export.prometheus.descriptions = true＃是否将发布描述作为scrape有效负载的一部分启用到Prometheus。将其关闭以最小化每次刮擦发送的数据量。<br>
management.metrics.export.prometheus.enabled = true ＃是否启用将指标导出到Prometheus。<br>
management.metrics.export.prometheus.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.prometheus.pushgateway.base-url = localhost：9091 ＃Pushgateway的基本URL。<br>
management.metrics.export.prometheus.pushgateway.enabled = false ＃通过Prometheus Pushgateway启用发布。<br>
management.metrics.export.prometheus.pushgateway.grouping-key =＃为推送的指标分组键。<br>
management.metrics.export.prometheus.pushgateway.job = ＃此应用程序实例的作业标识符。<br>
management.metrics.export.prometheus.pushgateway.push-rate = 1m ＃用于推送指标的频率。<br>
management.metrics.export.prometheus.pushgateway.shutdown-operation = ＃应该在关机时执行的操作。<br>
management.metrics.export.signalfx.access-token = #SignalFX访问令牌。<br>
management.metrics.export.signalfx.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.signalfx.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.signalfx.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.signalfx.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.signalfx.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.signalfx.source = ＃唯一标识正在向SignalFx发布指标的应用实例。默认为本地主机名。<br>
management.metrics.export.signalfx.step = 10s＃步骤大小（即报告频率）使用。<br>
management.metrics.export.signalfx.uri = https：//ingest.signalfx.com# 将指标发送到的URI。<br>
management.metrics.export.simple.enabled = true ＃在没有任何其他导出器的情况下，是否启用将指标导出到内存后端。<br>
management.metrics.export.simple.mode =累积＃计数模式。<br>
management.metrics.export.simple.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.statsd.enabled = true ＃是否启用将度量标准导出到StatsD。<br>
management.metrics.export.statsd.flavor = datadog#StatsD线路协议使用。<br>
management.metrics.export.statsd.host = localhost ＃StatsD服务器的主机，用于接收导出的指标。<br>
management.metrics.export.statsd.max-packet-length = 1400 ＃单个有效负载的总长度应保持在网络的MTU中。<br>
management.metrics.export.statsd.polling-frequency = 10s ＃测量仪表<br>
的频率。轮询仪表时，会重新计算其值，如果值已更改（或者publishUnchangedMeters为true），则会将其发送到StatsD服务器。management.metrics.export.statsd.port = 8125 ＃StatsD服务器的端口，用于接收导出的指标。<br>
management.metrics.export.statsd.publish-不变米= true ＃是否将未更改的计量表发送到StatsD服务器。<br>
management.metrics.export.wavefront.api-token = ＃将指标直接发布到Wavefront API主机时使用的API令牌。<br>
management.metrics.export.wavefront.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.wavefront.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.wavefront.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.wavefront.global-prefix =＃全局前缀用于将源自此应用程序的白盒工具的度量标准与在Wavefront UI中查看时源自其他Wavefront集成的度量标准分开。<br>
management.metrics.export.wavefront.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.wavefront.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.wavefront.source = ＃应用程序实例的唯一标识符，该实例是发布到Wavefront的度量标准的来源。默认为本地主机名。<br>
management.metrics.export.wavefront.step = 10s ＃要使用的步长（即报告频率）。<br>
management.metrics.export.wavefront.uri = https://longboard.wavefront.com# 将指标发送到的URI。<br>
management.metrics.use-global-registry = true ＃是否应将自动配置的MeterRegistry实现绑定到Metrics上的全局静态注册表。<br>
management.metrics.tags。* = ＃应用于每个仪表的公共标签。<br>
management.metrics.web.client.max-uri-tags = 100 ＃允许的唯一URI标记值的最大数量。达到最大标记值数后，过滤器将拒绝具有其他标记值的度量标准。<br>
management.metrics.web.client.requests-metric-name = http.client.requests ＃已发送请求的度量标准的名称。<br>
management.metrics.web.server.auto-time-requests = true ＃是否应自动为Spring MVC，WebFlux或Jersey处理的请求定时。<br>
management.metrics.web.server.max-uri-tags = 100 ＃允许的唯一URI标记值的最大数量。达到最大标记值数后，过滤器将拒绝具有其他标记值的度量标准。<br>
management.metrics.web.server.requests-metric-name = http.server.requests ＃已接收请求的度量标准的名称。<br>
＃----------------------------------------<br>
#DEDTOOLS PROPERTIES<br>
＃----- -----------------------------------<br>
#DESTOOLS（DevToolsProperties）<br>
spring.devtools.add-properties = true ＃是否启用开发属性默认值。<br>
spring.devtools.livereload.enabled = true ＃是否启用livereload.com兼容服务器。<br>
spring.devtools.livereload.port = 35729 ＃服务器端口。<br>
spring.devtools.restart.additional-exclude = ＃应该从触发完全重启中排除的其他模式。<br>
spring.devtools.restart.additional-paths = ＃要监视更改的其他路径。<br>
spring.devtools.restart.enabled = true ＃是否启用自动重启。<br>
spring.devtools.restart.exclude= META-INF /行家/ **，META-INF /资源/ **，资源/ **，静态/ **，公共/ *<em>，模板/ <strong>，</strong> / <em>的Test.class，</em></em> / * Tests.class，git.properties，META-INF / build-info.properties ＃应该从触发完全重启中排除的模式。<br>
spring.devtools.restart.log-condition-evaluation-delta = true ＃是否在重新启动时记录条件评估增量。<br>
spring.devtools.restart.poll-interval = 1s ＃轮询类路径更改之间等待的时间。<br>
spring.devtools.restart.quiet-period = 400ms ＃触发重启之前没有任何类路径更改所需的安静时间量。<br>
spring.devtools.restart.trigger-file =＃特定文件的名称，当更改时，触发重新启动检查。如果未指定，则任何类路径文件更改都会触发重新启动。<br>
#remote DEVTOOLS（RemoteDevToolsProperties）<br>
spring.devtools.remote.context-path = /。~~ spring-boot！〜＃用于处理远程连接的上下文路径。<br>
spring.devtools.remote.proxy.host = ＃用于连接远程应用程序的代理主机。<br>
spring.devtools.remote.proxy.port = ＃用于连接远程应用程序的代理端口。<br>
spring.devtools.remote.restart.enabled = true ＃是否启用远程重启。<br>
spring.devtools.remote.secret = ＃建立连接所需的共享密钥（启用远程支持所需）。<br>
spring.devtools.remote.secret头名= X-AUTH-TOKEN ＃用于传输共享密钥的HTTP头。<br>
＃----------------------------------------<br>
#TESTING PROPERTIES<br>
＃----- -----------------------------------<br>
spring.test.database.replace = any ＃要替换的现有DataSource的类型。<br>
spring.test.mockmvc.print =默认#MVC 打印选项。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务的数据库设计]]></title>
        <id>https://cm940324.github.io/post/weifuwu-sheji/</id>
        <link href="https://cm940324.github.io/post/weifuwu-sheji/">
        </link>
        <updated>2021-06-17T05:19:26.000Z</updated>
        <content type="html"><![CDATA[<h3 id="单独的数据库">单独的数据库：</h3>
<p>微服务设计的一个关键是数据库设计，基本原则是每个服务都有自己单独的数据库，而且只有微服务本身可以访问这个数据库。它是基于下面三个原因。</p>
<p><strong>优化服务接口</strong>：微服务之间的接口越小越好，最好只有服务调用接口（RPC或消息），没有其他接口。如果微服务不能独享自己的数据库，那么数据库也变成了接口的一部分，这大大拓展了接口范围。</p>
<p><strong>错误诊断</strong>：生产环境中的错误大部分都是和数据库有关的，要么是数据出了问题，要么是数据库的使用方式出了问题。当你不能完全控制数据库的访问时，会有各种各样的错误发生。它可能是别的程序直接连到你的数据库或者是其他部门直接用客户端访问数据库的数据，而这些都是在程序中查不到的，增加了错误排查难度。如果是程序中的问题，只要修改了代码，那么这个错误就不会再有。而上面提到的错误，你永远都没法预测它们什么时候还会再次发生。</p>
<p><strong>性能调优</strong>：性能调优也是一样，你需要对数据库有全权控制才能保证它的性能。如果其他部门一定要访问数据库，而且只是查询的话，那么可以另外创建一份只读数据库，让他们在另一个库中查询，这样才不会影响到你的库。</p>
<p>理想的设计是你的数据库只有你的服务能访问，你也只调用自己数据库中的数据，所有对别的微服务的访问都通过服务调用来实现（请参阅<a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">“微服务之间调用的最佳设计“</a>）。当然，在实际应用中，单纯的服务调用可能不能满足性能或其他要求，不同的微服务都多少需要共享一些数据。</p>
<h3 id="共享数据">共享数据：</h3>
<p>微服务之间的数据共享可以有下四种方式。</p>
<h4 id="静态表">静态表：</h4>
<p>有一些静态的数据库表，例如国家，可能会被很多程序用到，而且程序内部需要对国家这个表做连接（join）生成最终用户展示数据，这样用微服务调用的方式就效率不高，影响性能。一个办法是在每个微服务中配置一个这样的表，它是只读的，这样就可以做数据库连接了。当然你需要保证数据同步。这个方案在多数情况下都是可以接受的，因为以下两点：</p>
<ol>
<li>静态的数据库表结构基本不变：因为一旦表结构变了，你不但要更改所有微服务的数据库表，还要修改所有微服务的程序。</li>
<li>数据库表中的数据变化不频繁：这样数据同步的工作量不大。另外当你同步数据库时总会有延迟，如果数据变化不频繁那么你有很多同步方式可供选择。</li>
</ol>
<h4 id="只读业务数据访问">只读业务数据访问：</h4>
<p>如果你需要读取别的数据库里的动态业务数据， 理想的方式是服务调用。如果你只是调用其他微服务做一些计算，一般情况下性能都是可以接受的。如果你需要做数据的连接，那么你可以用程序代码来做，而不是用SQL语句。如果测试之后性能不能满足要求，那你可以考虑在自己的数据库里建一套只读数据表。数据同步方式大致有两种。如果是事件驱动方式，就用发消息的方式进行同步，如果是RPC方式，就用数据库本身提供的同步方式或者第三方同步软件。<br>
通常情况下，你可能只需要其他数据库的几张表，每张表只需要几个字段。这时，其他数据库是数据的最终来源，控制所有写操作以及相应的业务验证逻辑，我们叫它主表。你的只读库可以叫从表。 当一条数据写入主表后，会发一条广播消息，所有拥有从表的微服务监听消息并更新只读表中的数据。但这时你要特别小心，因为它的危险性要比静态表大得多。第一它的表结构变更会更频繁，而且它的变更完全不受你控制。第二业务数据不像静态表，它是经常更新的，这样对数据同步的要求就比较高。要根据具体的业务需求来决定多大的延迟是可以接受的。<br>
另外它还有两个问题：</p>
<ol>
<li><strong>数据的容量</strong>：数据库中的数据量是影响性能的主要因素。因为这个数据是外来的，不利于掌握它的流量规律，很难进行容量规划，也不能更好地进行性能调优。</li>
<li><strong>接口外泄</strong>: 微服务之间的接口本来只有服务调用接口，这时你可以对内部程序和数据库做任何更改，而不影响其他服务。现在数据库表结构也变成了接口的一部分。接口一旦发布之后，基本是不能更改的，这大大限制了你的灵活性。幸运的是因为另外建了一套表，有了一个缓冲，当主表修改时，从表也许不需要同步更新。</li>
</ol>
<p>除非你能用服务调用（没有本地只读数据库）的方式完成所有功能，不然不管你是用RPC方式还是事件驱动方式进行微服务集成，上面提到的问题都是不可避免的。但是你可以通过合理规划数据库更改，来减少上面问题带来的影响，下面将会详细讲解。</p>
<h4 id="读写业务数据访问">读写业务数据访问：</h4>
<p>这是最复杂的一种情况。一般情况下，你有一个表是主表，而其他表是从表。主表包含主要信息，而且这些主要信息被复制到从表，但微服务会有额外字段需要写入从表。这样本地微服务对从表就既有读也有写的操作。而且主表和从表有一个先后次序的关系。从表的主键来源于主表，因此一定先有主表，再有从表。</p>
<p>假设我们有两个与电影有关的微服务，一个是电影论坛，用户可以发表对电影的评论。另一个是电影商店。“movie”是共享表，左边的一个是电影论坛库，它的“movie”表是主表。右边的是电影商店库，它的“movie”表是从表。它们共享“id”字段（主键）。主表是数据的主要来源，但从表里的“quantity”和“price”字段主表里面没有。主表插入数据后，发消息，从表接到消息，插入一条数据到本地“movie”表。并且从表还会修改表里的“quantity”和“price”字段。在这种情况下，要给每一个字段分配一个唯一源头（微服务），只有源头才有权利主动更改字段，其他微服务只能被动更改（接收源头发出的更改消息之后再改）。在本例子中， “quantity”和“price”字段的源头是右边的表，其他的字段的源头都是左边的表。本例子中“quantity”和“price”只在从表中存在，因此数据写入是单向的，方向是主表到从表。如果主表也需要这些字段，那么它们还要被回写，那数据写入就变成双向的。</p>
<h4 id="直接访问其它数据库">直接访问其它数据库：</h4>
<p>这种方式是要绝对禁止的。生产环境中的许多程序错误和性能问题都是由这种方式产生的。上面的三种方式由于是另外新建了本地只读数据库表，产生了数据库的物理隔离，这样一个数据库的性能问题不会影响到另一个。另外，当主库中的表结构更改时，你可以暂时保持从库中的表不变，这样程序还可以运行。如果直接访问别人的库，主库一修改，别的微服务程序马上就会报错。请参阅ApplicationDatabase。</p>
<h3 id="向后兼容的数据库更新">向后兼容的数据库更新：</h3>
<p>从上面的论述可以看出，数据库表结构的修改是一个影响范围很广的事情。在微服务架构中，共享的表在别的服务中也会有一个只读的拷贝。现在当你要更改表结构时，还需要考虑到对别的微服务的影响。当在单体（Monolithic）架构中，为了保证程序部署能够回滚，数据库的更新是向后兼容的。需要兼容性的另一个原因是支持蓝绿发布（Blue-Green Deployment）。在这种部署方式中，你同时拥有新旧版本的代码，由负载均衡来决定每一个请求指向那个版本。它们可以共享一个数据库（这就要求数据库是向后兼容的），也可以使用不同的数据。数据库的更新简单来讲有以下几种类型：<br>
<strong>增加表或字段</strong>：如果字段可取空值，这个操作是向后兼容的。如果是非空值就要插入一个缺省值。</p>
<p><strong>删除表或字段</strong>：可先暂时保留被删除表或字段，经过几个版本之后再删除。</p>
<p><strong>修改字段名</strong>：新增加一个字段，把数据从旧字段拷贝到新字段，用数据库触发器（或程序）同步旧字段和新字段（供过渡时期使用）。 然后再在几个版本之后把原来的字段删除（请参阅<a href="https://thoughts-on-java.org/update-database-schema-without-downtime/">Update your Database Schema Without Downtime</a>）。</p>
<p><strong>修改表名</strong>：如果数据库支持可更新视图，最简单的办法是先修改表的名字，然后创建一个可更新视图指向原来的表（请参阅<a href="https://martinfowler.com/articles/evodb.html">Evolutionary Database Design</a> ）。如果数据库不支持可更新视图，使用的方法与修改字段名相似，需要创建新的表并做数据同步。</p>
<p><strong>修改字段类型</strong>：与修改字段名几乎相同，只是在拷贝数据时，需要做数据类型转换。</p>
<p>向后兼容的数据库更新的好处是，当程序部署出现问题时，如需进行回滚。只要回滚程序就行了，而不必回滚数据库。回滚时一般只回滚一个版本。凡是需要删除的表或字段在本次部署时都不做修改，等到一个或几个版本之后，确认没有问题了再删除。它的另一个好处就是不会对其他微服务中的共享表产生立刻的直接影响。当本微服务升级后，其他微服务可以评估这些数据库更新带来的影响再决定是否需要做相应的程序或数据库修改。</p>
<h3 id="跨服务事物">跨服务事物：</h3>
<p>微服务的一个难点是如何实现跨服务的事物支持。两阶段提交（Two-Phase Commit）已被证明性能上不能满足需求，现在基本上没有人用。被一致认可的方法叫Saga。它的原理是为事物中的每个操作写一个补偿操作（Compensating Transaction），然后在回滚阶段挨个执行每一个补偿操作。示例如下图，在一个事物中共有3个操作T1，T2，T3。每一个操作要定义一个补偿操作，C1，C2，C3。事物执行时是按照正向顺序先执行T1，当回滚时是按照反向顺序先执行C3。 事物中的每一个操作（正向操作和补偿操作）都被包装成一个命令（Command），Saga执行协调器（Saga Execution Coordinator (SEC)）负责执行所有命令。在执行之前，所有的命令都会按顺序被存入日志中，然后Saga执行协调器从日志中取出命令，依次执行。当某个执行出现错误时，这个错误也被写入日志，并且所有正在执行的命令被停止，开始回滚操作。</p>
<p>Saga放松了对一致性（Consistency）的要求，它能保证的是最终一致性（Eventual Consistency），因此在事物执行过程中数据是不一致的，并且这种不一致会被别的进程看到。在生活中，大多数情况下，我们对一致性的要求并没有那么高，短暂的不一致性是可以接收的。例如银行的转账操作，它们在执行过程中都不是在一个数据库事物里执行的，而是用记账的方式分成两个动作来执行，保证的也是最终一致性。</p>
<p>Saga的原理看起来很简单，但要想正确的实施还是有一定难度的。它的核心问题在于对错误的处理，要把它完全讲明白需要另写一遍文章，我现在只讲一下要点。网络环境是不可靠的，正在执行的命令可能很长时间都没有返回结果，这时，第一，你要设定一个超时。第二，因为你不知道没有返回值的原因是，已经完成了命令但网络出了问题，还是没完成就牺牲了，因此不知道是否要执行补偿操作。这时正确的做法是重试原命令，直到得到完成确认，然后再执行补偿操作。但这对命令有一个要求，那就是这个操作必须是幂等的（Idempotent），也就是说它可以执行多次，但最终结果还是一样的。</p>
<p>另外，有些操作的补偿操作比较容易生成，例如付款操作，你只要把钱款退回就可以了。但有些操作，像发邮件，完成之后就没有办法回到之前的状态了，这时就只能再发一个邮件更正以前的信息。因此补偿操作不一定非要返回到原来的状态，而是抵消掉原来操作产生的效果。</p>
<h3 id="微服务的拆分">微服务的拆分：</h3>
<p>我们原来的程序大多数都是单体程序，但现在要把它拆分成微服务，应该怎样做才能降低对现有应用的影响呢？</p>
<p>假设我们要拆分出来一个微服务叫“client-service”，它需要访问“core client”表。第一步，我们先把程序从原来的代码里拆分出来，变成一个服务. 数据库不动，这个服务仍然指向原来的数据库。其他程序不再直接访问这个服务管理的表，而是通过服务调用或另建共享表来获取数据。</p>
<p>第二步，再把服务的数据库表拆分出来，这时微服务就拥有它自己的数据库了，而不再需要原来的共享数据库了。这时就成了一个真正意义上的的微服务。</p>
<p>上面只讲了拆分一个微服务，如果有多个需要拆分，则需一个一个按照上面讲的方法依次进行。</p>
<p>另外，Martin Fowler在他的文章&quot;Break Monolith into Microservices&quot;里有一个很好的建议。那就是，当你把服务从单体程序里拆分时，不要只想着把代码拆分出来。因为现在的需求可能已经跟原来有所不同，原先的设计可能也不太适用了。而且，技术也已更新，代码也要作相应的改造。更好的办法是重写原来的功能（而不是重写原来的代码），把重点放在拆分业务功能上，而不是拆分代码上，用新的设计和技术来实现这个业务功能。</p>
<h3 id="结论">结论：</h3>
<p>数据库设计是微服务设计的一个关键点，基本原则是每个微服务都有自己单独的数据库，而且只有微服务本身可以访问这个数据库。微服务之间的数据共享可以通过服务调用，或者主、从表的方式实现。在共享数据时，要找到合适的同步方式。在微服务架构中，数据库的修改影响广泛，需要保证这种修改是向后兼容的。实现跨服务事物的标准方法是Saga。当把单体程序拆分成微服务时，可以分步进行，以减少对现有程序的影响。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[两数之和]]></title>
        <id>https://cm940324.github.io/post/twonum/</id>
        <link href="https://cm940324.github.io/post/twonum/">
        </link>
        <updated>2021-06-11T01:50:16.000Z</updated>
        <content type="html"><![CDATA[<p>给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案。<br>
示例 1：<br>
//输入：nums = [2,7,11,15], target = 9<br>
//输出：[0,1]<br>
//解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。</p>
<p>// 示例 2：<br>
//输入：nums = [3,2,4], target = 6<br>
//输出：[1,2]</p>
<p>// 示例 3：</p>
<p>//输入：nums = [3,3], target = 6<br>
//输出：[0,1]<br>
// 提示：</p>
<p>// 2 &lt;= nums.length &lt;= 104<br>
// -109 &lt;= nums[i] &lt;= 109<br>
// -109 &lt;= target &lt;= 109<br>
// 只会存在一个有效答案</p>
<p>// 进阶：你可以想出一个时间复杂度小于 O(n2) 的算法吗？<br>
// Related Topics 数组 哈希表</p>
<pre><code>class Solution {
    public int[] twoSum(int[] nums, int target) {
        Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;();
        for (int i = 1; i &lt;= nums.length; i++) {
            if (map.contains(target - nums[i])){
                return new int[]{map.get(target - nums[i]),i};
            }
            map.put(map.contains(target - nums[i]), i);
        }
        return new int[0];
    }
    
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Data Rest---Paging and Sorting ]]></title>
        <id>https://cm940324.github.io/post/spring-data-rest-learn/</id>
        <link href="https://cm940324.github.io/post/spring-data-rest-learn/">
        </link>
        <updated>2021-06-10T07:11:22.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-paging">1. Paging</h3>
<p>Spring Data REST能识别含有分页和排序请求的URL，从而返回用户想要的数据，而不是直接返回一大堆数据集合。如果你继承PagingAndSortingRepository&lt;T, ID&gt;并获取实体类的列表集合，例如：</p>
<pre><code>interface PersonRepository extends PagingAndSortingRepository&lt;Person, Long&gt; {}
</code></pre>
<p>那么请求数据分页默认数为20个，也就是说第一次请求为20个数据，并带有分页的参数，如果想要自定义分页的参数，可以采用更改请求的URL参数的办法进行更改：</p>
<p><mark>http://localhost:8080/persons/?size=5</mark></p>
<p>如果要在你自己的查询方法中使用分页，需要在方法的参数中添加一个Pageable参数，这样获得的数据是一页数据(Page)而不是一个列表(List):</p>
<pre><code>@RestResource(path = &quot;nameStartsWith&quot;, rel = &quot;nameStartsWith&quot;)

public PagefindByNameStartsWith(@Param(&quot;name&quot;) String name, Pageable p);
</code></pre>
<p>这样的一个查询方法，会输出到链接：/people/search/nameStartsWith 并且会支持分页，这个原理和Spring Data Jpa的类似。</p>
<h3 id="2-previous-and-next-links">2. Previous and Next Links</h3>
<p>每个分页的response数据返回到前端页面，都有一个prev和next链接，比如在浏览器中请求 localhost:8080/people?size=5 后得到的数据如下：</p>
<pre><code>{
&quot;_links&quot; : {
	&quot;self&quot; : {
		&quot;href&quot; : &quot;http://localhost:8080/persons{&amp;sort,page,size}&quot;, 
	&quot;templated&quot; : true
	},
	&quot;next&quot; : {
		&quot;href&quot; : &quot;http://localhost:8080/persons?page=1&amp;size=5{&amp;sort}&quot;, 
		&quot;templated&quot; : true
	}
},
	&quot;_embedded&quot; : {
		... data ...
	},
	&quot;page&quot; : { ③
	&quot;size&quot; : 5,
	&lt;!-- &quot;totalElements&quot; : 50 --&gt;
	&quot;totalPages&quot; : 10,
	&quot;number&quot; : 0
}
</code></pre>
<p>这两个链接是指向下一级链接(next)和上一级(prev)的链接的地址</p>
<h3 id="3sorting">3.Sorting</h3>
<p>和Paging一样，Spring Data Rest识别含有排序的URL请求参数，实体类对应的同样有一个实体仓库。为了让数据按照自己想要的参数进行排序，可以在URL请求中添加一个name属性，并指定属性的排序方式，指定排序的方向(正向asc,逆向desc),比如：</p>
<pre><code class="language-html">http://localhost:8080/people/search/nameStartsWith?name=K&amp;sort=name,desc
</code></pre>
<p>这样一个语句是使用了定义在PersonRepository中的findByNameStartsWith查询方法进行查询所有Person的姓名中以字母K开头的并以name进行逆向排序的用户。通常为使用多个属性进行排序，往往可以添加sort=PROPERTY自己想要排序的参数进行排序。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务：服务注册发现+ API 网关+配置中心+配置中心+服务跟踪]]></title>
        <id>https://cm940324.github.io/post/weifuwu-ques/</id>
        <link href="https://cm940324.github.io/post/weifuwu-ques/">
        </link>
        <updated>2021-06-07T07:00:17.000Z</updated>
        <content type="html"><![CDATA[<p><strong>服务注册发现</strong></p>
<p>服务注册就是维护一个登记簿，它管理系统内所有的服务地址。当新的服务启动后，它会向登记簿交待自己的地址信息。服务的依赖方直接向登记簿要 Service Provider 地址就行了。当下用于服务注册的工具非常多 ZooKeeper，Consul，Etcd, 还有 Netflix 家的 eureka 等。服务注册有两种:</p>
<p><strong>形式：客户端注册和第三方注册。</strong></p>
<p><strong>客户端注册（zookeeper</strong>）<br>
客户端注册是服务自身要负责注册与注销的工作。当服务启动后向注册中心注册自身，当服务下线时注销自己。期间还需要和注册中心保持心跳。心跳不一定要客户端来做，也可以由注册中心负责（这个过程叫探活）。这种方式的缺点是注册工作与服务耦合在一起，不同语言都要实现一套注册逻辑。</p>
<p><strong>第三方注册（独立的服务 Registrar）</strong></p>
<p>第三方注册由一个独立的服务Registrar负责注册与注销。当服务启动后以某种方式通知Registrar，然后 Registrar 负责向注册中心发起注册工作。同时注册中心要维护与服务之间的心跳，当服务不可用时，向注册中心注销服务。这种方式的缺点是 Registrar 必须是一个高可用的系统则注册工作没法进展。</p>
<p><strong>客户端发现</strong></p>
<p>客户端发现是指客户端负责查询可用服务地址，以及负载均衡的工作。这种方式最方便直接，而且也方便做负载均衡。再者一旦发现某个服务不可用立即换另外一个，非常直接。缺点也在于多语言时的重复工作，每个语言实现相同的逻辑。</p>
<p><strong>服务端发现</strong></p>
<p>服务端发现需要额外的 Router 服务，请求先打到 Router，然后 Router 负责查询服务与负载均衡。这种方式虽然没有客户端发现的缺点，但是它的缺点是保证 Router 的高可用。</p>
<p><strong>API 网关</strong><br>
API Gateway 是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的<br>
Facade 模式很像。API Gateway 封装内部系统的架构，并且提供 API 给各个客户端。它还可能有其他功能，如授权、监控、负载均衡、缓存、请求分片和管理、静态响应处理等。下图展示了一个适应当前架构的 API Gateway。<br>
API Gateway 负责请求转发、合成和协议转换。所有来自客户端的请求都要先经过 API Gateway，然后路由这些请求到对应的微服务。API Gateway 将经常通过调用多个微服务来处理一个请求以及聚合多个服务的结果。它可以在 web 协议与内部使用的非 Web 友好型协议间进行转换，如HTTP 协议、WebSocket 协议。</p>
<p><strong>请求转发</strong></p>
<p>服务转发主要是对客户端的请求安装微服务的负载转发到不同的服务上</p>
<p><strong>响应合并</strong></p>
<p>把业务上需要调用多个服务接口才能完成的工作合并成一次调用对外统一提供服务。</p>
<p><strong>协议转换</strong></p>
<p>重点是支持 SOAP，JMS，Rest 间的协议转换。</p>
<p><strong>数据转换</strong></p>
<p>重点是支持 XML 和 Json 之间的报文格式转换能力（可选）</p>
<p><strong>安全认证</strong></p>
<ol>
<li>
<p>基于 Token 的客户端访问控制和安全策略</p>
</li>
<li>
<p>传输数据和报文加密，到服务端解密，需要在客户端有独立的 SDK 代理包</p>
</li>
<li>
<p>基于 Https 的传输加密，客户端和服务端数字证书支持</p>
</li>
<li>
<p>基于 OAuth2.0 的服务安全认证(授权码，客户端，密码模式等）</p>
</li>
</ol>
<p><strong>配置中心</strong><br>
配置中心一般用作系统的参数配置，它需要满足如下几个要求：高效获取、实时感知、分布式访问。</p>
<p><strong>zookeeper 配置中心</strong></p>
<p>采取数据加载到内存方式解决高效获取的问题，借助 zookeeper 的节点监听机制来实现实时感知。</p>
<p><strong>事件调度（kafka）</strong><br>
消息服务和事件的统一调度，常用用 kafka ，activemq 等。</p>
<p><strong>服务跟踪（starter-sleuth）</strong></p>
<p>随着微服务数量不断增长，需要跟踪一个请求从一个微服务到下一个微服务的传播过程， SpringCloud Sleuth 正是解决这个问题，它在日志中引入唯一 ID，以保证微服务调用之间的一致性，这样你就能跟踪某个请求是如何从一个微服务传递到下一个。</p>
<ol>
<li>
<p>为了实现请求跟踪，当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求创建一个唯一的跟踪标识，同时在分布式系统内部流转的时候，框架始终保持传递该唯一标识，直到返回给请求方为止，这个唯一标识就是前文中提到的 Trace ID。通过 Trace ID 的记录，我们就能将所有请求过程日志关联起来。</p>
</li>
<li>
<p>为了统计各处理单元的时间延迟，当请求达到各个服务组件时，或是处理逻辑到达某个状态时，也通过一个唯一标识来标记它的开始、具体过程以及结束，该标识就是我们前文中提到的 Span ID，对于每个 Span 来说，它必须有开始和结束两个节点，通过记录开始 Span 和结束 Span 的时间戳，就能统计出该 Span 的时间延迟，除了时间戳记录之外，它还可以包含一些其他元数据，比如：事件名称、请求信息等。</p>
</li>
<li>
<p>在快速入门示例中，我们轻松实现了日志级别的跟踪信息接入，这完全归功于spring-cloudstarter-sleuth 组件的实现。在 Spring Boot 应用中，通过在工程中引入 spring-cloud<br>
starter-sleuth 依赖之后， 它会自动的为当前应用构建起各通信通道的跟踪机制，比如：</p>
</li>
</ol>
<ul>
<li>通过诸如 RabbitMQ、Kafka（或者其他任何 Spring Cloud Stream 绑定器实现的消息<br>
中间件）传递的请求。</li>
<li>通过 Zuul 代理传递的请求。</li>
<li>通过 RestTemplate 发起的请求。</li>
</ul>
<p><strong>服务熔断（Hystrix）</strong><br>
在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。</p>
<p>熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序</p>
<p>不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费 CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作。</p>
<p><strong>Hystrix 断路器机制</strong></p>
<p>断路器很好理解, 当 Hystrix Command 请求后端服务失败数量超过一定比例(默认 50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认 5 秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况,</p>
<p>如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix 的断路器就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力。</p>
<p><strong>API 管理</strong></p>
<p>SwaggerAPI 管理工具。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[hibernate CascadeType属性说明]]></title>
        <id>https://cm940324.github.io/post/hibernate-cascadetype/</id>
        <link href="https://cm940324.github.io/post/hibernate-cascadetype/">
        </link>
        <updated>2021-06-07T06:31:17.000Z</updated>
        <content type="html"><![CDATA[<h3 id="cascade属性-指定级联操作的行为可多选">cascade属性： 指定级联操作的行为(可多选)</h3>
<ul>
<li><strong>CascadeType.PERSIST 级联新增（又称级联保存）：</strong><br>
获取A对象里也同时也重新获取最新的B时的对象。即会重新查询数据库里的最新数据，并且，只有A类新增时，会级联B对象新增。若B对象在数据库存（跟新）在则抛异常（让B变为持久态），对应EntityManager的presist方法,调用JPA规范中的persist()，不适用于Hibernate的save()方法</li>
<li><strong>CascadeType.MERGE 级联合并（又称级联更新）</strong><br>
指A类新增或者变化，会级联B对象（新增或者变化） ，对应EntityManager的merge方法，调用JPA规范中merge()时，不适用于Hibernate的update()方法</li>
<li><strong>CascadeType.REMOVE 级联删除</strong><br>
只有A类删除时，会级联删除B类,即在设置的那一端进行删除时，另一端才会级联删除，对应EntityManager的remove方法，调用JPA规范中的remove()时，适用于Hibernate的delete()方法</li>
<li><strong>CascadeType.REFRESH 级联刷新</strong><br>
获取order（一或多）对象里也同时也重新获取最新的items（多）的对象，对应EntityManager的refresh(object)，调用JPA规范中的refresh()时，适用于Hibernate的flush()方法</li>
<li><strong>CascadeType.ALL</strong><br>
包含所有持久化方法</li>
</ul>
<p><strong>综上：大多数情况用CascadeType.MERGE就能达到级联跟新又不报错，用CascadeType.ALL时要斟酌下CascadeType.REMOVE</strong></p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[PostgreSQL踩坑记录]]></title>
        <id>https://cm940324.github.io/post/postgresql-ques/</id>
        <link href="https://cm940324.github.io/post/postgresql-ques/">
        </link>
        <updated>2021-06-03T06:26:03.000Z</updated>
        <content type="html"><![CDATA[<ol>
<li>在进行数据库记录的迁移和复制数据后容易出现错误</li>
</ol>
<pre><code>DETAIL:  Key (id)=(1) already exists
</code></pre>
<p>解决方案：</p>
<pre><code>select setval('tablename_id_seq', max(id)) from tablename;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[设计模式的通俗理解]]></title>
        <id>https://cm940324.github.io/post/shejimoshi-tongsu/</id>
        <link href="https://cm940324.github.io/post/shejimoshi-tongsu/">
        </link>
        <updated>2021-05-27T00:56:09.000Z</updated>
        <content type="html"><![CDATA[<h3 id="工厂方法">工厂方法</h3>
<p>追 MM 少不了请吃饭了，麦当劳的鸡翅和肯德基的鸡翅都是 MM 爱吃的东西，虽然口味有所不同，但不管你带 MM 去麦当劳或肯德基，只管向服务员说「来四个鸡翅」就行了。麦当劳和肯德基就是生产鸡翅的 Factory 工厂模式：客户类和工厂类分开。</p>
<p>消费者任何时候需要某种产品，只需向工厂请求即可。消费者无须修改就可以接纳新产品。缺点是当产品修改时，工厂类也要做相应的修改。如：如何创建及如何向客户端提供。</p>
<h3 id="建造者模式">建造者模式</h3>
<p>MM 最爱听的就是「我爱你」这句话了，见到不同地方的 MM，要能够用她们的方言跟她说这句话哦，我有一个多种语言翻译机，上面每种语言都有一个按键，见到 MM 我只要按对应的键，它就能够用相应的语言说出「我爱你」这句话了，国外的 MM 也可以轻松搞掂，这就是我的「我爱你」builder。</p>
<p>建造模式：将产品的内部表象和产品的生成过程分割开来，从而使一个建造过程生成具有不同的内部表象的产品对象。建造模式使得产品内部表象可以独立的变化，客户不必知道产品内部组成的细节。建造模式可以强制实行一种分步骤进行的建造过程。</p>
<h3 id="抽象工厂">抽象工厂</h3>
<p>请 MM 去麦当劳吃汉堡，不同的 MM 有不同的口味，要每个都记住是一件烦人的事情，我一般采用 Factory Method 模式，带着 MM 到服务员那儿，说「要一个汉堡」，具体要什么样的汉堡呢，让 MM 直接跟服务员说就行了。</p>
<p>工厂方法模式：核心工厂类不再负责所有产品的创建，而是将具体创建的工作交给子类去做，成为一个抽象工厂角色，仅负责给出具体工厂类必须实现的接口，而不接触哪一个产品类应当被实例化这种细节。</p>
<h3 id="原型模式">原型模式</h3>
<p>跟 MM 用 QQ 聊天，一定要说些深情的话语了，我搜集了好多肉麻的情话，需要时只要 copy 出来放到 QQ 里面就行了，这就是我的情话 prototype 了。（100 块钱一份，你要不要）</p>
<p>原始模型模式：通过给出一个原型对象来指明所要创建的对象的类型，然后用复制这个原型对象的方法创建出更多同类型的对象。原始模型模式允许动态的增加或减少产品类，产品类不需要非得有任何事先确定的等级结构，原始模型模式适用于任何的等级结构。缺点是每一个类都必须配备一个克隆方法。</p>
<h3 id="单态模式">单态模式</h3>
<p>俺有 6 个漂亮的老婆，她们的老公都是我，我就是我们家里的老公 Sigleton，她们只要说道「老公」，都是指的同一个人，那就是我 (刚才做了个梦啦，哪有这么好的事)</p>
<p>单例模式：单例模式确保某一个类只有一个实例，而且自行实例化并向整个系统提供这个实例单例模式。单例模式只应在有真正的 “单一实例” 的需求时才可使用</p>
<h3 id="适配器模式">适配器模式</h3>
<p>在朋友聚会上碰到了一个美女 Sarah，从香港来的，可我不会说粤语，她不会说普通话，只好求助于我的朋友 kent 了，他作为我和 Sarah 之间的 Adapter，让我和 Sarah 可以相互交谈了 (也不知道他会不会耍我)</p>
<p>适配器（变压器）模式：把一个类的接口变换成客户端所期待的另一种接口，从而使原本因接口原因不匹配而无法一起工作的两个类能够一起工作。适配类可以根据参数返还一个合适的实例给客户端。</p>
<h3 id="桥梁模式">桥梁模式</h3>
<p>早上碰到 MM，要说早上好，晚上碰到 MM，要说晚上好；碰到 MM 穿了件新衣服，要说你的衣服好漂亮哦，碰到 MM 新做的发型，要说你的头发好漂亮哦。不要问我 “早上碰到 MM 新做了个发型怎么说” 这种问题，自己用 BRIDGE 组合一下不就行了</p>
<p>桥梁模式：将抽象化与实现化脱耦，使得二者可以独立的变化，也就是说将他们之间的强关联变成弱关联，也就是指在一个软件系统的抽象化和实现化之间使用组合 / 聚合关系而不是继承关系，从而使两者可以独立的变化。</p>
<h3 id="合成模式">合成模式</h3>
<p>Mary 今天过生日。“我过生日，你要送我一件礼物。”“嗯，好吧，去商店，你自己挑。”“这件 T 恤挺漂亮，买，这条裙子好看，买，这个包也不错，买。”“喂，买了三件了呀，我只答应送一件礼物的哦。”“什么呀，T 恤加裙子加包包，正好配成一套呀，小姐，麻烦你包起来。”“……”，MM 都会用 Composite 模式了，你会了没有？</p>
<p>合成模式：合成模式将对象组织到树结构中，可以用来描述整体与部分的关系。合成模式就是一个处理对象的树结构的模式。合成模式把部分与整体的关系用树结构表示出来。合成模式使得客户端把一个个单独的成分对象和由他们复合而成的合成对象同等看待。</p>
<h3 id="装饰模式">装饰模式</h3>
<p>Mary 过完轮到 Sarly 过生日，还是不要叫她自己挑了，不然这个月伙食费肯定玩完，拿出我去年在华山顶上照的照片，在背面写上 “最好的的礼物，就是爱你的 Fita”，再到街上礼品店买了个像框（卖礼品的 MM 也很漂亮哦），再找隔壁搞美术设计的 Mike 设计了一个漂亮的盒子装起来……，我们都是 Decorator，最终都在修饰我这个人呀，怎么样，看懂了吗？</p>
<p>装饰模式：装饰模式以对客户端透明的方式扩展对象的功能，是继承关系的一个替代方案，提供比继承更多的灵活性。动态给一个对象增加功能，这些功能可以再动态的撤消。增加由一些基本功能的排列组合而产生的非常大量的功能。</p>
<h3 id="门面模式">门面模式</h3>
<p>我有一个专业的 Nikon 相机，我就喜欢自己手动调光圈、快门，这样照出来的照片才专业，但 MM 可不懂这些，教了半天也不会。幸好相机有 Facade 设计模式，把相机调整到自动档，只要对准目标按快门就行了，一切由相机自动调整，这样 MM 也可以用这个相机给我拍张照片了。门面模式：外部与一个子系统的通信必须通过一个统一的门面对象进行。</p>
<p>门面模式提供一个高层次的接口，使得子系统更易于使用。每一个子系统只有一个门面类，而且此门面类只有一个实例，也就是说它是一个单例模式。但整个系统可以有多个门面类。</p>
<h3 id="享元模式">享元模式</h3>
<p>每天跟 MM 发短信，手指都累死了，最近买了个新手机，可以把一些常用的句子存在手机里，要用的时候，直接拿出来，在前面加上 MM 的名字就可以发送了，再不用一个字一个字敲了。共享的句子就是 Flyweight，MM 的名字就是提取出来的外部特征，根据上下文情况使用。享元模式：FLYWEIGHT 在拳击比赛中指最轻量级。</p>
<p>享元模式以共享的方式高效的支持大量的细粒度对象。享元模式能做到共享的关键是区分内蕴状态和外蕴状态。内蕴状态存储在享元内部，不会随环境的改变而有所不同。外蕴状态是随环境的改变而改变的。外蕴状态不能影响内蕴状态，它们是相互独立的。</p>
<p>将可以共享的状态和不可以共享的状态从常规类中区分开来，将不可以共享的状态从类里剔除出去。客户端不可以直接创建被共享的对象，而应当使用一个工厂对象负责创建被共享的对象。享元模式大幅度的降低内存中对象的数量。</p>
<h3 id="代理模式">代理模式</h3>
<p>跟 MM 在网上聊天，一开头总是 “hi, 你好”,“你从哪儿来呀？”“你多大了？”“身高多少呀？” 这些话，真烦人，写个程序做为我的 Proxy 吧，凡是接收到这些话都设置好了自己的回答，接收到其他的话时再通知我回答，怎么样，酷吧。</p>
<p>代理模式：代理模式给某一个对象提供一个代理对象，并由代理对象控制对源对象的引用。代理就是一个人或一个机构代表另一个人或者一个机构采取行动。某些情况下，客户不想或者不能够直接引用一个对象，代理对象可以在客户和目标对象直接起到中介的作用。</p>
<p>客户端分辨不出代理主题对象与真实主题对象。代理模式可以并不知道真正的被代理对象，而仅仅持有一个被代理对象的接口，这时候代理对象不能够创建被代理对象，被代理对象必须有系统的其他角色代为创建并传入。</p>
<h3 id="责任链模式">责任链模式</h3>
<p>晚上去上英语课，为了好开溜坐到了最后一排，哇，前面坐了好几个漂亮的 MM 哎，找张纸条，写上 “Hi, 可以做我的女朋友吗？如果不愿意请向前传”，纸条就一个接一个的传上去了，糟糕，传到第一排的 MM 把纸条传给老师了，听说是个老处女呀，快跑！</p>
<p>责任链模式：在责任链模式中，很多对象由每一个对象对其下家的引用而接起来形成一条链。请求在这个链上传递，直到链上的某一个对象决定处理此请求。客户并不知道链上的哪一个对象最终处理这个请求，系统可以在不影响客户端的情况下动态的重新组织链和分配责任。处理者有两个选择：承担责任或者把责任推给下家。一个请求可以最终不被任何接收端对象所接受。</p>
<h3 id="命令模式">命令模式</h3>
<p>俺有一个 MM 家里管得特别严，没法见面，只好借助于她弟弟在我们俩之间传送信息，她对我有什么指示，就写一张纸条让她弟弟带给我。这不，她弟弟又传送过来一个 COMMAND，为了感谢他，我请他吃了碗杂酱面，哪知道他说：“我同时给我姐姐三个男朋友送 COMMAND，就数你最小气，才请我吃面。”</p>
<p>命令模式：命令模式把一个请求或者操作封装到一个对象中。命令模式把发出命令的责任和执行命令的责任分割开，委派给不同的对象。命令模式允许请求的一方和发送的一方独立开来，使得请求的一方不必知道接收请求的一方的接口，更不必知道请求是怎么被接收，以及操作是否执行，何时被执行以及是怎么被执行的。系统支持命令的撤消。</p>
<h3 id="解释器模式">解释器模式</h3>
<p>俺有一个《泡 MM 真经》，上面有各种泡 MM 的攻略，比如说去吃西餐的步骤、去看电影的方法等等，跟 MM 约会时，只要做一个 Interpreter，照着上面的脚本执行就可以了。</p>
<p>解释器模式：给定一个语言后，解释器模式可以定义出其文法的一种表示，并同时提供一个解释器。客户端可以使用这个解释器来解释这个语言中的句子。解释器模式将描述怎样在有了一个简单的文法后，使用模式设计解释这些语句。</p>
<p>在解释器模式里面提到的语言是指任何解释器对象能够解释的任何组合。在解释器模式中需要定义一个代表文法的命令类的等级结构，也就是一系列的组合规则。每一个命令对象都有一个解释方法，代表对命令对象的解释。命令对象的等级结构中的对象的任何排列组合都是一个语言。</p>
<h3 id="迭代模式">迭代模式</h3>
<p>我爱上了 Mary，不顾一切的向她求婚。Mary：“想要我跟你结婚，得答应我的条件” 我：“什么条件我都答应，你说吧” Mary：“我看上了那个一克拉的钻石” 我：“我买，我买，还有吗？” Mary：“我看上了湖边的那栋别墅” 我：“我买，我买，还有吗？” Mary：“我看上那辆法拉利跑车” 我脑袋嗡的一声，坐在椅子上，一咬牙：“我买，我买，还有吗？”</p>
<p>迭代模式：迭代模式可以顺序访问一个聚集中的元素而不必暴露聚集的内部表象。多个对象聚在一起形成的总体称之为聚集，聚集对象是能够包容一组对象的容器对象。迭代子模式将迭代逻辑封装到一个独立的子对象中，从而与聚集本身隔开。</p>
<p>迭代模式简化了聚集的界面。每一个聚集对象都可以有一个或一个以上的迭代子对象，每一个迭代子的迭代状态可以是彼此独立的。迭代算法可以独立于聚集角色变化。</p>
<h3 id="调停者模式">调停者模式</h3>
<p>四个 MM 打麻将，相互之间谁应该给谁多少钱算不清楚了，幸亏当时我在旁边，按照各自的筹码数算钱，赚了钱的从我这里拿，赔了钱的也付给我，一切就 OK 啦，俺得到了四个 MM 的电话。调停者模式：调停者模式包装了一系列对象相互作用的方式，使得这些对象不必相互明显作用。从而使他们可以松散偶合。</p>
<p>当某些对象之间的作用发生改变时，不会立即影响其他的一些对象之间的作用。保证这些作用可以彼此独立的变化。调停者模式将多对多的相互作用转化为一对多的相互作用。调停者模式将对象的行为和协作抽象化，把对象在小尺度的行为上与其他对象的相互作用分开处理。</p>
<h3 id="备忘录模式">备忘录模式</h3>
<p>同时跟几个 MM 聊天时，一定要记清楚刚才跟 MM 说了些什么话，不然 MM 发现了会不高兴的哦，幸亏我有个备忘录，刚才与哪个 MM 说了什么话我都拷贝一份放到备忘录里面保存，这样可以随时察看以前的记录啦。</p>
<p>备忘录模式：备忘录对象是一个用来存储另外一个对象内部状态的快照的对象。备忘录模式的用意是在不破坏封装的条件下，将一个对象的状态捉住，并外部化，存储起来，从而可以在将来合适的时候把这个对象还原到存储起来的状态。</p>
<h3 id="观察者模式">观察者模式</h3>
<p>想知道咱们公司最新 MM 情报吗？加入公司的 MM 情报邮件组就行了，tom 负责搜集情报，他发现的新情报不用一个一个通知我们，直接发布给邮件组，我们作为订阅者（观察者）就可以及时收到情报啦。</p>
<p>观察者模式：观察者模式定义了一种一队多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个主题对象在状态上发生变化时，会通知所有观察者对象，使他们能够自动更新自己。</p>
<h3 id="状态模式">状态模式</h3>
<p>跟 MM 交往时，一定要注意她的状态哦，在不同的状态时她的行为会有不同，比如你约她今天晚上去看电影，对你没兴趣的 MM 就会说 “有事情啦”，对你不讨厌但还没喜欢上的 MM 就会说 “好啊，不过可以带上我同事么？”，已经喜欢上你的 MM 就会说 “几点钟？看完电影再去泡吧怎么样？”，当然你看电影过程中表现良好的话，也可以把 MM 的状态从不讨厌不喜欢变成喜欢哦。</p>
<p>状态模式：状态模式允许一个对象在其内部状态改变的时候改变行为。这个对象看上去象是改变了它的类一样。状态模式把所研究的对象的行为包装在不同的状态对象里，每一个状态对象都属于一个抽象状态类的一个子类。</p>
<p>状态模式的意图是让一个对象在其内部状态改变的时候，其行为也随之改变。状态模式需要对每一个系统可能取得的状态创立一个状态类的子类。当系统的状态变化时，系统便改变所选的子类。</p>
<h3 id="策略模式">策略模式</h3>
<p>跟不同类型的 MM 约会，要用不同的策略，有的请电影比较好，有的则去吃小吃效果不错，有的去海边浪漫最合适，单目的都是为了得到 MM 的芳心，我的追 MM 锦囊中有好多 Strategy 哦。策略模式：策略模式针对一组算法，将每一个算法封装到具有共同接口的独立的类中，从而使得它们可以相互替换。</p>
<p>策略模式使得算法可以在不影响到客户端的情况下发生变化。策略模把行为和环境分开。环境类负责维持和查询行为类，各种算法在具体的策略类中提供。由于算法和环境独立开来，算法的增减，修改都不会影响到环境和客户端</p>
<h3 id="模版方法模式">模版方法模式</h3>
<p>看过《如何说服女生上床》这部经典文章吗？女生从认识到上床的不变的步骤分为巧遇、打破僵局、展开追求、接吻、前戏、动手、爱抚、进去八大步骤 (Template method)，但每个步骤针对不同的情况，都有不一样的做法，这就要看你随机应变啦 (具体实现)；</p>
<p>模板方法模式：模板方法模式准备一个抽象类，将部分逻辑以具体方法以及具体构造子的形式实现，然后声明一些抽象方法来迫使子类实现剩余的逻辑。不同的子类可以以不同的方式实现这些抽象方法，从而对剩余的逻辑有不同的实现。先制定一个顶级逻辑框架，而将逻辑的细节留给具体的子类去实现。</p>
<h3 id="访问者模式">访问者模式</h3>
<p>情人节到了，要给每个 MM 送一束鲜花和一张卡片，可是每个 MM 送的花都要针对她个人的特点，每张卡片也要根据个人的特点来挑，我一个人哪搞得清楚，还是找花店老板和礼品店老板做一下 Visitor，让花店老板根据 MM 的特点选一束花，让礼品店老板也根据每个人特点选一张卡，这样就轻松多了；</p>
<p>访问者模式：访问者模式的目的是封装一些施加于某种数据结构元素之上的操作。一旦这些操作需要修改的话，接受这个操作的数据结构可以保持不变。访问者模式适用于数据结构相对未定的系统，它把数据结构和作用于结构上的操作之间的耦合解脱开，使得操作集合可以相对自由的演化。访问者模式使得增加新的操作变的很容易，就是增加一个新的访问者类。</p>
<p>访问者模式将有关的行为集中到一个访问者对象中，而不是分散到一个个的节点类中。当使用访问者模式时，要将尽可能多的对象浏览逻辑放在访问者类中，而不是放到它的子类中。访问者模式可以跨过几个类的等级结构访问属于不同的等级结构的成员类。</p>
]]></content>
    </entry>
</feed>