<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://cm940324.github.io</id>
    <title>Oasis</title>
    <updated>2021-08-27T14:38:46.202Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://cm940324.github.io"/>
    <link rel="self" href="https://cm940324.github.io/atom.xml"/>
    <subtitle>&lt;a href=&quot;https://cm940324.github.io/&quot; target=&quot;_blank&quot;&gt;code blog&lt;/a&gt;</subtitle>
    <logo>https://cm940324.github.io/images/avatar.png</logo>
    <icon>https://cm940324.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Oasis</rights>
    <entry>
        <title type="html"><![CDATA[Leetcode sql题每日三题]]></title>
        <id>https://cm940324.github.io/post/leetcode-sql/</id>
        <link href="https://cm940324.github.io/post/leetcode-sql/">
        </link>
        <updated>2021-08-26T00:03:11.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1">1.</h2>
<p>表1: Person</p>
<pre><code>+-------------+---------+

| 列名         | 类型     |

+-------------+---------+

| PersonId    | int     |

| FirstName   | varchar |

| LastName    | varchar |

+-------------+---------+

PersonId 是上表主键
</code></pre>
<p>表2: <code>Address</code></p>
<pre><code>+-------------+---------+
| 列名         | 类型    |
+-------------+---------+
| AddressId   | int     |
| PersonId    | int     |
| City        | varchar |
| State       | varchar |
+-------------+---------+
AddressId 是上表主键
</code></pre>
<p>编写一个 SQL 查询，满足条件：无论 person 是否有地址信息，都需要基于上述两表提供 person 的以下信息：</p>
<pre><code>FirstName, LastName, City, State
</code></pre>
<h3 id="解答">解答</h3>
<h5 id="思路">思路:</h5>
<p>根据题目要求得知,需要查询的为Person表的FirstName,LastName和Address表的City,State字段,以Person表为主表,Address表的PersonId为外键进行查询,可保证无论Address表中是否有关联的值,Person表都能展示其信息。</p>
<h5 id="答案">答案：</h5>
<p>SELECT p.FirstName,p.LastName,a.City,a.State FROM Person p left join Address a  on  p.PersonId = a.PersonId</p>
<h5 id="重点"><strong>重点：</strong></h5>
<p>连表查询中，主表的内容都会被展示</p>
<h2 id="2">2.</h2>
<p>编写一个 SQL 查询，获取 <code>Employee</code> 表中第二高的薪水（Salary） 。</p>
<pre><code>+----+--------+
| Id | Salary |
+----+--------+
| 1  | 100    |
| 2  | 200    |
| 3  | 300    |
+----+--------+
</code></pre>
<p>例如上述 <code>Employee</code> 表，SQL查询应该返回 <code>200</code> 作为第二高的薪水。如果不存在第二高的薪水，那么查询应返回 <code>null</code>。</p>
<pre><code>+---------------------+
| SecondHighestSalary |
+---------------------+
| 200                 |
+---------------------+
</code></pre>
<h3 id="解答-2">解答</h3>
<h5 id="思路-2">思路：</h5>
<p>审题发现几个本题重要的考点：</p>
<p>1.获取第二高的薪水，需要掌握orderby和limit的使用，‘第二高’ 是降序的排序方式，所以需要使用order by  。。 desc。</p>
<pre><code> 			limit y 分句表示: 读取 y 条数据
	  	limit x, y 分句表示: 跳过 x 条数据，读取 y 条数据
      limit y offset x 分句表示: 跳过 x 条数据，读取 y 条数据
      limit n 等价于 limit 0,n
</code></pre>
<p>2.其次需要考虑特殊情况，首先需要去重同样的salary，其次就是如果不存在第二高的薪水，结果应为null，可以有两种解决方式：一种是用临时表，还有一种就是使用IFNULL函数。</p>
<h5 id="答案-2">答案：</h5>
<p>select IFNULL((select distinct Salary from Employee order by Salary desc limit 1,1),null) as SecondHighestSalary;</p>
<h5 id="重点-2"><strong>重点</strong>：</h5>
<p>1.limit的使用</p>
<pre><code>	  	limit y 分句表示: 读取 y 条数据
	  	limit x, y 分句表示: 跳过 x 条数据，读取 y 条数据
      limit y offset x 分句表示: 跳过 x 条数据，读取 y 条数据
      limit n 等价于 limit 0,n
</code></pre>
<p>2.IFNULL和临时表判空的方式</p>
<h2 id="3">3.</h2>
<p>编写一个 SQL 查询，获取 <code>Employee</code> 表中第 <em>n</em> 高的薪水（Salary）。</p>
<pre><code>+----+--------+
| Id | Salary |
+----+--------+
| 1  | 100    |
| 2  | 200    |
| 3  | 300    |
+----+--------+
</code></pre>
<p>例如上述 <code>Employee</code> 表，<em>n = 2</em> 时，应返回第二高的薪水 <code>200</code>。如果不存在第 <em>n</em> 高的薪水，那么查询应返回 <code>null</code>。</p>
<pre><code>+------------------------+
| getNthHighestSalary(2) |
+------------------------+
| 200                    |
+------------------------+
</code></pre>
<h3 id="解答-3"><strong>解答</strong></h3>
<h5 id="思路-3"><strong>思路:</strong></h5>
<p>首先对存储过程的语法进行了基本的了解，题目的要求和上一题基本相同，但需要查的位置变成了变量，所以需要在limit后用变量选择跳过的个数</p>
<h5 id="答案-3"><strong>答案：</strong></h5>
<pre><code>CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT

BEGIN

  set N = N - 1;

  RETURN (

​      \# Write your MySQL query statement below.

​      SELECT IFNULl((SELECT distinct Salary from Employee order by Salary desc limit N,1),null)

  );

END
</code></pre>
<h5 id="重点-3"><strong>重点：</strong></h5>
<p>1.存储结构的基础语法</p>
<pre><code>create procedure sp_name()
begin
.........
end
</code></pre>
<p>2.limit后不能进行运算，所以应该在begin前就将需要跳过的数算好，这里需要跳过的数应为需要查到的位数-1</p>
<h2 id="4">4.</h2>
<p>编写一个 SQL 查询来实现分数排名。</p>
<p>如果两个分数相同，则两个分数排名（Rank）相同。请注意，平分后的下一个名次应该是下一个连续的整数值。换句话说，名次之间不应该有“间隔”。</p>
<pre><code>+----+-------+
| Id | Score |
+----+-------+
| 1  | 3.50  |
| 2  | 3.65  |
| 3  | 4.00  |
| 4  | 3.85  |
| 5  | 4.00  |
| 6  | 3.65  |
+----+-------+
</code></pre>
<p>例如，根据上述给定的 <code>Scores</code> 表，你的查询应该返回（按分数从高到低排列）：</p>
<pre><code>+-------+------+
| Score | Rank |
+-------+------+
| 4.00  | 1    |
| 4.00  | 1    |
| 3.85  | 2    |
| 3.65  | 3    |
| 3.65  | 3    |
| 3.50  | 4    |
+-------+------+
</code></pre>
<h3 id="解答-4"><strong>解答</strong></h3>
<h5 id="思路-4"><strong>思路:</strong></h5>
<p>回答此题的前提是需要了解sql的四大排名函数，审题得知，我们需要根据分数的大小降序排列后，对分数进行排名且名次之间无间隔，所以在四大排名函数中应选择<strong>DENSE_RANK()</strong>。</p>
<h5 id="答案-4"><strong>答案:</strong></h5>
<p>select Score,DENSE_RANK() over (order by Score DESC) 'Rank' from Scores;</p>
<h5 id="重点-4"><strong>重点:</strong></h5>
<p>1.sql的四大排名函数：</p>
<ul>
<li>​    ROW_NUMBER()      ----- 每条数据加一个序号，不适合排名，更加适合分页功能</li>
<li>​    RANK()              ---- 排名序号可重复，之后按总数算</li>
<li>​    DENSE_RANK()        ---- 排名序号可重复，之后按序号的后一个继续</li>
<li>​    NTILE()       ----将有序分区中的行分发到指定数目的组中，各个组有编号，分为几个区，一个区会有多少个。<br>
​    所以，按照题目要求，应采取DENSE_RANK()无间隔的排名函数<br>
2.对于 MySQL 解决方案，如果要转义用作列名的保留字，可以在关键字之前和之后使用撇号。例如 <code>Rank</code></li>
</ul>
<h2 id="5">5.</h2>
<p>表：<code>Logs</code></p>
<pre><code>+-------------+---------+
| Column Name | Type    |
+-------------+---------+
| id          | int     |
| num         | varchar |
+-------------+---------+
id 是这个表的主键。
</code></pre>
<p>编写一个 SQL 查询，查找所有至少连续出现三次的数字。</p>
<p>返回的结果表中的数据可以按 <strong>任意顺序</strong> 排列。</p>
<p>查询结果格式如下面的例子所示：</p>
<pre><code>Logs 表：
+----+-----+
| Id | Num |
+----+-----+
| 1  | 1   |
| 2  | 1   |
| 3  | 1   |
| 4  | 2   |
| 5  | 1   |
| 6  | 2   |
| 7  | 2   |
+----+-----+

Result 表：
+-----------------+
| ConsecutiveNums |
+-----------------+
| 1               |
+-----------------+
1 是唯一连续出现至少三次的数字。


</code></pre>
<h3 id="解答-5"><strong>解答</strong></h3>
<h5 id="思路-5"><strong>思路:</strong></h5>
<p>本题根据题目要求，需查询出连续出现至少三次的同一个数字，所以distinct函数是一定需要使用的；三次同一个数字的id分别为id，id+1，id+2，而num是相同的，所以需要两个自查询作为筛选条件</p>
<h5 id="答案-5"><strong>答案:</strong></h5>
<pre><code>select distinct Num as ConsecutiveNums from Logs where (Id+1,Num) in (select * from Logs) and (Id+2,Num) in (select * from Logs)
</code></pre>
<h5 id="重点-5"><strong>重点:</strong></h5>
<p>活用子查询</p>
<h2 id="6">6.</h2>
<p><code>Employee</code> 表包含所有员工，他们的经理也属于员工。每个员工都有一个 Id，此外还有一列对应员工的经理的 Id。</p>
<pre><code>+----+-------+--------+-----------+
| Id | Name  | Salary | ManagerId |
+----+-------+--------+-----------+
| 1  | Joe   | 70000  | 3         |
| 2  | Henry | 80000  | 4         |
| 3  | Sam   | 60000  | NULL      |
| 4  | Max   | 90000  | NULL      |
+----+-------+--------+-----------+
</code></pre>
<p>给定 <code>Employee</code> 表，编写一个 SQL 查询，该查询可以获取收入超过他们经理的员工的姓名。在上面的表格中，Joe 是唯一一个收入超过他的经理的员工。</p>
<pre><code>+----------+
| Employee |
+----------+
| Joe      |
+----------+
</code></pre>
<h3 id="解答-6"><strong>解答</strong></h3>
<h5 id="思路-6"><strong>思路:</strong></h5>
<p>本题需要使用子链接或自链接</p>
<h5 id="答案-6"><strong>答案：</strong></h5>
<p>子链接：</p>
<pre><code>select a.Name as Employee from Employee a where a.Salary &gt; 

(select b.Salary from Employee b where b.Id = a.ManagerId) 
</code></pre>
<p>自链接：</p>
<pre><code>select a.Name as Employee from Employee a join Employee b where b.id = a.ManagerId and b.Salary &lt; a.Salary
</code></pre>
<h5 id="重点-6"><strong>重点：</strong></h5>
<p>加强自链接和子链接的使用</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maven setting]]></title>
        <id>https://cm940324.github.io/post/maven-setting/</id>
        <link href="https://cm940324.github.io/post/maven-setting/">
        </link>
        <updated>2021-08-09T01:16:36.000Z</updated>
        <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?> 
<p><settings xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"></p>
 <!--本地仓库。该值表示构建系统本地仓库的路径。其默认值为~/.m2/repository。 --> 
<p><localRepository>usr/local/maven</localRepository></p>
 <!--Maven是否需要和用户交互以获得输入。如果Maven需要和用户交互以获得输入，则设置成true，反之则应为false。默认为true。--> 
<p><interactiveMode>true</interactiveMode></p>
 <!--Maven是否需要使用plugin-registry.xml文件来管理插件版本。如果需要让Maven使用文件~/.m2/plugin-registry.xml来管理插件版本，则设为true。默认为false。--> 
<p><usePluginRegistry>false</usePluginRegistry></p>
 <!--表示Maven是否需要在离线模式下运行。如果构建系统需要在离线模式下运行，则为true，默认为false。当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。 --> 
<p><offline>false</offline></p>
 <!--当插件的组织Id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。默认情况下该列表包含了org.apache.maven.plugins。 --> 
 <pluginGroups> 
 <!--plugin的组织Id（groupId） --> 
 <pluginGroup>org.codehaus.mojo</pluginGroup> 
 </pluginGroups> 
 <!--用来配置不同的代理，多代理profiles 可以应对笔记本或移动设备的工作环境：通过简单的设置profile id就可以很容易的更换整个代理配置。 --> 
 <proxies> 
 <!--代理元素包含配置代理时需要的信息--> 
 <proxy> 
 <!--代理的唯一定义符，用来区分不同的代理元素。--> 
 <id>myproxy</id> 
 <!--该代理是否是激活的那个。true则激活代理。当我们声明了一组代理，而某个时候只需要激活一个代理的时候，该元素就可以派上用处。 --> 
 <active>true</active> 
 <!--代理的协议。 协议://主机名:端口，分隔成离散的元素以方便配置。--> 
 <protocol>http</protocol> 
 <!--代理的主机名。协议://主机名:端口，分隔成离散的元素以方便配置。 --> 
 <host>proxy.somewhere.com</host> 
 <!--代理的端口。协议://主机名:端口，分隔成离散的元素以方便配置。 --> 
 <port>8080</port> 
 <!--代理的用户名，用户名和密码表示代理服务器认证的登录名和密码。 --> 
 <username>proxyuser</username> 
 <!--代理的密码，用户名和密码表示代理服务器认证的登录名和密码。 --> 
 <password>somepassword</password> 
 <!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定；例子中使用了竖线分隔符，使用逗号分隔也很常见。--> 
 <nonProxyHosts>*.google.com|ibiblio.org</nonProxyHosts> 
 </proxy> 
 </proxies> 
 <!--配置服务端的一些设置。一些设置如安全证书不应该和pom.xml一起分发。这种类型的信息应该存在于构建服务器上的settings.xml文件中。--> 
 <servers> 
 <!--服务器元素包含配置服务器时需要的信息 --> 
 <server> 
 <!--这是server的id（注意不是用户登陆的id），该id与distributionManagement中repository元素的id相匹配。--> 
 <id>server001</id> 
 <!--鉴权用户名。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --> 
 <username>my_login</username> 
 <!--鉴权密码 。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --> 
 <password>my_password</password> 
 <!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是/home/hudson/.ssh/id_dsa）以及如果需要的话，一个密语。将来passphrase和password元素可能会被提取到外部，但目前它们必须在settings.xml文件以纯文本的形式声明。 --> 
 <privateKey>${usr.home}/.ssh/id_dsa</privateKey> 
 <!--鉴权时使用的私钥密码。--> 
 <passphrase>some_passphrase</passphrase> 
 <!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --> 
 <filePermissions>664</filePermissions> 
 <!--目录被创建时的权限。 --> 
 <directoryPermissions>775</directoryPermissions> 
 <!--传输层额外的配置项 --> 
 <configuration></configuration> 
 </server> 
 </servers> 
 <!--为仓库列表配置的下载镜像列表。 --> 
 <mirrors> 
 <!--给定仓库的下载镜像。 --> 
 <mirror> 
 <!--该镜像的唯一标识符。id用来区分不同的mirror元素。 --> 
 <id>planetmirror.com</id> 
 <!--镜像名称 --> 
 <name>PlanetMirror Australia</name> 
 <!--该镜像的URL。构建系统会优先考虑使用该URL，而非使用默认的服务器URL。 --> 
 <url>http://downloads.planetmirror.com/pub/maven2</url> 
 <!--被镜像的服务器的id。例如，如果我们要设置了一个Maven中央仓库（http://repo1.maven.org/maven2）的镜像，就需要将该元素设置成central。这必须和中央仓库的id central完全一致。--> 
 <mirrorOf>central</mirrorOf> 
 </mirror> 
 </mirrors> 
 <!--根据环境参数来调整构建配置的列表。settings.xml中的profile元素是pom.xml中profile元素的裁剪版本。它包含了id，activation, repositories, pluginRepositories和 properties元素。这里的profile元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是settings.xml文件的角色定位），而非单独的项目对象模型设置。如果一个settings中的profile被激活，它的值会覆盖任何其它定义在POM中或者profile.xml中的带有相同id的profile。 --> 
 <profiles> 
 <!--根据环境参数来调整的构件的配置--> 
 <profile> 
 <!--该配置的唯一标识符。 --> 
 <id>test</id> 
 <!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。如POM中的profile一样，profile的力量来自于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。settings.xml文件中的activeProfile元素可以包含profile的id。profile也可以通过在命令行，使用-P标记和逗号分隔的列表来显式的激活（如，-P test）。--> 
 <activation> 
 <!--profile默认是否激活的标识--> 
 <activeByDefault>false</activeByDefault> 
 <!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--> 
 <jdk>1.5</jdk> 
 <!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--> 
 <os> 
 <!--激活profile的操作系统的名字 --> 
 <name>Windows XP</name> 
 <!--激活profile的操作系统所属家族(如 'windows') --> 
 <family>Windows</family> 
 <!--激活profile的操作系统体系结构 --> 
 <arch>x86</arch> 
 <!--激活profile的操作系统版本--> 
 <version>5.1.2600</version> 
 </os> 
 <!--如果Maven检测到某一个属性（其值可以在POM中通过${名称}引用），其拥有对应的名称和值，Profile就会被激活。如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--> 
 <property> 
 <!--激活profile的属性的名称--> 
 <name>mavenVersion</name> 
 <!--激活profile的属性的值 --> 
 <value>2.0.3</value> 
 </property> 
 <!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--> 
 <file> 
 <!--如果指定的文件存在，则激活profile。 --> 
 <exists>/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/</exists> 
 <!--如果指定的文件不存在，则激活profile。--> 
 <missing>/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/</missing> 
 </file> 
 </activation> 
 <!--对应profile的扩展属性列表。Maven属性和Ant中的属性一样，可以用来存放一些值。这些值可以在POM中的任何地方使用标记${X}来使用，这里X是指属性的名称。属性有五种不同的形式，并且都能在settings.xml文件中访问。 
 1. env.X: 在一个变量前加上"env."的前缀，会返回一个shell环境变量。例如,"env.PATH"指代了$path环境变量（在Windows上是%PATH%）。 
 2. project.x：指代了POM中对应的元素值。 
 3. settings.x: 指代了settings.xml中对应元素的值。 
 4. Java System Properties: 所有可通过java.lang.System.getProperties()访问的属性都能在POM中使用该形式访问， 
 如/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0/jre。 
 5. x: 在<properties/>元素中，或者外部文件中设置，以${someVar}的形式使用。 --> 
 <properties> 
 <user.install>/ebs1/build-machine/usr/local/hudson/hudson-home/jobs/maven-guide-</user.install> 
 </properties> 
 <!--远程仓库列表，它是Maven用来填充构建系统本地仓库所使用的一组远程项目。 --> 
 <repositories> 
 <!--包含需要连接到远程仓库的信息 --> 
 <repository> 
 <!--远程仓库唯一标识--> 
 <id>codehausSnapshots</id> 
 <!--远程仓库名称 --> 
 <name>Codehaus Snapshots</name> 
 <!--如何处理远程仓库里发布版本的下载--> 
 <releases> 
 <!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --> 
 <enabled>false</enabled> 
 <!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --> 
 <updatePolicy>always</updatePolicy> 
 <!--当Maven验证构件校验文件失败时该怎么做-ignore（忽略），fail（失败），或者warn（警告）。--> 
 <checksumPolicy>warn</checksumPolicy> 
 </releases> 
 <!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素--> 
 <snapshots> 
 <enabled/><updatePolicy/><checksumPolicy/> 
 </snapshots> 
 <!--远程仓库URL，按protocol://hostname/path形式 --> 
 <url>http://snapshots.maven.codehaus.org/maven2</url> 
 <!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --> 
 <layout>default</layout> 
 </repository> 
 </repositories> 
 <!--发现插件的远程仓库列表。仓库是两种主要构件的家。第一种构件被用作其它构件的依赖。这是中央仓库中存储的大部分构件类型。另外一种构件类型是插件。Maven插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。pluginRepositories元素的结构和repositories元素的结构类似。每个pluginRepository元素指定一个Maven可以用来寻找新插件的远程地址。--> 
 <pluginRepositories> 
 <!--包含需要连接到远程插件仓库的信息.参见profiles/profile/repositories/repository元素的说明--> 
 <pluginRepository> 
 <releases> 
 <enabled/><updatePolicy/><checksumPolicy/> 
 </releases> 
 <snapshots> 
 <enabled/><updatePolicy/><checksumPolicy/> 
 </snapshots> 
 <id/><name/><url/><layout/> 
 </pluginRepository> 
 </pluginRepositories> 
 <!--手动激活profiles的列表，按照profile被应用的顺序定义activeProfile。 该元素包含了一组activeProfile元素，每个activeProfile都含有一个profile id。任何在activeProfile中定义的profile id，不论环境设置如何，其对应的 
 profile都会被激活。如果没有匹配的profile，则什么都不会发生。例如，env-test是一个activeProfile，则在pom.xml（或者profile.xml）中对应id的profile会被激活。如果运行过程中找不到这样一个profile，Maven则会像往常一样运行。 --> 
 <activeProfiles> 
 <!-- --> 
 <activeProfile>env-test</activeProfile> 
 </activeProfiles> 
 </profile> 
 </profiles> 
</settings> 
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[@Excel参数大全]]></title>
        <id>https://cm940324.github.io/post/excel-args/</id>
        <link href="https://cm940324.github.io/post/excel-args/">
        </link>
        <updated>2021-07-19T09:05:37.000Z</updated>
        <content type="html"><![CDATA[<table>
<thead>
<tr>
<th>参数</th>
<th>类型</th>
<th>默认值</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>sort</td>
<td>int</td>
<td>Integer.MAX_VALUE</td>
<td>导出时在excel中排序</td>
</tr>
<tr>
<td>name</td>
<td>String</td>
<td>空</td>
<td>导出到Excel中的名字</td>
</tr>
<tr>
<td>dateFormat</td>
<td>String</td>
<td>空</td>
<td>日期格式, 如: yyyy-MM-dd</td>
</tr>
<tr>
<td>dictType</td>
<td>String</td>
<td>空</td>
<td>如果是字典类型，请设置字典的type值 (如: sys_user_sex)</td>
</tr>
<tr>
<td>readConverterExp</td>
<td>String</td>
<td>空</td>
<td>读取内容转表达式 (如: 0=男,1=女,2=未知)</td>
</tr>
<tr>
<td>separator</td>
<td>String</td>
<td>,</td>
<td>分隔符，读取字符串组内容</td>
</tr>
<tr>
<td>scale</td>
<td>int</td>
<td>-1</td>
<td>BigDecimal 精度 默认:-1(默认不开启BigDecimal格式化)</td>
</tr>
<tr>
<td>roundingMode</td>
<td>int</td>
<td>BigDecimal.ROUND_HALF_EVEN</td>
<td>BigDecimal 舍入规则 默认:BigDecimal.ROUND_HALF_EVEN</td>
</tr>
<tr>
<td>columnType</td>
<td>Enum</td>
<td>Type.STRING</td>
<td>导出类型（0数字 1字符串 2图片）</td>
</tr>
<tr>
<td>height</td>
<td>String</td>
<td>14</td>
<td>导出时在excel中每个列的高度 单位为字符</td>
</tr>
<tr>
<td>width</td>
<td>String</td>
<td>16</td>
<td>导出时在excel中每个列的宽 单位为字符</td>
</tr>
<tr>
<td>suffix</td>
<td>String</td>
<td>空</td>
<td>文字后缀,如% 90 变成90%</td>
</tr>
<tr>
<td>defaultValue</td>
<td>String</td>
<td>空</td>
<td>当值为空时,字段的默认值</td>
</tr>
<tr>
<td>prompt</td>
<td>String</td>
<td>空</td>
<td>提示信息</td>
</tr>
<tr>
<td>combo</td>
<td>String</td>
<td>Null</td>
<td>设置只能选择不能输入的列内容</td>
</tr>
<tr>
<td>targetAttr</td>
<td>String</td>
<td>空</td>
<td>另一个类中的属性名称,支持多级获取,以小数点隔开</td>
</tr>
<tr>
<td>isStatistics</td>
<td>boolean</td>
<td>false</td>
<td>是否自动统计数据,在最后追加一行统计数据总和</td>
</tr>
<tr>
<td>type</td>
<td>Enum</td>
<td>Type.ALL</td>
<td>字段类型（0：导出导入；1：仅导出；2：仅导入）</td>
</tr>
</tbody>
</table>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[JPA踩坑记录]]></title>
        <id>https://cm940324.github.io/post/jpa-qa/</id>
        <link href="https://cm940324.github.io/post/jpa-qa/">
        </link>
        <updated>2021-06-24T06:08:55.000Z</updated>
        <content type="html"><![CDATA[<h3 id="spring-data-jpa查询到的对象被set值后自动更新数据库">Spring data JPA查询到的对象被set值后，自动更新数据库</h3>
<p>做项目开发的时候遇到这样一个问题：数据库有临时表和正式表，数据审批通过后才会进入正式表，根据业务要求，页面的数据需要通过临时表对象来显示，当需要显示正式表数据时，先查询到临时表对象，再查询正式表对象，将正式表对象赋值给临时表对象用于页面显示，代码执行完毕后，发现数据库正式表数据覆盖了临时表数据，很纳闷，查看代码，在把正式表数据赋值给临时表对象后，并没有保存临时表对象的代码呀，数据库怎么会被更新？<br>
后来查看日志发现，当将正式表数据赋值给临时表时，有一条update语句执行了。查看资料后才知道，使用JPA查询后的对象处于持久态，持久态的对象属性在被set后，会自动执行update语句更新数据库。<br>
这才恍然大悟，基于这个原因，只要把持久态的对象转换为游离态或者是临时态，就可以解决问题。<br>
先理解下Hibernate 中对象的三种状态：<br>
(1)临时状态：通过new新建的对象，没有被持久化，也不在session缓存中<br>
(2)游离状态：已经被持久化，但不在session缓存中<br>
(3)持久状态：已经被持久化，也在session缓存中<br>
(持久化：数据库有这条数据)<br>
持久态到游离态的方法有：session.close()、session.evict(obj)、session.clear()<br>
close()：关闭session，整个session中的持久态对象都成为游离态<br>
clear()：清楚session中的所有缓存，所有持久化对象变为游离态<br>
evict(obj)：把某个持久化状态的对象从session中清除，该对象变为游离态</p>
<p>根据三个方法的介绍，最好的处理方式应该选择evict(obj)方法。</p>
<p>由于业务需求，我的解决方式是，新建一个临时态的临时表对象，将查询到的正式表对象赋值给临时态对象，这样就不会触发update语句，经测试，问题解决。</p>
<p>`	@PersistenceContext<br>
private EntityManager entityManager;</p>
<pre><code>Session session = entityManager.unwrap(Session.class);`</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[springboot2的配置文件properties和yml的一些常用属性]]></title>
        <id>https://cm940324.github.io/post/springboot2-yml/</id>
        <link href="https://cm940324.github.io/post/springboot2-yml/">
        </link>
        <updated>2021-06-17T08:13:43.000Z</updated>
        <content type="html"><![CDATA[<p>＃================================================= ==================<br>
＃COMMON SPRING BOOT PROPERTIES</p>
<h2 id=""></h2>
<p>此样本文件作为指南提供。不要将它的#complete复制<br>
到您自己的应用程序中。^^^<br>
＃============================================== =====================</p>
<p>＃----------------------------------------<br>
#CORE PROPERTIES<br>
＃----- -----------------------------------<br>
debug = false ＃启用调试日志。<br>
trace = false ＃启用跟踪日志。</p>
<p>#logGING<br>
logging.config = ＃日志配置文件的位置。例如，Logback的<code>classpath：logback.xml</code>。<br>
logging.exception-conversion-word =％wEx ＃记录异常时使用的转换字。<br>
logging.file = ＃日志文件名（例如，<code>myapp.log</code>）。名称可以是精确位置或相对于当前目录。<br>
logging.file.max-history = 0 ＃要保留的归档日志文件的最大值。仅支持默认的logback设置。<br>
logging.file.max-size = 10MB ＃最大日志文件大小。仅支持默认的logback设置。<br>
logging.group。* =＃记录组以同时快速更改多个记录器。例如，<code>logging.level.db = org.hibernate，org.springframework.jdbc</code>。<br>
logging.level。* = ＃日志级别严重性映射。例如，<code>logging.level.org.springframework = DEBUG</code>。<br>
logging.path = ＃日志文件的位置。例如，<code>/ var / log</code>。<br>
logging.pattern.console = ＃用于输出到控制台的Appender模式。仅支持默认的Logback设置。<br>
logging.pattern.dateformat = yyyy-MM-dd HH：mm：ss.SSS ＃日志日期格式的Appender模式。仅支持默认的Logback设置。<br>
logging.pattern.file =＃用于输出到文件的Appender模式。仅支持默认的Logback设置。<br>
logging.pattern.level =％5p ＃日志级别的Appender模式。仅支持默认的Logback设置。<br>
logging.register-shutdown-hook = false ＃在日志记录系统初始化时注册一个关闭钩子。</p>
<p>＃AOP<br>
spring.aop.auto =真＃添加@EnableAspectJAutoProxy。<br>
spring.aop.proxy-target-class = true ＃是否要创建基于子类的（CGLIB）代理（true），而不是基于标准Java接口的代理（false）。</p>
<p>#IDENTITY （ContextIdApplicationContextInitializer）<br>
spring.application.name = #Application name。</p>
<p>#DINAND （SpringApplicationAdminJmxAutoConfiguration）<br>
spring.application.admin.enabled = false ＃是否为应用程序启用管理功能。<br>
spring.application.admin.jmx-name = org.springframework.boot：type = Admin，name = SpringApplication #JMX 应用程序管理员MBean的名称。</p>
<p>#AUTO-CONFIGURATION<br>
spring.autoconfigure.exclude = ＃要排除的自动配置类。</p>
<p>＃BANNER<br>
spring.banner.charset = UTF-8 ＃横幅文件编码。<br>
spring.banner.location = classpath：banner.txt ＃横幅文本资源位置。<br>
spring.banner.image.location = classpath：banner.gif ＃横幅图像文件位置（也可以使用jpg或png）。<br>
spring.banner.image.width = 76 ＃字符中的横幅图像的宽度。<br>
spring.banner.image.height = #crs 中横幅图像的高度（默认基于图像高度）。<br>
spring.banner.image.margin = 2 ＃字符中的左手图像边距。<br>
spring.banner.image.invert = false ＃是否应针对暗终端主题反转图像。</p>
<p>#SPRING CORE spring.beaninfo.ignore = true ＃是否跳过BeanInfo类的搜索。</p>
<p>#SPRING CACHE（CacheProperties）<br>
spring.cache.cache-names = #Cmama 分隔的要创建的缓存名称列表（如果底层缓存管理器支持）。<br>
spring.cache.caffeine.spec = ＃用于创建缓存的规范。有关规格格式的更多详细信息，请参阅CaffeineSpec。<br>
spring.cache.couchbase.expiration = ＃条目到期。默认情况下，条目永不过期。请注意，此值最终会转换为秒。<br>
spring.cache.ehcache.config = ＃用于初始化EhCache的配置文件的位置。<br>
spring.cache.infinispan.config = ＃用于初始化Infinispan的配置文件的位置。<br>
spring.cache.jcache.config = ＃用于初始化缓存管理器的配置文件的位置。<br>
spring.cache.jcache.provider = #CachingProvider实现的完全限定名称，用于检索符合JSR-107的缓存管理器。仅当类路径上有多个JSR-107实现时才需要。<br>
spring.cache.redis.cache-null-values = true ＃允许缓存空值。<br>
spring.cache.redis.key-prefix = ＃键前缀。<br>
spring.cache.redis.time-to-live = ＃条目到期。默认情况下，条目永不过期。<br>
spring.cache.redis.use-key-prefix = true＃写入Redis时是否使用密钥前缀。<br>
spring.cache.type = #Cache 类型。默认情况下，根据环境自动检测。</p>
<p>#SPRING CONFIG  - 仅使用环境属性（ConfigFileApplicationListener）<br>
spring.config.additional-location = ＃配置除默认值之外使用的文件位置。<br>
spring.config.location = ＃配置替换默认值的文件位置。<br>
spring.config.name = application ＃配置文件名。</p>
<p>#HAZELCAST（HazelcastProperties）<br>
spring.hazelcast.config = ＃用于初始化Hazelcast的配置文件的位置。</p>
<p>#PROJECT INFORMATION（ProjectInfoProperties）<br>
spring.info.build.encoding = UTF-8 ＃文件编码。<br>
spring.info.build.location = classpath：META-INF / build-info.properties ＃生成的build-info.properties文件的位置。<br>
spring.info.git.encoding = UTF-8 ＃文件编码。<br>
spring.info.git.location =类路径：git.properties 生成的git.properties文件＃所在。</p>
<p>＃JMX<br>
spring.jmx.default域 = ＃JMX域名。<br>
spring.jmx.enabled = true ＃将管理bean公开给JMX域。<br>
spring.jmx.server = mbeanServer ＃MBeanServer bean name。<br>
spring.jmx.unique-names = false ＃是否应确保唯一的运行时对象名称。</p>
<p>#Email （MailProperties）<br>
spring.mail.default-encoding = UTF-8 ＃默认MimeMessage编码。<br>
spring.mail.host = #SMTP 服务器主机。例如，<code>smtp.example.com</code>。<br>
spring.mail.jndi-name = ＃会话JNDI名称。设置时，优先于其他会话设置。<br>
spring.mail.password = #SMTP 服务器的登录密码。<br>
spring.mail.port = #SMTP 服务器端口。<br>
spring.mail.properties。* = ＃其他JavaMail会话属性。<br>
spring.mail.protocol = smtp ＃SMTP服务器使用的协议。<br>
spring.mail.test-connection = false＃是否在启动时测试邮件服务器是否可用。<br>
spring.mail.username = #SMTP 服务器的登录用户。</p>
<p>#APICING SETTINGS（SpringApplication）<br>
spring.main.allow-bean-definition-overriding = false ＃是否允许通过注册与现有定义同名的定义来覆盖bean定义。<br>
spring.main.banner-mode = console ＃模式用于在应用程序运行时显示横幅。<br>
spring.main.sources = 要包含在ApplicationContext中的<br>
#Sources （类名，包名或XML资源位置）。spring.main.web-application-type = ＃用于显式请求特定类型的Web应用程序的标志。如果未设置，则基于类路径自动检测。</p>
<p>#FILE ENCODING（FileEncodingApplicationListener）<br>
spring.mandatory-file-encoding = ＃应用程序必须使用的预期字符编码。</p>
<p>#INTERINGIZATION （MessageSourceProperties）<br>
spring.messages.always-use-message-format = false ＃是否始终应用MessageFormat规则，甚至解析不带参数的消息。<br>
spring.messages.basename = messages ＃逗号分隔的basenames列表（本质上是一个完全限定的类路径位置），每个都遵循ResourceBundle约定，轻松支持基于斜杠的位置。<br>
spring.messages.cache-duration = ＃加载的资源包文件缓存持续时间。未设置时，捆绑包将永久缓存。如果未指定持续时间后缀，则将使用秒。<br>
spring.messages.encoding = UTF-8 ＃消息包编码。<br>
spring.messages.fallback-to-system-locale = true ＃如果找不到特定区域设置的文件，是否回退到系统区域设置。<br>
spring.messages.use-code-as-default-message = false ＃是否使用消息代码作为默认消息而不是抛出“NoSuchMessageException”。仅在开发期间推荐。</p>
<p>＃OUTPUT<br>
spring.output.ansi.enabled =检测＃配置的ANSI输出。</p>
<p>#PID FILE（ApplicationPidFileWriter）<br>
spring.pid.fail-on-write-error = ＃如果使用ApplicationPidFileWriter但它无法写入PID文件，则失败。<br>
spring.pid.file = ＃要写入的PID文件的位置（如果使用ApplicationPidFileWriter）。</p>
<p>＃PROFILES<br>
spring.profiles.active = ＃逗号分隔的有源配置文件列表。可以通过命令行开关覆盖。<br>
spring.profiles.include = ＃无条件地激活指定的逗号分隔的配置文件列表（如果使用YAML，则激活配置文件列表）。</p>
<p>＃Quartz调度器（QuartzProperties）<br>
spring.quartz.auto-启动 =真＃是否自动启动初始化后的调度。<br>
spring.quartz.jdbc.comment-prefix =  - #SQL 初始化脚本中单行注释的前缀。<br>
spring.quartz.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.quartz.jdbc.schema = classpath：org / quartz / impl / jdbcjobstore / tables_ @ @ platform @@ .sql ＃用于初始化数据库模式的SQL文件的路径。<br>
spring.quartz.job-store-type = memory ＃Quartz作业存储类型。<br>
spring.quartz.overwrite-existing-jobs = false ＃配置的作业是否应覆盖现有的作业定义。<br>
spring.quartz.properties。* = ＃其他Quartz Scheduler属性。<br>
spring.quartz.scheduler-name = quartzScheduler ＃调度程序的名称。<br>
spring.quartz.startup-delay = 0s ＃一旦初始化完成，调度程序启动之后的延迟。<br>
spring.quartz.wait-for-jobs-to-complete-on-shutdown = false ＃是否等待在关闭时运行的作业完成。</p>
<p>#REACTOR （ReactorCoreProperties）<br>
spring.reactor.stacktrace -mode.enabled = false #Reactor 是否应该在运行时收集堆栈跟踪信息。</p>
<p>#SENDGRID（SendGridAutoConfiguration）<br>
spring.sendgrid.api-key = ＃SendGrid API密钥。<br>
spring.sendgrid.proxy.host = ＃SendGrid代理主机。<br>
spring.sendgrid.proxy.port = ＃SendGrid代理端口。</p>
<p>#TASK EXECUTION（TaskExecutionProperties）<br>
spring.task.execution.pool.allow-core-thread-timeout = true ＃是否允许核心线程超时。这可以实现池的动态增长和收缩。<br>
spring.task.execution.pool.core-size = 8 ＃核心线程数。<br>
spring.task.execution.pool.keep-alive = 60s ＃终止之前线程可能保持空闲的时间限制。<br>
spring.task.execution.pool.max-size = ＃允许的最大线程数。如果任务正在填满队列，则池可以扩展到该大小以适应负载。如果队列无限制，则忽略。<br>
spring.task.execution.pool.queue-capacity =＃队列容量。无限制的容量不会增加池，因此会忽略“max-size”属性。<br>
spring.task.execution.thread-name-prefix = task- ＃用于新创建的线程名称的前缀。</p>
<p>#TASK SCHEDULING（TaskSchedulingProperties）<br>
spring.task.scheduling.pool.size = 1 ＃允许的最大线程数。<br>
spring.task.scheduling.thread-name-prefix = scheduling- ＃用于新创建的线程名称的前缀。</p>
<p>＃----------------------------------------<br>
＃WEB PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#EmbEDDED SERVER CONFIGURATION（ServerProperties）<br>
server.address = ＃服务器应绑定到的网络地址。<br>
server.compression.enabled = false ＃是否启用了响应压缩。<br>
server.compression.excluded-user-agents = ＃逗号分隔的用户代理列表，不应压缩响应。<br>
server.compression.mime-types = text / html，text / xml，text / plain，text / css，text / javascript，application / javascript，application / json，application / xml ＃逗号分隔的MIME类型列表应该是压缩。<br>
server.compression.min-response-size = 2KB＃执行压缩所需的最小“Content-Length”值。<br>
server.connection-timeout = ＃连接器在关闭连接之前等待另一个HTTP请求的时间。未设置时，将使用连接器的特定于容器的默认值。使用值-1表示没有（即无限）超时。<br>
server.error.include-exception = false ＃包含“exception”属性。<br>
server.error.include-stacktrace = never ＃何时包含“stacktrace”属性。<br>
server.error.path = / error ＃错误控制器的路径。<br>
server.error.whitelabel.enabled = true＃是否在服务器出错时启用浏览器中显示的默认错误页面。<br>
server.http2.enabled = false ＃是否启用HTTP / 2支持，如果当前环境支持它。<br>
server.jetty.acceptors = -1 ＃要使用的接受者线程数。当值为-1（默认值）时，接受器的数量是从操作环境派生的。<br>
server.jetty.accesslog.append = false ＃追加到日志。<br>
server.jetty.accesslog.date-format = dd / MMM / yyyy：HH：mm：ss Z ＃请求日志的时间戳格式。<br>
server.jetty.accesslog.enabled = false ＃启用访问日志。<br>
server.jetty.accesslog.extended-format = false＃启用扩展NCSA格式。<br>
server.jetty.accesslog.file-date-format = ＃日期文件名中的日期格式。<br>
server.jetty.accesslog.filename = ＃日志文件名。如果未指定，则日志重定向到“System.err”。<br>
server.jetty.accesslog.locale = ＃请求日志的区域设置。<br>
server.jetty.accesslog.log-cookies = false ＃启用请求cookie的记录。<br>
server.jetty.accesslog.log-latency = false ＃启用请求处理时间的记录。<br>
server.jetty.accesslog.log-server = false ＃启用请求主机名的日志记录。<br>
server.jetty.accesslog.retention-period = 31＃删除旋转日志文件之前的天数。<br>
server.jetty.accesslog.time-zone = GMT ＃请求日志的时区。<br>
server.jetty.max-http-post-size = 200000B #HTTP post或put内容的最大大小。<br>
server.jetty.selectors = -1 ＃要使用的选择器线程数。当值为-1（默认值）时，选择器的数量是从操作环境派生的。<br>
server.max-http-header-size = 8KB #HTTP 邮件头的最大大小。<br>
server.port = 8080 ＃服务器HTTP端口。<br>
server.server-header = ＃用于Server响应头的值（如果为空，则不发送头）。<br>
server.use-forward-headers = ＃是否应将X-Forwarded- <em>标头应用于HttpRequest。<br>
server.servlet.context-parameters。</em> = ＃Servlet context init参数。<br>
server.servlet.context-path = ＃应用程序的上下文路径。<br>
server.servlet.application-display-name = application ＃显示<br>
应用程序的名称。server.servlet.jsp.class-name = org.apache.jasper.servlet.JspServlet ＃用于JSP的servlet的类名。<br>
server.servlet.jsp.init-parameters。* = ＃用于配置JSP servlet的Init参数。<br>
server.servlet.jsp.registered = true＃是否已注册JSP servlet。<br>
server.servlet.session.cookie.comment = ＃会话cookie的评论。<br>
server.servlet.session.cookie.domain = ＃会话cookie的域名。<br>
server.servlet.session.cookie.http-only = ＃是否对会话cookie使用“HttpOnly”cookie。<br>
server.servlet.session.cookie.max-age = ＃会话cookie的最大年龄。如果未指定持续时间后缀，则将使用秒。<br>
server.servlet.session.cookie.name = ＃会话cookie名称。<br>
server.servlet.session.cookie.path = ＃会话cookie的路径。<br>
server.servlet.session.cookie.secure =＃是否始终将会话cookie标记为安全。<br>
server.servlet.session.persistent = false ＃是否在重新启动之间保留会话数据。<br>
server.servlet.session.store-dir = ＃用于存储会话数据的目录。<br>
server.servlet.session.timeout = 30m ＃会话超时。如果未指定持续时间后缀，则将使用秒。<br>
server.servlet.session.tracking-modes = ＃会话跟踪模式。<br>
server.ssl.ciphers = ＃支持的SSL密码。<br>
server.ssl.client-auth = ＃客户端身份验证模式。<br>
server.ssl.enabled = true ＃是否启用SSL支持。<br>
server.ssl.enabled-protocols = ＃启用SSL协议。<br>
server.ssl.key-alias = ＃标识密钥库中密钥的别名。<br>
server.ssl.key-password = ＃用于访问密钥库中密钥的密码。<br>
server.ssl.key-store = ＃保存SSL证书的密钥库的路径（通常是jks文件）。<br>
server.ssl.key-store-password = ＃用于访问密钥库的密码。<br>
server.ssl.key-store-provider = ＃密钥库的提供者。<br>
server.ssl.key-store-type = ＃密钥库的类型。<br>
server.ssl.protocol = TLS ＃要使用的SSL协议。<br>
server.ssl.trust-store = ＃持有SSL证书的信任存储。<br>
server.ssl.trust-store-password = ＃用于访问信任库的密码。<br>
server.ssl.trust-store-provider = ＃信任存储的提供者。<br>
server.ssl.trust-store-type = ＃信任库的类型。<br>
server.tomcat.accept-count = 100 ＃当所有可能的请求处理线程都在使用时，传入连接请求的最大队列长度。<br>
server.tomcat.accesslog.buffered = true ＃是否缓冲输出，使其仅定期刷新。<br>
server.tomcat.accesslog.directory = logs＃创建日志文件的目录。可以绝对或相对于Tomcat基础目录。<br>
server.tomcat.accesslog.enabled = false ＃启用访问日志。<br>
server.tomcat.accesslog.file-date-format = .yyyy-MM-dd ＃要放在日志文件名中的日期格式。<br>
server.tomcat.accesslog.pattern = common ＃访问日志的格式模式。<br>
server.tomcat.accesslog.prefix = access_log ＃日志文件名前缀。<br>
server.tomcat.accesslog.rename-on-rotate = false ＃是否延迟在文件名中包含日期戳，直到旋转时间。<br>
server.tomcat.accesslog.request-attributes-enabled = false＃设置请求的IP地址，主机名，协议和端口的请求属性。<br>
server.tomcat.accesslog.rotate = true ＃是否启用访问日志轮换。<br>
server.tomcat.accesslog.suffix = .log ＃日志文件名后缀。<br>
server.tomcat.additional-tld-skip-patterns = ＃逗号分隔的其他模式列表，这些模式匹配要忽略的TLD扫描的jar。<br>
server.tomcat.background-processor-delay = 10s #backgroundProcess 方法调用之间的延迟。如果未指定持续时间后缀，则将使用秒。<br>
server.tomcat.basedir = #Tomcat 基目录。如果未指定，则使用临时目录。<br>
server.tomcat.internal-proxies = 10 \。\ d {1,3} \。\ d {1,3} \。\ d {1,3} | \<br>
。192 \ 168 \ d {1,3} \ d {1,3} | \<br>
。169 \ 254 \ d {1,3} \ d {1,3} | \<br>
。127 \ d {1,3} \ d {1,3} \ d {1,3} | \<br>
172 \ 1 [6-9] {1} \ d {1,3} \ d {1,3} |。。\<br>
172 \ 2 [0-9] {1} \ d {1,3} \ d {1,3} |。。\<br>
172 \。3 [0-1] {1} \。\ d {1,3} \。\ d {1,3} \<br>
0：0：0：0：0：0：0：1 \<br>
:: 1 ＃正则表达式匹配要信任的代理。<br>
server.tomcat.max-connections = 10000 ＃服务器在任何给定时间接受和处理的最大连接数。<br>
server.tomcat.max-http-post-size = 2MB #HTTP 帖子内容的最大大小。<br>
server.tomcat.max-swallow-size = 2MB ＃要吞咽的请求正文的最大数量。<br>
server.tomcat.max-threads = 200 ＃最大工作线程数。<br>
server.tomcat.min-spare-threads = 10 ＃最小工作线程数。<br>
server.tomcat.port-header = X-Forwarded-Port＃用于覆盖原始端口值的HTTP头的名称。<br>
server.tomcat.protocol-header = ＃包含传入协议的头文件，通常命名为“X-Forwarded-Proto”。<br>
server.tomcat.protocol-header-https-value = https ＃协议标头的值，指示传入请求是否使用SSL。<br>
server.tomcat.redirect-context-root = true ＃是否应通过在路径中附加/来重定向对上下文根的请求。<br>
server.tomcat.remote-ip-header = ＃从中提取远程IP的HTTP头的名称。例如，<code>X-FORWARDED-FOR</code>。<br>
server.tomcat.resource.allow-caching = true＃是否允许此Web应用程序使用静态资源缓存。<br>
server.tomcat.resource.cache-ttl = ＃静态资源缓存的生存时间。<br>
server.tomcat.uri-encoding = UTF-8 ＃用于解码URI的字符编码。<br>
server.tomcat.use-relative-redirects = ＃通过调用sendRedirect生成的HTTP 1.1和更高版本的位置标头是使用相对还是绝对重定向。<br>
server.undertow.accesslog.dir = #Undertow 访问日志目录。<br>
server.undertow.accesslog.enabled = false ＃是否启用访问日志。<br>
server.undertow.accesslog.pattern = common ＃访问日志的格式模式。<br>
server.undertow.accesslog.prefix = access_log。＃日志文件名前缀。<br>
server.undertow.accesslog.rotate = true ＃是否启用访问日志轮换。<br>
server.undertow.accesslog.suffix = log ＃日志文件名后缀。<br>
server.undertow.buffer-size = ＃每个缓冲区的大小。<br>
server.undertow.direct-buffers = ＃是否在Java堆外部分配缓冲区。默认值源自JVM可用的最大内存量。<br>
server.undertow.eager-filter-init = true ＃是否应在启动时初始化servlet过滤器。<br>
server.undertow.io-threads =＃为worker创建的I / O线程数。默认值源自可用处理器的数量。<br>
server.undertow.max-http-post-size = -1B #HTTP 帖子内容的最大大小。当值为-1时，默认值为大小无限制。<br>
server.undertow.worker-threads = ＃工作线程数。默认值是I / O线程数的8倍。</p>
<p>#FREEMARKER（FreeMarkerProperties）<br>
spring.freemarker.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.freemarker.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.freemarker.cache = false ＃是否启用模板缓存。<br>
spring.freemarker.charset = UTF-8 ＃模板编码。<br>
spring.freemarker.check-template-location = true ＃是否检查模板位置是否存在。<br>
spring.freemarker.content-type = text / html ＃Content-Type value。<br>
spring.freemarker.enabled = true ＃是否为此技术启用MVC视图分辨率。<br>
spring.freemarker.expose-request-attributes = false ＃是否应在与模板合并之前将所有请求属性添加到模型中。<br>
spring.freemarker.expose-session-attributes = false ＃是否应在与模板合并之前将所有HttpSession属性添加到模型中。<br>
spring.freemarker.expose-spring-macro-helpers = true ＃是否公开一个RequestContext供Spring的宏库使用，名称为“springMacroRequestContext”。<br>
spring.freemarker.prefer-file-system-access = true ＃是否更喜欢文件系统访问以进行模板加载。文件系统访问可以热检测模板更改。<br>
spring.freemarker.prefix = ＃在构建URL时添加前缀以查看名称的前缀。<br>
spring.freemarker.request-context-attribute = ＃所有视图的<br>
RequestContext属性的名称。spring.freemarker.settings。* = ＃众所周知的FreeMarker密钥，传递给FreeMarker的配置。<br>
spring.freemarker.suffix = .ftl ＃在构建URL时附加到视图名称的后缀。<br>
spring.freemarker.template-loader-path = classpath：/ templates /＃逗号分隔的模板路径列表。<br>
spring.freemarker.view-names = ＃可以解析的视图名称的白名单。</p>
<p>#GLOVY TEMPLATES（GroovyTemplateProperties）<br>
spring.groovy.template.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.groovy.template.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.groovy.template.cache = false ＃是否启用模板缓存。<br>
spring.groovy.template.charset = UTF-8 ＃模板编码。<br>
spring.groovy.template.check-template-location = true＃是否检查模板位置是否存在。<br>
spring.groovy.template.configuration。* = ＃请参阅GroovyMarkupConfigurer<br>
spring.groovy.template.content-type = text / html ＃Content-Type value。<br>
spring.groovy.template.enabled = true ＃是否为此技术启用MVC视图分辨率。<br>
spring.groovy.template.expose-request-attributes = false ＃是否应在与模板合并之前将所有请求属性添加到模型中。<br>
spring.groovy.template.expose-session-attributes = false ＃在与模板合并之前是否应将所有HttpSession属性添加到模型中。<br>
spring.groovy.template.expose-spring-macro-helpers = true ＃是否公开一个RequestContext供Spring的宏库使用，名称为“springMacroRequestContext”。<br>
spring.groovy.template.prefix = ＃在构建URL时添加前缀以查看名称的前缀。<br>
spring.groovy.template.request-context-attribute = ＃所有视图的<br>
RequestContext属性的名称。spring.groovy.template.resource-loader-path = classpath：/ templates / ＃Template path。<br>
spring.groovy.template.suffix = .tpl ＃在构建URL时附加到视图名称的后缀。<br>
spring.groovy.template.view-names =＃可以解析的视图名称的白名单。</p>
<p>#SPRING HATEOAS（HateoasProperties）<br>
spring.hateoas.use-hal-as-default-json-media-type = true ＃是否应将application / hal + json响应发送给接受application / json的请求。</p>
<p>#HTTP （HttpProperties）<br>
spring.http.converters.preferred-json-mapper = ＃用于HTTP消息转换的首选JSON映射器。默认情况下，根据环境自动检测。<br>
spring.http.encoding.charset = UTF-8 #HTTP 请求和响应的字符集。如果未明确设置，则添加到“Content-Type”标头。<br>
spring.http.encoding.enabled = true ＃是否启用http编码支持。<br>
spring.http.encoding.force = ＃是否在HTTP请求和响应上强制编码到已配置的字符集。<br>
spring.http.encoding.force-request =＃是否在HTTP请求中强制编码到配置的字符集。如果未指定“force”，则默认为true。<br>
spring.http.encoding.force-response = ＃是否在HTTP响应中强制编码到配置的字符集。<br>
spring.http.encoding.mapping = ＃用于编码映射的Locale。<br>
spring.http.log-request-details = false ＃是否允许在DEBUG和TRACE级别记录（可能敏感的）请求详细信息。</p>
<p>#MULTIPART （MultipartProperties）<br>
spring.servlet.multipart.enabled = true ＃是否启用分段上传支持。<br>
spring.servlet.multipart.file-size-threshold = 0B ＃将文件写入磁盘后的阈值。<br>
spring.servlet.multipart.location = ＃上传文件的中间位置。<br>
spring.servlet.multipart.max-file-size = 1MB ＃最大文件大小。<br>
spring.servlet.multipart.max-request-size = 10MB ＃最大请求大小。<br>
spring.servlet.multipart.resolve-lazily = false ＃是否在文件或参数访问时懒惰地解析多部分请求。</p>
<p>#JACKSON （JacksonProperties）<br>
spring.jackson.date-format = ＃日期格式字符串或完全限定的日期格式类名。例如，<code>yyyy-MM-dd HH：mm：ss</code>。<br>
spring.jackson.default-property-inclusion = ＃控制序列化期间包含的属性。配置了Jackson的JsonInclude.Include枚举中的一个值。<br>
spring.jackson.deserialization。* = #Jackson on / off功能会影响Java对象的反序列化方式。<br>
spring.jackson.generator。* = ＃Jackson开/关功能的发电机。<br>
spring.jackson.joda-date-time-format =#Joda日期时间格式字符串。如果未配置，如果使用格式字符串配置，则使用“date-format”作为后备。<br>
spring.jackson.locale = ＃用于格式化的区域设置。<br>
spring.jackson.mapper。* = #Jackson 通用开/关功能。<br>
spring.jackson.parser。* = ＃Jackson开启/关闭解析器的功能。<br>
spring.jackson.property-naming-strategy = #Jackson PropertyNamingStrategy的常数之一。也可以是PropertyNamingStrategy子类的完全限定类名。<br>
spring.jackson.serialization。* = #Jacker on / off功能会影响Java对象的序列化方式。<br>
spring.jackson.time-zone =＃格式化日期时使用的时区。例如，“America / Los_Angeles”或“GMT + 10”。<br>
spring.jackson.visibility。* = #Jackson 可见性阈值，可用于限制自动检测哪些方法（和字段）。</p>
<p>#GSON（GsonProperties）<br>
spring.gson.date-format = ＃序列化Date对象时使用的格式。<br>
spring.gson.disable -html-escaping = ＃是否禁用HTML字符的转义，例如'&lt;'，'&gt;'等<br>
spring.gson.disable-inner-class-serialization = ＃是否在内容类中排除内部类序列化。<br>
spring.gson.enable-complex-map-key-serialization = ＃是否启用复杂映射键（即非基元）的序列化。<br>
spring.gson.exclude-fields-without-expose-annotation = ＃是否排除所有不考虑序列化或反序列化但没有“Expose”注释的字段。<br>
spring.gson.field-naming-policy = ＃在序列化和反序列化期间应该应用于对象字段的命名策略。<br>
spring.gson.generate-non-executable-json = ＃是否通过在输出前添加一些特殊文本来生成不可执行的JSON。<br>
spring.gson.lenient = ＃是否宽容解析不符合RFC 4627的<br>
JSON.chring.gson.long-serialization-policy = ＃长和长类型的序列化策略。<br>
spring.gson.pretty-printing = ＃是否输出适合页面的序列化JSON以进行漂亮的打印。<br>
spring.gson.serialize-nulls = ＃是否序列化空字段。</p>
<p>#JERSEY （JerseyProperties）<br>
spring.jersey.application-path = ＃作为应用程序基URI的路径。如果指定，则覆盖“@ApplicationPath”的值。<br>
spring.jersey.filter.order = 0 ＃Jersey过滤链顺序。<br>
spring.jersey.init。* = ＃通过servlet或过滤器传递给Jersey的Init参数。<br>
spring.jersey.servlet.load-on-startup = -1 ＃加载Jersey servlet的启动优先级。<br>
spring.jersey.type = servlet ＃Jersey集成类型。</p>
<p>#SPRING LDAP（LdapProperties）<br>
spring.ldap.anonymous-read-only = false ＃只读操作是否应使用匿名环境。<br>
spring.ldap.base = #Base 后缀，所有操作都应该来自该后缀。<br>
spring.ldap.base-environment。* = #LDAP 规范设置。<br>
spring.ldap.password = ＃服务器的登录密码。<br>
spring.ldap.urls = ＃服务器的LDAP URL。<br>
spring.ldap.username = ＃登录服务器的用户名。</p>
<p>＃EMBEDDED LDAP（EmbeddedLdapProperties）<br>
spring.ldap.embedded.base-dn = ＃基本DN列表。<br>
spring.ldap.embedded.credential.username = ＃嵌入式LDAP用户名。<br>
spring.ldap.embedded.credential.password = ＃嵌入式LDAP密码。<br>
spring.ldap.embedded.ldif = classpath：schema.ldif #Schema （LDIF）脚本资源引用。<br>
spring.ldap.embedded.port = 0 ＃嵌入式LDAP端口。<br>
spring.ldap.embedded.validation.enabled = true ＃是否启用LDAP模式验证。<br>
spring.ldap.embedded.validation.schema = ＃自定义架构的路径。</p>
<p>#MUSTACHE TEMPLATES（MustacheAutoConfiguration）<br>
spring.mustache.allow-request-override = false ＃是否允许HttpServletRequest属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.mustache.allow-session-override = false ＃是否允许HttpSession属性覆盖（隐藏）控制器生成的同名模型属性。<br>
spring.mustache.cache = false ＃是否启用模板缓存。<br>
spring.mustache.charset = UTF-8 ＃模板编码。<br>
spring.mustache.check-template-location = true ＃是否检查模板位置是否存在。<br>
spring.mustache.content-type = text / html ＃Content-Type value。<br>
spring.mustache.enabled = true ＃是否为此技术启用MVC视图分辨率。<br>
spring.mustache.expose-request-attributes = false ＃在与模板合并之前是否应将所有请求属性添加到模型中。<br>
spring.mustache.expose-session-attributes = false ＃在与模板合并之前是否应将所有HttpSession属性添加到模型中。<br>
spring.mustache.expose-spring-macro-helpers = true ＃是否公开一个RequestContext供Spring的宏库使用，名称为“springMacroRequestContext”。<br>
spring.mustache.prefix= classpath：/ templates / ＃适用于模板名称的前缀。<br>
spring.mustache.request-context-attribute = ＃所有视图的<br>
RequestContext属性的名称。spring.mustache.suffix = .mustache ＃后缀应用于模板名称。<br>
spring.mustache.view-names = ＃可以解析的视图名称的白名单。</p>
<p>#SPRING MVC（WebMvcProperties）<br>
spring.mvc.async.request-timeout = ＃异步请求处理<br>
超时之前的时间。spring.mvc.contentnegotiation.favor-parameter = false ＃是否应使用请求参数（默认为“format”）来确定请求的媒体类型。<br>
spring.mvc.contentnegotiation.favor-path-extension = false ＃是否应使用URL路径中的路径扩展来确定所请求的媒体类型。<br>
spring.mvc.contentnegotiation.media-types。* = ＃映射内容协商的媒体类型的文件扩展名。例如，yml到text / yaml。<br>
spring.mvc.contentnegotiation.parameter-name =＃启用“favor-parameter”时要使用的查询参数名称。<br>
spring.mvc.date-format = ＃要使用的日期格式。例如，<code>dd / MM / yyyy</code>。<br>
spring.mvc.dispatch-trace-request = false ＃是否将TRACE请求分派给FrameworkServlet doService方法。<br>
spring.mvc.dispatch-options-request = true ＃是否将OPTIONS请求分派给FrameworkServlet doService方法。<br>
spring.mvc.favicon.enabled = true ＃是否启用favicon.ico的解析。<br>
spring.mvc.formcontent.filter.enabled = true ＃是否启用Spring的FormContentFilter。<br>
spring.mvc.hiddenmethod.filter.enabled = true＃是否启用Spring的HiddenHttpMethodFilter。<br>
spring.mvc.ignore-default-model-on-redirect = true ＃在重定向场景中是否应忽略“默认”模型的内容。<br>
spring.mvc.locale = ＃要使用的语言环境。默认情况下，“Accept-Language”标头会覆盖此区域设置。<br>
spring.mvc.locale-resolver = accept-header ＃定义应如何解析语言环境。<br>
spring.mvc.log-resolved-exception = false ＃是否启用由“HandlerExceptionResolver”解析的异常的警告日志记录，“DefaultHandlerExceptionResolver”除外。<br>
spring.mvc.message-codes-resolver-format =＃格式化消息代码的策略。例如，<code>PREFIX_ERROR_CODE</code>。<br>
spring.mvc.pathmatch.use-registered-suffix-pattern = false ＃后缀模式匹配是否仅适用于使用“spring.mvc.contentnegotiation.media-types。<em>”注册的扩展。<br>
spring.mvc.pathmatch.use-suffix-pattern = false ＃将模式与请求匹配时是否使用后缀模式匹配（“。</em>”）。<br>
spring.mvc.servlet.load-on-startup = -1 ＃加载调度程序servlet的启动优先级。<br>
spring.mvc.servlet.path = / ＃调度程序servlet的路径。<br>
spring.mvc.static-path-pattern = / ** ＃用于静态资源的路径模式。<br>
spring.mvc.throw-exception-if-no-handler-found = false ＃如果没有找到Handler来处理请求，是否应该抛出“NoHandlerFoundException”。<br>
spring.mvc.view.prefix = #Spring MVC视图前缀。<br>
spring.mvc.view.suffix = #Spring MVC视图后缀。</p>
<p>#SPRING RESOURCES HANDLING（ResourceProperties）<br>
spring.resources.add-mappings = true ＃是否启用默认资源处理。<br>
spring.resources.cache.cachecontrol.cache-private = ＃表示响应消息仅供单个用户使用，不得由共享高速缓存存储。<br>
spring.resources.cache.cachecontrol.cache-public = ＃表示任何缓存都可以存储响应。<br>
spring.resources.cache.cachecontrol.max-age = ＃应该缓存响应的最长时间，如果未指定持续时间后缀，则以秒为单位。<br>
spring.resources.cache.cachecontrol.must-revalidate =＃表示一旦它变得陈旧，缓存一定不能使用响应而不用服务器重新验证它。<br>
spring.resources.cache.cachecontrol.no-cache = ＃表示只有在与服务器重新验证时才能重用缓存的响应。<br>
spring.resources.cache.cachecontrol.no-store = ＃表示在任何情况下都不缓存响应。<br>
spring.resources.cache.cachecontrol.no-transform = ＃表明他们不应该转换响应内容的中介（缓存和其他人）。<br>
spring.resources.cache.cachecontrol.proxy-revalidate = ＃与“must-revalidate”指令的含义相同，但它不适用于私有缓存。<br>
spring.resources.cache.cachecontrol.s-max-age = ＃共享缓存应缓存响应的最长时间，如果未指定持续时间后缀，则以秒为单位。<br>
spring.resources.cache.cachecontrol.stale-if-error = ＃遇到错误时可以使用响应的最长时间，如果未指定持续时间后缀，则以秒为单位。<br>
spring.resources.cache.cachecontrol.stale-while-revalidate = ＃响应变为失效后可以响应的最长时间，如果未指定持续时间后缀，<br>
则以秒为单位。spring.resources.cache.period = ＃资源处理程序所服务资源的缓存周期。如果未指定持续时间后缀，则将使用秒。<br>
spring.resources.chain.cache= true ＃是否在资源链中启用缓存。<br>
spring.resources.chain.compressed = false ＃是否启用已压缩资源的解析（gzip，brotli）。<br>
spring.resources.chain.enabled = ＃是否启用Spring资源处理链。默认情况下，禁用，除非至少启用了一个策略。<br>
spring.resources.chain.html-application-cache = false ＃是否启用HTML5应用程序缓存清单重写。<br>
spring.resources.chain.strategy.content.enabled = false ＃是否启用内容版本策略。<br>
spring.resources.chain.strategy.content.paths = / **＃逗号分隔的模式列表，应用于内容版本策略。<br>
spring.resources.chain.strategy.fixed.enabled = false ＃是否启用固定版本策略。<br>
spring.resources.chain.strategy.fixed.paths = / ** ＃以逗号分隔的模式列表应用于固定版本策略。<br>
spring.resources.chain.strategy.fixed.version = ＃用于固定版本策略的版本字符串。<br>
spring.resources.static-locations = classpath：/ META-INF / resources /，classpath：/ resources /，classpath：/ static /，classpath：/ public / ＃静态资源的位置。</p>
<p>#SPRING SESSION（SessionProperties）<br>
spring.session.store-type = ＃会话存储类型。<br>
spring.session.timeout = ＃会话超时。如果未指定持续时间后缀，则将使用秒。<br>
spring.session.servlet.filter-order = -2147483598 ＃会话存储库过滤顺序。<br>
spring.session.servlet.filter-dispatcher-types = async，error，request ＃会话存储库过滤器调度程序类型。</p>
<p>#SPRING SESSION HAZELCAST（HazelcastSessionProperties）<br>
spring.session.hazelcast.flush-mode = on-save #sessions flush mode。<br>
spring.session.hazelcast.map-name = spring：session：sessions ＃用于存储会话的地图的名称。</p>
<p>#SPRING SESSION JDBC（JdbcSessionProperties）<br>
spring.session.jdbc.cleanup-cron = 0 * * * * * #cron 表达式用于过期的会话清理作业。<br>
spring.session.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.session.jdbc.schema = classpath中：组织/ springframework的/会话/ JDBC / schema- @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。<br>
spring.session.jdbc.table-name = SPRING_SESSION ＃用于存储会话的数据库表的名称。</p>
<p>#SPRING SESSION MONGODB（MongoSessionProperties）<br>
spring.session.mongodb.collection-name = sessions ＃用于存储会话的集合名称。</p>
<p>#SPRING SESSION REDIS（RedisSessionProperties）<br>
spring.session.redis.cleanup-cron = 0 * * * * * #cron 表达式用于过期的会话清理作业。<br>
spring.session.redis.flush-mode = on-save #sessions flush mode。<br>
spring.session.redis.namespace = spring：session ＃用于存储会话的密钥的命名空间。</p>
<p>#THYMELEAF（ThymeleafAutoConfiguration）<br>
spring.thymeleaf.cache = true ＃是否启用模板缓存。<br>
spring.thymeleaf.check-template = true ＃是否在呈现模板之前检查模板是否存在。<br>
spring.thymeleaf.check-template-location = true ＃是否检查模板位置是否存在。<br>
spring.thymeleaf.enabled = true ＃是否为Web框架启用Thymeleaf视图解析。<br>
spring.thymeleaf.enable-spring-el-compiler = false ＃在SpringEL表达式中启用SpringEL编译器。<br>
spring.thymeleaf.encoding = UTF-8 ＃模板文件编码。<br>
spring.thymeleaf.excluded-view-names = ＃逗号分隔的视图名称列表（允许的模式）应从分辨率中排除。<br>
spring.thymeleaf.mode = HTML ＃要应用于模板的模板模式。另请参见Thymeleaf的TemplateMode枚举。<br>
spring.thymeleaf.prefix = classpath：/ templates / ＃在构建URL时添加前缀以查看名称的前缀。<br>
spring.thymeleaf.reactive.chunked-mode-view-names = ＃逗号分隔的视图名称列表（允许的模式），当设置了最大块大小时，它应该是在CHUNKED模式下执行的唯一列表。<br>
spring.thymeleaf.reactive.full-mode-view-names =＃逗号分隔的视图名称列表（允许的模式），即使设置了最大块大小，也应该在FULL模式下执行。<br>
spring.thymeleaf.reactive.max-chunk-size = 0B ＃用于写入响应的数据缓冲区的最大大小。<br>
spring.thymeleaf.reactive.media-types = ＃视图技术支持的媒体类型。<br>
spring.thymeleaf.render-hidden-markers-before-checkboxes = false ＃是否应在复选框元素本身之前呈现隐藏的表单输入作为复选框的标记。<br>
spring.thymeleaf.servlet.content-type = text / html ＃Content-Type写入HTTP响应的值。<br>
spring.thymeleaf.servlet.produce-partial-output-while-processing = true#Thymeleaf是否应尽快开始编写部分输出或缓冲直到模板处理完成。<br>
spring.thymeleaf.suffix = .html ＃在构建URL时附加到视图名称的后缀。<br>
spring.thymeleaf.template-resolver-order = ＃链中模板解析器的顺序。<br>
spring.thymeleaf.view-names = ＃逗号分隔的视图名称列表（允许的模式），可以解析。</p>
<p>#SPRING WEBFLUX（WebFluxProperties）<br>
spring.webflux.date-format = ＃要使用的日期格式。例如，<code>dd / MM / yyyy</code>。<br>
spring.webflux.hiddenmethod.filter.enabled = true ＃是否启用Spring的HiddenHttpMethodFilter。<br>
spring.webflux.static-path-pattern = / ** ＃用于静态资源的路径模式。</p>
<p>#SPRING WEB SERVICES（WebServicesProperties）<br>
spring.webservices.path = / services ＃作为服务基URI的路径。<br>
spring.webservices.servlet.init = ＃Servlet init参数传递给Spring Web Services。<br>
spring.webservices.servlet.load-on-startup = -1 ＃加载Spring Web Services servlet的启动优先级。<br>
spring.webservices.wsdl-locations = ＃逗号分隔的WSDL位置列表以及要作为bean公开的随附XSD。</p>
<p>＃----------------------------------------<br>
＃SECURITY PROPERTIES<br>
＃----- -----------------------------------<br>
＃SECURITY（SecurityProperties）<br>
spring.security.filter.order = -100 ＃安全过滤器链顺序。<br>
spring.security.filter.dispatcher-types = async，error，request ＃安全过滤器链调度程序类型。<br>
spring.security.user.name = user ＃默认用户名。<br>
spring.security.user.password = ＃默认用户名的密码。<br>
spring.security.user.roles = ＃授予默认用户名的角色。</p>
<p>＃SECURITY OAUTH2 CLIENT（OAuth2ClientProperties）<br>
spring.security.oauth2.client.provider。* = ＃OAuth提供商详细信息。<br>
spring.security.oauth2.client.registration。* = ＃OAuth客户注册。</p>
<p>＃SECURITY OAUTH2 RESOURCE SERVER（OAuth2ResourceServerProperties）<br>
spring.security.oauth2.resourceserver.jwt.jwk-set-uri = ＃JSON用于验证JWT令牌的Web Key URI。<br>
spring.security.oauth2.resourceserver.jwt.issuer-uri = OpenID Connect Provider声明为其颁发者标识符的URI。</p>
<p>＃----------------------------------------<br>
＃DATA PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#FLYWAY （FlywayProperties）<br>
spring.flyway.baseline-description = &lt;&lt; Flyway Baseline &gt;&gt; ＃描述在应用基线时标记现有模式。<br>
spring.flyway.baseline-on-migrate = false ＃是否在迁移非空架构时自动调用基线。<br>
spring.flyway.baseline-version = 1 ＃用于在执行基线时标记现有模式的版本。<br>
spring.flyway.check-location = true ＃是否检查迁移脚本位置是否存在。<br>
spring.flyway.clean-disabled = false ＃是否禁用数据库清理。<br>
spring.flyway.clean-on-validation-error = false＃发生验证错误时是否自动调用clean。<br>
spring.flyway.connect-retries = 0 ＃尝试连接数据库时的最大重试次数。<br>
spring.flyway.enabled = true ＃是否启用flyway。<br>
spring.flyway.encoding = UTF-8 #SQL 迁移的编码。<br>
spring.flyway.group = false ＃是否在应用它们时在同一事务中将所有挂起的迁移组合在一起。<br>
spring.flyway.ignore-future-migrations = true ＃在读取架构历史记录表时是否忽略未来的迁移。<br>
spring.flyway.ignore-ignored-migrations = false＃是否在读取模式历史记录表时忽略忽略的迁移。<br>
spring.flyway.ignore-missing-migrations = false ＃是否在读取模式历史记录表时忽略缺少的迁移。<br>
spring.flyway.ignore-pending-migrations = false ＃在读取架构历史记录表时是否忽略挂起的迁移。<br>
spring.flyway.init-sqls = ＃在获取连接后立即执行以初始化连接的SQL语句。<br>
spring.flyway.installed-by = ＃用户名在架构历史记录表中记录为已应用迁移。<br>
spring.flyway.locations = classpath：db / migration＃迁移脚本的位置。可以包含特殊的“{vendor}”占位符以使用特定于供应商的位置。<br>
spring.flyway.mixed = false ＃是否允许在同一迁移中混合事务和非事务语句。<br>
spring.flyway.out-of-order = false ＃是否允许迁移无序运行。<br>
spring.flyway.password = ＃要迁移的数据库的登录密码。<br>
spring.flyway.placeholder-prefix = $ { ＃迁移脚本中占位符的前缀。<br>
spring.flyway.placeholder-replacement = true ＃在迁移脚本中执行占位符替换。<br>
spring.flyway.placeholder-suffix =}＃迁移脚本中占位符的后缀。<br>
spring.flyway.placeholders = ＃占位符及其替换应用于sql迁移脚本。<br>
spring.flyway.repeatable-sql-migration-prefix = R ＃可重复SQL迁移的文件名前缀。<br>
spring.flyway.schemas = ＃由<br>
Flyway 管理的方案名称（区分大小写）。spring.flyway.skip-default-callbacks = false ＃是否跳过默认回调。如果为true，则仅使用自定义回调。<br>
spring.flyway.skip-default-resolvers = false ＃是否跳过默认的解析器。如果为true，则仅使用自定义解析程序。<br>
spring.flyway.sql-migration-prefix = V.#SQL迁移的文件名前缀。<br>
spring.flyway.sql-migration-separator = __ #SQL迁移的文件名分隔符。<br>
spring.flyway.sql-migration-suffixes = .sql #SQL迁移的文件名后缀。<br>
spring.flyway.table = flyway_schema_history ＃<br>
将由 Flyway 使用的架构架构历史记录表的名称。spring.flyway.target = ＃应考虑迁移的目标版本。<br>
spring.flyway.url = 要迁移的数据库的JDBC url。如果未设置，则使用主要配置的数据源。<br>
spring.flyway.user = ＃要迁移的数据库的登录用户。<br>
spring.flyway.validate-on-migrate = true ＃是否在执行迁移时自动调用validate。</p>
<p>#LIQUIBASE（LiquibaseProperties）<br>
spring.liquibase.change-log = classpath：/db/changelog/db.changelog-master.yaml# 更改日志配置路径。<br>
spring.liquibase.check-change-log-location = true ＃是否检查更改日志位置是否存在。<br>
spring.liquibase.contexts = ＃逗号分隔的运行时上下文列表。<br>
spring.liquibase.database-change-log-lock-table = DATABASECHANGELOGLOCK ＃用于跟踪并发Liquibase用法的表的名称。<br>
spring.liquibase.database-change-log-table = DATABASECHANGELOG ＃用于跟踪更改历史<br>
记录的表的名称。spring.liquibase.default-模式= ＃默认数据库架构。<br>
spring.liquibase.drop-first = false ＃是否首先删除数据库模式。<br>
spring.liquibase.enabled = true ＃是否启用Liquibase支持。<br>
spring.liquibase.labels = ＃逗号分隔的运行时标签列表。<br>
spring.liquibase.liquibase-schema = #Schema用于Liquibase对象。<br>
spring.liquibase.liquibase-tablespace = ＃用于Liquibase对象的表空间。<br>
spring.liquibase.parameters。* = ＃更改日志参数。<br>
spring.liquibase.password = ＃要迁移的数据库的登录密码。<br>
spring.liquibase.rollback-file = ＃执行更新时写入回滚SQL的文件。<br>
spring.liquibase.test-rollback-on-update = false ＃是否应在执行更新之前测试回滚。<br>
spring.liquibase.url = ＃JDBC要迁移的数据库的URL。如果未设置，则使用主要配置的数据源。<br>
spring.liquibase.user = ＃要迁移的数据库的登录用户。</p>
<p>＃COUCHBASE（CouchbaseProperties）<br>
spring.couchbase.bootstrap-hosts = #Couchbase 节点（主机或IP地址）来自引导程序。<br>
spring.couchbase.bucket.name = default ＃要连接的存储桶的名称。<br>
spring.couchbase.bucket.password =   ＃桶的密码。<br>
spring.couchbase.env.endpoints.key-value = 1 ＃针对键/值服务的每个节点的套接字数。<br>
spring.couchbase.env.endpoints.queryservice.min-endpoints = 1 ＃每个节点的最小套接字数。<br>
spring.couchbase.env.endpoints.queryservice.max-endpoints = 1 ＃每个节点的最大套接字数。<br>
spring.couchbase.env.endpoints.viewservice.min-endpoints = 1 ＃每个节点的最小套接字数。<br>
spring.couchbase.env.endpoints.viewservice.max-endpoints = 1 ＃每个节点的最大套接字数。<br>
spring.couchbase.env.ssl.enabled = ＃是否启用SSL支持。除非另有说明，否则在提供“keyStore”时自动启用。<br>
spring.couchbase.env.ssl.key-store = ＃保存证书的JVM密钥库的路径。<br>
spring.couchbase.env.ssl.key-store-password = ＃用于访问密钥库的密码。<br>
spring.couchbase.env.timeouts.connect = 5000ms ＃桶连接超时。<br>
spring.couchbase.env.timeouts.key-value = 2500ms ＃对特定密钥超时执行的阻止操作。<br>
spring.couchbase.env.timeouts.query = 7500ms ＃N1QL查询操作超时。<br>
spring.couchbase.env.timeouts.socket-connect = 1000ms #Socket 连接超时。<br>
spring.couchbase.env.timeouts.view = 7500ms ＃常规和地理空间视图操作超时。</p>
<p>#DAO （PersistenceExceptionTranslationAutoConfiguration）<br>
spring.dao.exceptiontranslation.enabled = true ＃是否启用PersistenceExceptionTranslationPostProcessor。</p>
<p>#CASSANDRA （CassandraProperties）<br>
spring.data.cassandra.cluster-name = #Cassandra 集群的名称。<br>
spring.data.cassandra.compression = none ＃Cassandra二进制协议支持的压缩。<br>
spring.data.cassandra.connect-timeout = #Socket 选项：连接超时。<br>
spring.data.cassandra.consistency-level = ＃查询一致性级别。<br>
spring.data.cassandra.contact-points = localhost ＃群集节点地址。<br>
spring.data.cassandra.fetch-size = ＃查询默认提取大小。<br>
spring.data.cassandra.jmx-enabled = false＃是否启用JMX报告。<br>
spring.data.cassandra.keyspace-name = ＃要使用的Keyspace名称。<br>
spring.data.cassandra.port = #Cassandra 服务器的端口。<br>
spring.data.cassandra.password = ＃服务器的登录密码。<br>
spring.data.cassandra.pool.heartbeat-interval = 30s #Heartbeat interval，在此之后，在空闲连接上发送消息以确保它仍然存在。如果未指定持续时间后缀，则将使用秒。<br>
spring.data.cassandra.pool.idle-timeout = 120s ＃删除空闲连接之前的空闲超时。如果未指定持续时间后缀，则将使用秒。<br>
spring.data.cassandra.pool.max队列大小= 256 ＃如果没有可用连接，则排队的最大请求数。<br>
spring.data.cassandra.pool.pool-timeout = 5000ms ＃尝试从主机池获取连接时的池超时。<br>
spring.data.cassandra.read-timeout = #Socket 选项：读取超时。<br>
spring.data.cassandra.repositories.type = auto ＃要启用的Cassandra存储库的类型。<br>
spring.data.cassandra.serial-consistency-level = ＃查询串行一致性级别。<br>
spring.data.cassandra.schema-action = none ＃启动时要采取的架构操作。<br>
spring.data.cassandra.ssl = false ＃启用SSL支持。<br>
spring.data.cassandra.username = ＃服务器的登录用户。</p>
<p>#DATA COUCHBASE（CouchbaseDataProperties）<br>
spring.data.couchbase.auto-index = false ＃自动创建视图和索引。<br>
spring.data.couchbase.consistency = read-your-own-writes ＃在生成的查询中默认应用的一致性。<br>
spring.data.couchbase.repositories.type = auto ＃要启用的Couchbase存储库的类型。</p>
<p>#ELASTICSEARCH（ElasticsearchProperties）<br>
spring.data.elasticsearch.cluster-name = elasticsearch ＃Elasticsearch集群名称。<br>
spring.data.elasticsearch.cluster-nodes = ＃逗号分隔的集群节点地址列表。<br>
spring.data.elasticsearch.properties。* = ＃用于配置客户端的其他属性。<br>
spring.data.elasticsearch.repositories.enabled = true ＃是否启用Elasticsearch存储库。</p>
<p>#DATA JDBC spring.data.jdbc.repositories.enabled = true ＃是否启用JDBC存储库。</p>
<p>#DATA LDAP spring.data.ldap.repositories.enabled = true ＃是否启用LDAP存储库。</p>
<p>#MONGODB（MongoProperties）<br>
spring.data.mongodb.authentication-database = ＃认证数据库名称。<br>
spring.data.mongodb.database = ＃数据库名称。<br>
spring.data.mongodb.field-naming-strategy = ＃要使用的FieldNamingStrategy的完全限定名称。<br>
spring.data.mongodb.grid-fs-database = ＃GridFS数据库名称。<br>
spring.data.mongodb.host = #Mongo 服务器主机。无法使用URI设置。<br>
spring.data.mongodb.password = #mongo 服务器的登录密码。无法使用URI设置。<br>
spring.data.mongodb.port = #Mongo 服务器端口。无法使用URI设置。<br>
spring.data.mongodb.repositories.type = auto ＃要启用的Mongo存储库的类型。<br>
spring.data.mongodb.uri = mongodb：// localhost / test ＃Mongo数据库URI。无法使用主机，端口和凭据进行设置。<br>
spring.data.mongodb.username = #mongo 服务器的登录用户。无法使用URI设置。</p>
<p>#DATA REDIS<br>
spring.data.redis.repositories.enabled = true ＃是否启用Redis存储库。</p>
<p>＃NEO4J（Neo4jProperties）<br>
spring.data.neo4j.auto-index = none ＃自动索引模式。<br>
spring.data.neo4j.embedded.enabled = true ＃如果嵌入式驱动程序可用，是否启用嵌入模式。<br>
spring.data.neo4j.open-in-view = true ＃注册OpenSessionInViewInterceptor。将Neo4j会话绑定到线程以进行整个请求处理。<br>
spring.data.neo4j.password = ＃服务器的登录密码。<br>
spring.data.neo4j.repositories.enabled = true ＃是否启用Neo4j存储库。<br>
spring.data.neo4j.uri = 驱动程序使用的#URL 。默认情况下自动检测。<br>
spring.data.neo4j.username = ＃服务器的登录用户。</p>
<p>#DATA REST（RepositoryRestProperties）<br>
spring.data.rest.base-path = #Spring Data REST用于公开存储库资源的基本路径。<br>
spring.data.rest.default-media-type = ＃未指定时用作默认值的内容类型。<br>
spring.data.rest.default-page-size = ＃默认页面大小。<br>
spring.data.rest.detection-strategy = default ＃用于确定暴露哪些存储库的策略。<br>
spring.data.rest.enable-enum-translation = ＃是否通过Spring Data REST默认资源包启用枚举值转换。<br>
spring.data.rest.limit-param-name =#URL查询字符串参数的名称，指示一次返回多少结果。<br>
spring.data.rest.max-page-size = ＃最大页面大小。<br>
spring.data.rest.page-param-name = #URL 查询字符串参数的名称，指示要返回的页面。<br>
spring.data.rest.return-body-on-create = ＃是否在创建实体后返回响应正文。<br>
spring.data.rest.return-body-on-update = ＃更新实体后是否返回响应正文。<br>
spring.data.rest.sort-param-name = #URL 查询字符串参数的名称，指示对结果进行排序的方向。</p>
<p>#SOLR （SolrProperties）<br>
spring.data.solr.host = http：//127.0.0.1：8983 / solr #Solr host。如果设置了“zk-host”，则忽略。<br>
spring.data.solr.repositories.enabled = true ＃是否启用Solr存储库。<br>
spring.data.solr.zk-host = ＃ZooKeeper主机地址，格式为HOST：PORT。</p>
<p>＃DATA WEB（SpringDataWebProperties）<br>
spring.data.web.pageable.default页大小 = 20 ＃缺省页大小。<br>
spring.data.web.pageable.max-page-size = 2000 ＃要接受的最大页面大小。<br>
spring.data.web.pageable.one-indexed-parameters = false ＃是否公开和假设从1开始的页码索引。<br>
spring.data.web.pageable.page-parameter = page ＃页面索引参数名称。<br>
spring.data.web.pageable.prefix = ＃<br>
常用前缀，用于页码和页面大小参数。spring.data.web.pageable.qualifier-delimiter = _＃限定符与实际页码和大小属性之间使用的分隔符。<br>
spring.data.web.pageable.size-parameter = size ＃页面大小参数名称。<br>
spring.data.web.sort.sort-parameter = sort ＃排序参数名称。</p>
<p>#DATASOURCE （DataSourceAutoConfiguration＆DataSourceProperties）<br>
spring.datasource.continue-on-error = false ＃初始化数据库时是否发生错误时停止。<br>
spring.datasource.data = #Data （DML）脚本资源引用。<br>
spring.datasource.data-username = ＃用于执行DML脚本的数据库<br>
的用户名（如果不同）。spring.datasource.data-password = ＃执行DML脚本的数据库的密码（如果不同）。<br>
spring.datasource.dbcp2。* = ＃Commons DBCP2特定设置<br>
spring.datasource.driver-class-name =#JDBC驱动程序的完全限定名称。默认情况下，基于URL自动检测。<br>
spring.datasource.generate-unique-name = false ＃是否生成随机数据源名称。<br>
spring.datasource.hikari。* = ＃Hikari特定设置<br>
spring.datasource.initialization-mode = embedded ＃使用可用的DDL和DML脚本初始化数据源。<br>
spring.datasource.jmx-enabled = false ＃是否启用JMX支持（如果由基础池提供）。<br>
spring.datasource.jndi-name = ＃JNDI数据源的位置。设置时将忽略类，URL，用户名和密码。<br>
spring.datasource.name =＃数据源的名称。使用嵌入式数据库时默认为“testdb”。<br>
spring.datasource.password = ＃数据库的登录密码。<br>
spring.datasource.platform = all ＃在DDL或DML脚本中使用的平台（例如架构 -  $ {platform} .sql或data  -  $ {platform} .sql）。<br>
spring.datasource.schema = #Schema （DDL）脚本资源引用。<br>
spring.datasource.schema-username = ＃执行DDL脚本的数据库<br>
的用户名（如果不同）。spring.datasource.schema-password = ＃执行DDL脚本的数据库的密码（如果不同）。<br>
spring.datasource.separator =;#SQL初始化脚本中的语句分隔符。<br>
spring.datasource.sql-script-encoding = #SQL 脚本编码。<br>
spring.datasource.tomcat。* = ＃Tomcat数据源特定设置<br>
spring.datasource.type = ＃要使用的连接池实现的完全限定名称。默认情况下，它是从类路径中自动检测到的。<br>
spring.datasource.url = ＃JDBC数据库的URL。<br>
spring.datasource.username = ＃登录数据库的用户名。<br>
spring.datasource.xa.data-source-class-name = #XA 数据源完全限定名称。<br>
spring.datasource.xa.properties =＃传递给XA数据源的属性。</p>
<p>#JEST （Elasticsearch HTTP客户端）（JestProperties）<br>
spring.elasticsearch.jest.connection-timeout = 3s ＃连接超时。<br>
spring.elasticsearch.jest.multi-threaded = true ＃是否从多个执行线程启用连接请求。<br>
spring.elasticsearch.jest.password = ＃登录密码。<br>
spring.elasticsearch.jest.proxy.host = #HTTP 客户端应使用的代理主机。<br>
spring.elasticsearch.jest.proxy.port = #HTTP 客户端应使用的代理端口。<br>
spring.elasticsearch.jest.read-timeout = 3s ＃读取超时。<br>
spring.elasticsearch.jest.uris = http：// localhost：9200＃逗号分隔的Elasticsearch实例列表。<br>
spring.elasticsearch.jest.username = ＃登录用户名。</p>
<p>#Elasticsearch REST客户端（RestClientProperties）<br>
spring.elasticsearch.rest.password = ＃凭据密码。<br>
spring.elasticsearch.rest.uris = http：// localhost：9200 ＃要使用的以逗号分隔的Elasticsearch实例列表。<br>
spring.elasticsearch.rest.username = ＃凭据用户名。</p>
<p>＃H2 Web控制台（H2ConsoleProperties）<br>
spring.h2.console.enabled = false ＃是否启用控制台。<br>
spring.h2.console.path = / h2-console ＃控制台可用的路径。<br>
spring.h2.console.settings.trace = false ＃是否启用跟踪输出。<br>
spring.h2.console.settings.web-allow-others = false ＃是否启用远程访问。</p>
<p>＃InfluxDB（InfluxDbProperties）<br>
spring.influx.password = ＃登录密码。<br>
spring.influx.url = 要连接的InfluxDB实例的URL。<br>
spring.influx.user = ＃登录用户。</p>
<p>＃JOOQ （JooqProperties）<br>
spring.jooq.sql-dialect = #SQL 方言使用。默认情况下自动检测。</p>
<p>#JDBC （JdbcProperties）<br>
spring.jdbc.template.fetch-size = -1 ＃需要更多行时应从数据库中提取的行数。<br>
spring.jdbc.template.max-rows = -1 ＃最大行数。<br>
spring.jdbc.template.query-timeout = ＃查询超时。默认是使用JDBC驱动程序的默认配置。如果未指定持续时间后缀，则将使用秒。</p>
<p>＃JPA （JpaBaseConfiguration，HibernateJpaAutoConfiguration）<br>
spring.data.jpa.repositories.bootstrap-mode = default #JAPA 存储库的Bootstrap模式。<br>
spring.data.jpa.repositories.enabled = true ＃是否启用JPA存储库。<br>
spring.jpa.database = ＃要操作的目标数据库，默认情况下自动检测。也可以使用“databasePlatform”属性进行设置。<br>
spring.jpa.database-platform = ＃要操作的目标数据库的名称，默认情况下自动检测。也可以使用“Database”枚举来设置。<br>
spring.jpa.generate-ddl = false ＃是否在启动时初始化架构。<br>
spring.jpa.hibernate.ddl-auto = ＃DDL模式。这实际上是“hibernate.hbm2ddl.auto”属性的快捷方式。使用嵌入式数据库时未默认为“create-drop”，并且未检测到架构管理器。否则，默认为“none”。<br>
spring.jpa.hibernate.naming.implicit-strategy = ＃隐式命名策略的完全限定名称。<br>
spring.jpa.hibernate.naming.physical-strategy = ＃物理命名策略的完全限定名称。<br>
spring.jpa.hibernate.use-new-id-generator-mappings = ＃是否将Hibernate的较新的IdentifierGenerator用于AUTO，TABLE和SEQUENCE。<br>
spring.jpa.mapping-resources =＃Mapping资源（相当于persistence.xml中的“mapping-file”条目）。<br>
spring.jpa.open-in-view = true ＃注册OpenEntityManagerInViewInterceptor。将JPA EntityManager绑定到线程以进行整个请求处理。<br>
spring.jpa.properties。* = ＃要在JPA提供程序上设置的其他本机属性。<br>
spring.jpa.show -sql = false ＃是否启用SQL语句的日志记录。</p>
<p>#JTA （JtaAutoConfiguration）<br>
spring.jta.enabled = true ＃是否启用JTA支持。<br>
spring.jta.log-dir = #Transaction logs目录。<br>
spring.jta.transaction-manager-id = #Transaction manager唯一标识符。</p>
<p>#ATOMIKOS（AtomikosProperties）<br>
spring.jta.atomikos.connectionfactory.borrow-connection-timeout = 30 ＃从池中借用连接的超时（以秒为单位）。<br>
spring.jta.atomikos.connectionfactory.ignore-session-transacted-flag = true ＃是否在创建会话时忽略事务处理标志。<br>
spring.jta.atomikos.connectionfactory.local-transaction-mode = false ＃是否需要本地事务。<br>
spring.jta.atomikos.connectionfactory.maintenance-interval = 60 ＃池维护线程运行之间的时间（以秒为单位）。<br>
spring.jta.atomikos.connectionfactory.max-idle-time = 60＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.atomikos.connectionfactory.max-lifetime = 0 ＃连接在被销毁之前可以合并的时间（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.connectionfactory.max-pool-size = 1 ＃池的最大大小。<br>
spring.jta.atomikos.connectionfactory.min-pool-size = 1 ＃池的最小大小。<br>
spring.jta.atomikos.connectionfactory.reap-timeout = 0 ＃借用连接的reap超时（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.connectionfactory.unique-resource-name = jmsConnectionFactory＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.atomikos.connectionfactory.xa-connection-factory-class-name = #XAConnectionFactory的供应商特定实现。<br>
spring.jta.atomikos.connectionfactory.xa-properties = ＃供应商特定的XA属性。<br>
spring.jta.atomikos.datasource.borrow-connection-timeout = 30 ＃从池中借用连接的超时时间（秒）。<br>
spring.jta.atomikos.datasource.concurrent-connection-validation = ＃是否使用并发连接验证。<br>
spring.jta.atomikos.datasource.default-isolation-level = ＃池提供的连接的默认隔离级别。<br>
spring.jta.atomikos.datasource.login-timeout = ＃用于建立数据库连接的超时（以秒为单位）。<br>
spring.jta.atomikos.datasource.maintenance-interval = 60 ＃池维护线程运行之间的时间（以秒为单位）。<br>
spring.jta.atomikos.datasource.max-idle-time = 60 ＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.atomikos.datasource.max-lifetime = 0 ＃连接在被销毁之前可以合并的时间（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.datasource.max-pool-size = 1 ＃池的最大大小。<br>
spring.jta.atomikos.datasource.min-pool-size = 1＃池的最小大小。<br>
spring.jta.atomikos.datasource.reap-timeout = 0 ＃借用连接的reap超时（以秒为单位）。0表示没有限制。<br>
spring.jta.atomikos.datasource.test-query = ＃用于在返回连接之前验证连接的SQL查询或语句。<br>
spring.jta.atomikos.datasource.unique-resource-name = dataSource ＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.atomikos.datasource.xa-data-source-class-name = #XAConnectionFactory的供应商特定实现。<br>
spring.jta.atomikos.datasource.xa-properties = ＃供应商特定的XA属性。<br>
spring.jta.atomikos.properties.allow-sub-transactions = true ＃指定是否允许子事务。<br>
spring.jta.atomikos.properties.checkpoint-interval = 500 ＃检查点之间的间隔，表示为两个检查点之间的日志写入次数。<br>
spring.jta.atomikos.properties.default -jta -timeout = 10000ms #JTA 事务的默认超时。<br>
spring.jta.atomikos.properties.default-max-wait-time-on-shutdown = 9223372036854775807 ＃正常关闭（no-force）等待事务完成的时间。<br>
spring.jta.atomikos.properties.enable-logging = true ＃是否启用磁盘日志记录。<br>
spring.jta.atomikos.properties.force-shutdown-on-vm-exit = false ＃虚拟机关闭是否应触发事务核心的强制关闭。<br>
spring.jta.atomikos.properties.log-base-dir = ＃应存储日志文件的目录。<br>
spring.jta.atomikos.properties.log-base-name = tmlog ＃Transactions日志文件基名。<br>
spring.jta.atomikos.properties.max-actives = 50 ＃最大活动事务数。<br>
spring.jta.atomikos.properties.max-timeout = 300000ms ＃事务允许的最大超时时间。<br>
spring.jta.atomikos.properties.recovery.delay = 10000ms ＃两次恢复扫描之间的延迟。<br>
spring.jta.atomikos.properties.recovery.forget- orphaned -log-entries-delay = 86400000ms ＃恢复之后的延迟可以清除挂起（'孤立'）日志条目。<br>
spring.jta.atomikos.properties.recovery.max-retries = 5 ＃在抛出异常之前提交事务的重试次数。<br>
spring.jta.atomikos.properties.recovery.retry-interval = 10000ms ＃重试尝试之间的延迟。<br>
spring.jta.atomikos.properties.serial-jta-transactions = true ＃是否应尽可能加入子事务。<br>
spring.jta.atomikos.properties.service = ＃应该启动的事务管理器实现。<br>
spring.jta.atomikos.properties.threaded-two-phase-commit = false ＃是否对参与资源使用不同（和并发）线程进行两阶段提交。<br>
spring.jta.atomikos.properties.transaction-manager-unique-name = ＃事务管理器的唯一名称。</p>
<p>＃BITRONIX<br>
spring.jta.bitronix.connectionfactory.acquire-increment = 1 ＃在增长池时创建的连接数。<br>
spring.jta.bitronix.connectionfactory.acquisition-interval = 1 ＃获取无效连接后再次尝试获取连接之前等待的时间（以秒为单位）。<br>
spring.jta.bitronix.connectionfactory.acquisition-timeout = 30 ＃从池中获取连接的超时时间（秒）。<br>
spring.jta.bitronix.connectionfactory.allow-local-transactions = true ＃事务管理器是否应该允许混合XA和非XA事务。<br>
spring.jta.bitronix.connectionfactory.apply-transaction-timeout = false＃是否应在登记时在XAResource上设置事务超时。<br>
spring.jta.bitronix.connectionfactory.automatic-enlisting-enabled = true ＃是否应自动登记和退出资源。<br>
spring.jta.bitronix.connectionfactory.cache-producer-consumers = true ＃是否应该缓存生产者和消费者。<br>
spring.jta.bitronix.connectionfactory.class-name = #XA 资源的底层实现类名。<br>
spring.jta.bitronix.connectionfactory.defer-connection-release = true ＃提供程序是否可以在同一连接上运行多个事务并支持事务交错。<br>
spring.jta.bitronix.connectionfactory.disabled= ＃是否禁用此资源，这意味着暂时禁止从其池中获取连接。<br>
spring.jta.bitronix.connectionfactory.driver-properties = ＃应在底层实现上设置的属性。<br>
spring.jta.bitronix.connectionfactory.failed = ＃将此资源生成器标记为失败。<br>
spring.jta.bitronix.connectionfactory.ignore-recovery-failures = false ＃是否应忽略恢复失败。<br>
spring.jta.bitronix.connectionfactory.max-idle-time = 60 ＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.bitronix.connectionfactory.max-pool-size = 10＃池的最大大小。0表示没有限制。<br>
spring.jta.bitronix.connectionfactory.min-pool-size = 0 ＃池的最小大小。<br>
spring.jta.bitronix.connectionfactory.password = ＃用于连接JMS提供程序的密码。<br>
spring.jta.bitronix.connectionfactory.share-transaction-connections = false ＃是否可以在事务上下文中共享处于ACCESSIBLE状态的连接。<br>
spring.jta.bitronix.connectionfactory.test-connections = true ＃从池中获取时是否应测试连接。<br>
spring.jta.bitronix.connectionfactory.two-pc-ordering-position = 1＃在两阶段提交期间此资源应采取的位置（始终是第一个是Integer.MIN_VALUE，总是最后一个是Integer.MAX_VALUE）。<br>
spring.jta.bitronix.connectionfactory.unique-name = jmsConnectionFactory ＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.bitronix.connectionfactory.use -tm<br>
-join = true ＃启动XAResources时是否应该使用TMJOIN。spring.jta.bitronix.connectionfactory.user = ＃用于连接到JMS提供程序的用户。<br>
spring.jta.bitronix.datasource.acquire-increment = 1 ＃在增长池时创建的连接数。<br>
spring.jta.bitronix.datasource.acquisition-interval = 1＃在获取无效连接后再次尝试获取连接之前等待的时间（以秒为单位）。<br>
spring.jta.bitronix.datasource.acquisition-timeout = 30 ＃从池中获取连接的超时时间（秒）。<br>
spring.jta.bitronix.datasource.allow-local-transactions = true ＃事务管理器是否应该允许混合XA和非XA事务。<br>
spring.jta.bitronix.datasource.apply-transaction-timeout = false ＃是否应在XAResource登记时设置事务超时。<br>
spring.jta.bitronix.datasource.automatic-enlisting-enabled = true ＃是否应自动登记和退出资源。<br>
spring.jta.bitronix.datasource.class-name = #XA 资源的底层实现类名。<br>
spring.jta.bitronix.datasource.cursor-holdability = ＃连接的默认光标可保持性。<br>
spring.jta.bitronix.datasource.defer-connection-release = true ＃数据库是否可以在同一连接上运行多个事务并支持事务交错。<br>
spring.jta.bitronix.datasource.disabled = ＃是否禁用此资源，这意味着暂时禁止从其池中获取连接。<br>
spring.jta.bitronix.datasource.driver-properties = ＃应在底层实现上设置的属性。<br>
spring.jta.bitronix.datasource.enable -jdbc4-connection-test = ＃从池中获取连接时是否调用Connection.isValid（）。<br>
spring.jta.bitronix.datasource.failed = ＃将此资源生成器标记为失败。<br>
spring.jta.bitronix.datasource.ignore-recovery-failures = false ＃是否应忽略恢复失败。<br>
spring.jta.bitronix.datasource.isolation-level = ＃连接的默认隔离级别。<br>
spring.jta.bitronix.datasource.local-auto-commit = ＃本地事务的默认自动提交模式。<br>
spring.jta.bitronix.datasource.login-timeout =＃建立数据库连接的超时时间（秒）。<br>
spring.jta.bitronix.datasource.max-idle-time = 60 ＃从池中清除连接的时间（以秒为单位）。<br>
spring.jta.bitronix.datasource.max-pool-size = 10 ＃池的最大大小。0表示没有限制。<br>
spring.jta.bitronix.datasource.min-pool-size = 0 ＃池的最小大小。<br>
spring.jta.bitronix.datasource.prepared-statement-cache-size = 0 ＃<br>
预准备语句缓存的目标大小。0禁用缓存。spring.jta.bitronix.datasource.share-transaction-connections = false＃是否可以在事务上下文中共享处于ACCESSIBLE状态的连接。<br>
spring.jta.bitronix.datasource.test-query = ＃用于在返回连接之前验证连接的SQL查询或语句。<br>
spring.jta.bitronix.datasource.two-pc-ordering-position = 1 ＃此资源在两阶段提交期间应采取的位置（始终首先是Integer.MIN_VALUE，并且始终是最后一个是Integer.MAX_VALUE）。<br>
spring.jta.bitronix.datasource.unique-name = dataSource ＃用于在恢复期间标识资源的唯一名称。<br>
spring.jta.bitronix.datasource.use -tm -join = true ＃启动XAResources时是否应该使用TMJOIN。<br>
spring.jta.bitronix.properties.allow-multiple-lrc = false ＃是否允许多个LRC资源登记到同一事务中。<br>
spring.jta.bitronix.properties.asynchronous2-pc = false ＃是否启用异步执行两阶段提交。<br>
spring.jta.bitronix.properties.background-recovery-interval-seconds = 60 ＃在后台运行恢复过程的时间间隔（以秒为单位）。<br>
spring.jta.bitronix.properties.current-node-only-recovery = true ＃是否仅恢复当前节点。<br>
spring.jta.bitronix.properties.debug-zero-resource-transaction = false＃是否记录创建和提交没有单个登记资源的事务调用堆栈。<br>
spring.jta.bitronix.properties.default-transaction-timeout = 60 ＃默认事务超时，以秒为单位。<br>
spring.jta.bitronix.properties.disable-jmx = false ＃是否启用JMX支持。<br>
spring.jta.bitronix.properties.exception-analyzer = ＃设置要使用的异常分析器实现的完全限定名称。<br>
spring.jta.bitronix.properties.filter-log-status = false ＃是否启用日志过滤，以便只写入强制日志。<br>
spring.jta.bitronix.properties.force-batching-enabled = true＃是否批量磁盘强制。<br>
spring.jta.bitronix.properties.forced-write-enabled = true ＃是否强制将日志记录到磁盘。<br>
spring.jta.bitronix.properties.graceful-shutdown-interval = 60 ＃TM在关闭时中止事务之前等待事务完成的最大秒数。<br>
spring.jta.bitronix.properties.jndi-transaction-synchronization-registry-name = ＃TransactionSynchronizationRegistry的JNDI名称。<br>
spring.jta.bitronix.properties.jndi-user-transaction-name = ＃UserTransaction的JNDI名称。<br>
spring.jta.bitronix.properties.journal = disk ＃期刊的名称。可以是'disk'，'null'或类名。<br>
spring.jta.bitronix.properties.log-part1-filename = btm1.tlog ＃日志的第一个片段的名称。<br>
spring.jta.bitronix.properties.log-part2-filename = btm2.tlog ＃日志的第二个片段的名称。<br>
spring.jta.bitronix.properties.max-log-size-in-mb = 2 ＃日志片段的最大大小（兆字节）。<br>
spring.jta.bitronix.properties.resource-configuration-filename = ＃ResourceLoader配置文件名。<br>
spring.jta.bitronix.properties.server-id = #ASCII ID必须唯一标识此TM实例。默认为机器的IP地址。<br>
spring.jta.bitronix.properties.skip-corrupted-logs = false#Skip损坏的事务日志条目。<br>
spring.jta.bitronix.properties.warn-about-zero-resource-transaction = true ＃是否为没有单个登记资源的事务记录警告。</p>
<p>＃EMBEDDED MONGODB（EmbeddedMongoProperties）<br>
spring.mongodb.embedded.features = sync_delay ＃逗号分隔的要启用的功能列表。<br>
spring.mongodb.embedded.storage.database-dir = ＃用于数据存储的目录。<br>
spring.mongodb.embedded.storage.oplog-size = #oplog的最大大小。<br>
spring.mongodb.embedded.storage.repl-set-name = ＃副本集的名称。<br>
spring.mongodb.embedded.version = 3.5.5 ＃要使用的Mongo版本。</p>
<p>#REDIS（RedisProperties）<br>
spring.redis.cluster.max -redirects = ＃在群集中执行命令时要遵循的最大重定向数。<br>
spring.redis.cluster.nodes = ＃逗号分隔的“host：port”对列表引导自。<br>
spring.redis.database = 0 ＃连接工厂使用的数据库索引。<br>
spring.redis.url = ＃连接URL。覆盖主机，端口和密码。用户被忽略。示例：redis：// user：password@example.com ：6379<br>
spring.redis.host = localhost ＃Redis服务器主机。<br>
spring.redis.jedis.pool.max-active = 8＃池在给定时间可以分配的最大连接数。使用负值无限制。<br>
spring.redis.jedis.pool.max-idle = 8 ＃池中“空闲”连接的最大数量。使用负值表示无限数量的空闲连接。<br>
spring.redis.jedis.pool.max -wait = -1ms ＃在池耗尽时，在抛出异常之前连接分配应该阻塞的最长时间。使用负值无限期阻止。<br>
spring.redis.jedis.pool.min-idle = 0 ＃目标是池中维护的最小空闲连接数。此设置仅在其为正时才有效。<br>
spring.redis.lettuce.pool.max-active = 8＃池在给定时间可以分配的最大连接数。使用负值无限制。<br>
spring.redis.lettuce.pool.max-idle = 8 ＃池中“空闲”连接的最大数量。使用负值表示无限数量的空闲连接。<br>
spring.redis.lettuce.pool.max -wait = -1ms ＃在池耗尽时，在抛出异常之前连接分配应阻塞的最长时间。使用负值无限期阻止。<br>
spring.redis.lettuce.pool.min-idle = 0 ＃目标是池中维护的最小空闲连接数。此设置仅在其为正时才有效。<br>
spring.redis.lettuce.shutdown-timeout = 100ms＃关机超时。<br>
spring.redis.password = ＃redis服务器的登录密码。<br>
spring.redis.port = 6379 #Redis服务器端口。<br>
spring.redis.sentinel.master = #Redis服务器的名称。<br>
spring.redis.sentinel.nodes = ＃逗号分隔的“host：port”对列表。<br>
spring.redis.ssl = false ＃是否启用SSL支持。<br>
spring.redis.timeout = ＃连接超时。</p>
<p>#TRANSACTION （TransactionProperties）<br>
spring.transaction.default-timeout = ＃默认事务超时。如果未指定持续时间后缀，则将使用秒。<br>
spring.transaction.rollback-on-commit-failure = ＃是否回滚提交失败。</p>
<p>＃----------------------------------------<br>
＃INTEGRATION PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#ACTIVEMQ（ActiveMQProperties）<br>
spring.activemq.broker-url = ActiveMQ代理的URL。默认情况下自动生成。<br>
spring.activemq.close-timeout = 15s ＃在考虑结束完成之前等待的时间。<br>
spring.activemq.in-memory = true ＃默认代理URL是否应该在内存中。如果已指定显式代理，则忽略。<br>
spring.activemq.non-blocking-redelivery = false ＃是否在从回滚事务重新传递消息之前停止消息传递。这意味着启用此消息顺序时不会保留消息顺序。<br>
spring.activemq.password = ＃代理的登录密码。<br>
spring.activemq.send-timeout = 0ms ＃等待消息发送响应的时间。将其设置为0以永远等待。<br>
spring.activemq.user = ＃代理的登录用户。<br>
spring.activemq.packages.trust-all = ＃是否信任所有包。<br>
spring.activemq.packages.trusted = ＃逗号分隔的要信任的特定包列表（不信任所有包时）。<br>
spring.activemq.pool.block-if-full = true ＃是否阻止请求连接并且池已满。将其设置为false以改为抛出“JMSException”。<br>
spring.activemq.pool.block-if-full-timeout = -1ms＃如果池仍然满，则在抛出异常之前阻塞。<br>
spring.activemq.pool.enabled = false ＃是否应创建JmsPoolConnectionFactory，而不是常规ConnectionFactory。<br>
spring.activemq.pool.idle-timeout = 30s ＃连接空闲超时。<br>
spring.activemq.pool.max-connections = 1 ＃最大池化连接数。<br>
spring.activemq.pool.max-sessions-per-connection = 500 ＃池中每个连接的最大池化会话数。<br>
spring.activemq.pool.time-between-expiration-check = -1ms ＃在空闲连接驱逐线程的运行之间休眠的时间。当为负时，没有空闲连接驱逐线程运行。<br>
spring.activemq.pool.use-anonymous-producer = true ＃是否只使用一个匿名“MessageProducer”实例。将其设置为false以在每次需要时创建一个“MessageProducer”。</p>
<p>#ARTEMIS （ArtemisProperties）<br>
spring.artemis.embedded.cluster-password = ＃群集密码。默认情况下在启动时随机生成。<br>
spring.artemis.embedded.data-directory = #Journal 文件目录。如果关闭持久性，则没有必要。<br>
spring.artemis.embedded.enabled = true ＃如果Artemis服务器API可用，是否启用嵌入模式。<br>
spring.artemis.embedded.persistent = false ＃是否启用持久存储。<br>
spring.artemis.embedded.queues = ＃逗号分隔的队列，在启动时创建。<br>
spring.artemis.embedded.server-id =＃服务器ID。默认情况下，使用自动递增的计数器。<br>
spring.artemis.embedded.topics = ＃在启动时要创建的以逗号分隔的主题列表。<br>
spring.artemis.host = localhost ＃Artemis broker主机。<br>
spring.artemis.mode = ＃Artemis部署模式，默认情况下自动检测。<br>
spring.artemis.password = ＃代理的登录密码。<br>
spring.artemis.pool.block-if-full = true ＃是否在请求连接且池已满时阻止。将其设置为false以改为抛出“JMSException”。<br>
spring.artemis.pool.block-if-full-timeout = -1ms ＃如果池仍然满，则在抛出异常之前阻塞。<br>
spring.artemis.pool.enabled = false ＃是否应创建JmsPoolConnectionFactory，而不是常规ConnectionFactory。<br>
spring.artemis.pool.idle-timeout = 30s ＃连接空闲超时。<br>
spring.artemis.pool.max-connections = 1 ＃池化连接的最大数量。<br>
spring.artemis.pool.max-sessions-per-connection = 500 ＃池中每个连接的最大池化会话数。<br>
spring.artemis.pool.time-between-expiration-check = -1ms ＃在空闲连接驱逐线程的运行之间休眠的时间。当为负时，没有空闲连接驱逐线程运行。<br>
spring.artemis.pool.use-anonymous-producers = true＃是否只使用一个匿名“MessageProducer”实例。将其设置为false以在每次需要时创建一个“MessageProducer”。<br>
spring.artemis.port = 61616 #Artemis 经纪人端口。<br>
spring.artemis.user = ＃代理的登录用户。</p>
<p>#SPRING BATCH（BatchProperties）<br>
spring.batch.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.batch.job.enabled = true ＃在启动时执行上下文中的所有Spring Batch作业。<br>
spring.batch.job.names = ＃逗号分隔的要在启动时执行的作业名称列表（例如，<code>job1，job2</code>）。默认情况下，将执行上下文中找到的所有作业。<br>
spring.batch.schema = classpath中：组织/ springframework的/批号/核心/ schema- @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。<br>
spring.batch.table-prefix =＃所有批次元数据表的表前缀。</p>
<p>#SPRING INTEGRATION（IntegrationProperties）<br>
spring.integration.jdbc.initialize-schema = embedded ＃数据库模式初始化模式。<br>
spring.integration.jdbc.schema = classpath中：组织/ springframework的/集成/ JDBC / schema- @ @ 平台@ @ .SQL ＃的路径SQL文件，以用于初始化数据库架构。</p>
<p>#JMS （JmsProperties）<br>
spring.jms.cache.consumers = false ＃是否缓存消息使用者。<br>
spring.jms.cache.enabled = true ＃是否缓存会话。<br>
spring.jms.cache.producers = true ＃是否缓存消息生成器。<br>
spring.jms.cache.session-cache-size = 1 ＃会话缓存的大小（根据JMS会话类型）。<br>
spring.jms.jndi-name = ＃连接工厂JNDI名称。设置时，优先于其他连接工厂自动配置。<br>
spring.jms.listener.acknowledge-mode = ＃容器的确认模式。默认情况下，侦听器使用自动确认进行事务处理。<br>
spring.jms.listener.auto-startup = true ＃启动时自动启动容器。<br>
spring.jms.listener.concurrency = ＃最小并发使用者数。<br>
spring.jms.listener.max-concurrency = ＃最大并发使用者数。<br>
spring.jms.pub-sub-domain = false ＃默认目标类型是否为topic。<br>
spring.jms.template.default-destination = ＃用于没有目标参数的发送和接收操作的默认目标。<br>
spring.jms.template.delivery-delay = ＃用于发送呼叫的传递延迟。<br>
spring.jms.template.delivery-mode =＃交付模式。设置时启用QoS（服务质量）。<br>
spring.jms.template.priority = ＃发送时消息的优先级。设置时启用QoS（服务质量）。<br>
spring.jms.template.qos-enabled = ＃发送消息时是否启用显式QoS（服务质量）。<br>
spring.jms.template.receive-timeout = ＃用于接收呼叫的超时。<br>
spring.jms.template.time-to-live = ＃发送时消息的生存时间。设置时启用QoS（服务质量）。</p>
<p>#APACHE KAFKA（KafkaProperties）<br>
spring.kafka.admin.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.admin.fail-fast = false ＃如果代理在启动时不可用，是否快速失败。<br>
spring.kafka.admin.properties。* = ＃用于配置客户端的其他特定于管理员的属性。<br>
spring.kafka.admin.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.admin.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.admin.ssl.key-store-password =＃存储密钥库文件的密码。<br>
spring.kafka.admin.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.admin.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.admin.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.admin.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.admin.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。除非被覆盖，否则适用于所有组件。<br>
spring.kafka.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.consumer.auto-commit-interval = ＃如果'enable.auto.commit'设置为true，则将消费者偏移自动提交给Kafka的频率。<br>
spring.kafka.consumer.auto-offset-reset = ＃当Kafka中没有初始偏移量或者服务器上不再存在当前偏移量时该怎么办。<br>
spring.kafka.consumer.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。为消费者覆盖全球财产。<br>
spring.kafka.consumer.client-id =#ID在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.consumer.enable-auto-commit = ＃是否在后台定期提交消费者的偏移量。<br>
spring.kafka.consumer.fetch-max-wait = ＃如果没有足够的数据立即满足“fetch-min-size”给出的要求，服务器在回答获取请求之前会阻塞的最长时间。<br>
spring.kafka.consumer.fetch-min-size = ＃服务器应为获取请求返回的最小数据量。<br>
spring.kafka.consumer.group-id = ＃唯一字符串，用于标识此使用者所属的使用者组。<br>
spring.kafka.consumer.heartbeat间隔= ＃心跳与消费者协调员之间的预期时间。<br>
spring.kafka.consumer.key-deserializer = #Deserializer 类的键。<br>
spring.kafka.consumer.max-poll-records = ＃一次调用poll（）时返回的最大记录数。<br>
spring.kafka.consumer.properties。* = ＃用于配置客户端的其他特定于使用者的属性。<br>
spring.kafka.consumer.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.consumer.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.consumer.ssl.key-store-password =＃存储密钥库文件的密码。<br>
spring.kafka.consumer.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.consumer.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.consumer.ssl.trust-store-location = ＃信任存储文件的位置。<br>
spring.kafka.consumer.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.consumer.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.consumer.value-deserializer = #Deserializer 类的值。<br>
spring.kafka.jaas.control-flag = required ＃登录配置的控制标志。<br>
spring.kafka.jaas.enabled = false ＃是否启用JAAS配置。<br>
spring.kafka.jaas.login-module = com.sun.security.auth.module.Krb5LoginModule ＃登录模块。<br>
spring.kafka.jaas.options = ＃其他JAAS选项。<br>
spring.kafka.listener.ack-count = ＃当ackMode为“COUNT”或“COUNT_TIME”时，偏移提交之间的记录数。<br>
spring.kafka.listener.ack-mode = ＃Listener AckMode。请参阅spring-kafka文档。<br>
spring.kafka.listener.ack-time = ＃当ackMode为“TIME”或“COUNT_TIME”时，偏移提交之间的时间。<br>
spring.kafka.listener.client-id =＃侦听器的使用者client.id属性的前缀。<br>
spring.kafka.listener.concurrency = ＃在侦听器容器中运行的线程数。<br>
spring.kafka.listener.idle-event-interval = ＃发布空闲消费者事件（未收到数据）之间的时间。<br>
spring.kafka.listener.log-container-config = ＃是否在初始化期间记录容器配置（INFO级别）。<br>
spring.kafka.listener.monitor-interval = ＃检查无响应的消费者之间的时间。如果未指定持续时间后缀，则将使用秒。<br>
spring.kafka.listener.no-poll-threshold =#Multiplier应用于“pollTimeout”以确定消费者是否无响应。<br>
spring.kafka.listener.poll-timeout = ＃轮询消费者时使用的超时。<br>
spring.kafka.listener.type = single ＃Listener类型。<br>
spring.kafka.producer.acks = ＃生产者要求领导者在考虑完成请求之前收到的确认数。<br>
spring.kafka.producer.batch-size = ＃默认批量大小。<br>
spring.kafka.producer.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。为生产者覆盖全球财产。<br>
spring.kafka.producer.buffer-memory = ＃生产者可用于缓冲等待发送到服务器的记录的总内存大小。<br>
spring.kafka.producer.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.producer.compression-type = ＃生产者生成的所有数据的压缩类型。<br>
spring.kafka.producer.key-serializer = ＃密码的Serializer类。<br>
spring.kafka.producer.properties。* = ＃用于配置客户端的其他特定于生产者的属性。<br>
spring.kafka.producer.retries = ＃大于零时，启用重试失败的发送。<br>
spring.kafka.producer.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.producer.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.producer.ssl.key-store-password = ＃存储密钥库文件的密码。<br>
spring.kafka.producer.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.producer.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.producer.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.producer.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.producer.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.producer.transaction-id-prefix = ＃非空时，为生产者启用事务支持。<br>
spring.kafka.producer.value-serializer = #Serializer 类的值。<br>
spring.kafka.properties。* = ＃用于配置客户端的生产者和使用者<br>
共有的附加属性。spring.kafka.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.ssl.key-store-password =＃存储密钥库文件的密码。<br>
spring.kafka.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.streams.application-id = #Kafka streams application.id property; 默认spring.application.name。<br>
spring.kafka.streams.auto-startup = true ＃是否自动启动流工厂bean。<br>
spring.kafka.streams.bootstrap-servers = ＃逗号分隔的主机：端口对列表，用于建立与Kafka集群的初始连接。覆盖流的全局属性。<br>
spring.kafka.streams.cache-max-size-buffering = ＃用于跨所有线程缓冲的最大内存大小。<br>
spring.kafka.streams.client-id = #ID 在发出请求时传递给服务器。用于服务器端日志记录。<br>
spring.kafka.streams.properties。* = ＃用于配置流的其他Kafka属性。<br>
spring.kafka.streams.replication-factor =＃流处理应用程序创建的更改日志主题和重新分区主题的复制因子。<br>
spring.kafka.streams.ssl.key-password = ＃密钥库文件中私钥的密码。<br>
spring.kafka.streams.ssl.key-store-location = ＃密钥库文件的位置。<br>
spring.kafka.streams.ssl.key-store-password = ＃存储密钥库文件的密码。<br>
spring.kafka.streams.ssl.key-store-type = ＃密钥库的类型。<br>
spring.kafka.streams.ssl.protocol = ＃要使用的SSL协议。<br>
spring.kafka.streams.ssl.trust-store-location = ＃信任库文件的位置。<br>
spring.kafka.streams.ssl.trust-store-password = ＃存储信任存储文件的密码。<br>
spring.kafka.streams.ssl.trust-store-type = ＃信任库的类型。<br>
spring.kafka.streams.state-dir = ＃状态存储的目录位置。<br>
spring.kafka.template.default-topic = ＃发送消息的默认主题。</p>
<p>#RABBIT（RabbitProperties）<br>
spring.rabbitmq.addresses = ＃逗号分隔的客户端应连接的地址列表。<br>
spring.rabbitmq.cache.channel.checkout-timeout = ＃达到缓存大小后等待获取通道的持续时间。<br>
spring.rabbitmq.cache.channel.size = ＃要在缓存中保留的通道数。<br>
spring.rabbitmq.cache.connection.mode = channel ＃连接工厂缓存模式。<br>
spring.rabbitmq.cache.connection.size = ＃缓存的连接数。<br>
spring.rabbitmq.connection-timeout = ＃连接超时。将其设置为零以永远等待。<br>
spring.rabbitmq.dynamic = true ＃是否创建AmqpAdmin bean。<br>
spring.rabbitmq.host = localhost ＃RabbitMQ主机。<br>
spring.rabbitmq.listener.direct.acknowledge-mode = ＃容器的确认模式。<br>
spring.rabbitmq.listener.direct.auto-startup = true ＃是否在启动时自动启动容器。<br>
spring.rabbitmq.listener.direct.consumers-per-queue = ＃每个队列的消费者数量。<br>
spring.rabbitmq.listener.direct.default-requeue-rejected = ＃默认情况下，拒绝的交付是否重新排队。<br>
spring.rabbitmq.listener.direct.idle-event-interval =＃应该发布空闲容器事件的频率。<br>
spring.rabbitmq.listener.direct.missing-queues-fatal = false ＃如果容器声明的队列在代理上不可用，则是否失败。<br>
spring.rabbitmq.listener.direct.prefetch = ＃每个消费者可能未完成的未确认消息的最大数量。<br>
spring.rabbitmq.listener.direct.retry.enabled = false ＃是否启用发布重试。<br>
spring.rabbitmq.listener.direct.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。<br>
spring.rabbitmq.listener.direct.retry.max-attempts = 3＃传递邮件的最大尝试次数。<br>
spring.rabbitmq.listener.direct.retry.max -interval = 10000ms ＃尝试之间的最长持续时间。<br>
spring.rabbitmq.listener.direct.retry.multiplier = 1 ＃乘数应用于先前的重试间隔。<br>
spring.rabbitmq.listener.direct.retry.stateless = true ＃重试是无状态还是有状态。<br>
spring.rabbitmq.listener.simple.acknowledge-mode = ＃容器的确认模式。<br>
spring.rabbitmq.listener.simple.auto-startup = true ＃是否在启动时自动启动容器。<br>
spring.rabbitmq.listener.simple.concurrency =＃侦听器调用者线程的最小数量。<br>
spring.rabbitmq.listener.simple.default-requeue-rejected = ＃默认情况下，拒绝的交付是否重新排队。<br>
spring.rabbitmq.listener.simple.idle-event-interval = ＃应该发布空闲容器事件的频率。<br>
spring.rabbitmq.listener.simple.max-concurrency = ＃侦听器调用者线程的最大数量。<br>
spring.rabbitmq.listener.simple.missing-queues-fatal = true ＃如果容器声明的队列在代理上不可用，则是否失败和/或如果在运行时删除一个或多个队列，是否停止容器。<br>
spring.rabbitmq.listener.simple.prefetch =＃每个消费者可能未完成的未确认消息的最大数量。<br>
spring.rabbitmq.listener.simple.retry.enabled = false ＃是否启用发布重试。<br>
spring.rabbitmq.listener.simple.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。<br>
spring.rabbitmq.listener.simple.retry.max-attempts = 3 ＃传递邮件的最大尝试次数。<br>
spring.rabbitmq.listener.simple.retry.max -interval = 10000ms ＃尝试之间的最长持续时间。<br>
spring.rabbitmq.listener.simple.retry.multiplier = 1 ＃乘数应用于上一个重试间隔。<br>
spring.rabbitmq.listener.simple.retry.stateless = true ＃重试是无状态还是有状态。<br>
spring.rabbitmq.listener.simple.transaction-size = ＃确认模式为AUTO时要在acks之间处理的消息数。如果大于预取，则预取将增加到此值。<br>
spring.rabbitmq.listener.type = simple ＃Listener容器类型。<br>
spring.rabbitmq.password = guest ＃登录以对代理进行身份验证。<br>
spring.rabbitmq.port = 5672 ＃RabbitMQ端口。<br>
spring.rabbitmq.publisher-confirms = false ＃是否启用发布者确认。<br>
spring.rabbitmq.publisher-returns = false＃是否启用发布者返回。<br>
spring.rabbitmq.requested-heartbeat = ＃请求心跳超时; 零，没有。如果未指定持续时间后缀，则将使用秒。<br>
spring.rabbitmq.ssl.algorithm = #SSL 算法使用。默认情况下，由Rabbit客户端库配置。<br>
spring.rabbitmq.ssl.enabled = false ＃是否启用SSL支持。<br>
spring.rabbitmq.ssl.key-store = ＃保存SSL证书的密钥库的路径。<br>
spring.rabbitmq.ssl.key-store-password = ＃用于访问密钥库的密码。<br>
spring.rabbitmq.ssl.key-store-type = PKCS12 ＃密钥库类型。<br>
spring.rabbitmq.ssl.trust-store = ＃持有SSL证书的信任存储。<br>
spring.rabbitmq.ssl.trust-store-password = ＃用于访问信任库的密码。<br>
spring.rabbitmq.ssl.trust-store-type = JKS #Trust store type。<br>
spring.rabbitmq.ssl.validate-server-certificate = true ＃是否启用服务器端证书验证。<br>
spring.rabbitmq.ssl.verify-hostname = true ＃是否启用主机名验证。<br>
spring.rabbitmq.template.default-receive-queue = ＃从明确指定none时接收消息的默认队列的名称。<br>
spring.rabbitmq.template.exchange =＃用于发送操作的默认交换的名称。<br>
spring.rabbitmq.template.mandatory = ＃是否启用强制消息。<br>
spring.rabbitmq.template.receive-timeout = ＃receive（）<code>操作的超时。 spring.rabbitmq.template.reply-timeout = #outoutout用于</code>sendAndReceive（）`操作。<br>
spring.rabbitmq.template.retry.enabled = false ＃是否启用发布重试。<br>
spring.rabbitmq.template.retry.initial-interval = 1000ms ＃第一次和第二次尝试传递消息之间的持续时间。<br>
spring.rabbitmq.template.retry.max-attempts = 3 ＃传递邮件的最大尝试次数。<br>
spring.rabbitmq.template.retry.max -interval = 10000ms ＃尝试之间的最长持续时间。<br>
spring.rabbitmq.template.retry.multiplier = 1 ＃乘数应用于先前的重试间隔。<br>
spring.rabbitmq.template.routing-key = ＃用于发送操作的默认路由密钥的值。<br>
spring.rabbitmq.username = guest ＃登录用户以对代理进行身份验证。<br>
spring.rabbitmq.virtual-host = ＃连接到代理时使用的虚拟主机。</p>
<p>＃----------------------------------------<br>
＃ACTUATOR PROPERTIES<br>
＃----- -----------------------------------</p>
<p>#MANAGEMENT HTTP SERVER（ManagementServerProperties）<br>
management.server.add-application-context-header = false ＃在每个响应中添加“X-Application-Context”HTTP标头。<br>
management.server.address = ＃管理端点应绑定到的网络地址。需要自定义management.server.port。<br>
management.server.port = ＃管理端点HTTP端口（默认情况下使用与应用程序相同的端口）。配置其他端口以使用特定于管理的SSL。<br>
management.server.servlet.context-path = ＃管理端点context-path（例如，<code>/ management</code>）。需要自定义management.server.port。<br>
management.server.ssl.ciphers= ＃支持的SSL密码。<br>
management.server.ssl.client-auth = ＃客户端身份验证模式。<br>
management.server.ssl.enabled = true ＃是否启用SSL支持。<br>
management.server.ssl.enabled-protocols = ＃启用SSL协议。<br>
management.server.ssl.key-alias = ＃标识密钥库中密钥的别名。<br>
management.server.ssl.key-password = ＃用于访问密钥库中密钥的密码。<br>
management.server.ssl.key-store = ＃保存SSL证书的密钥库的路径（通常是jks文件）。<br>
management.server.ssl.key-store-password =＃用于访问密钥库的密码。<br>
management.server.ssl.key-store-provider = ＃密钥库的提供者。<br>
management.server.ssl.key-store-type = ＃密钥库的类型。<br>
management.server.ssl.protocol = TLS ＃要使用的SSL协议。<br>
management.server.ssl.trust-store = ＃持有SSL证书的信任存储。<br>
management.server.ssl.trust-store-password = ＃用于访问信任库的密码。<br>
management.server.ssl.trust-store-provider = ＃信任存储的提供者。<br>
management.server.ssl.trust-store-type = ＃信任库的类型。</p>
<p>#CLOUDFOUNDRY<br>
management.cloudfoundry.enabled = true ＃是否启用扩展的Cloud Foundry执行器端点。<br>
management.cloudfoundry.skip-ssl-validation = false ＃是否跳过Cloud Foundry执行器端点安全调用的SSL验证。</p>
<p>#ENDPOINTS GENERAL CONFIGURATION<br>
management.endpoints.enabled-by-default = ＃默认情况下是否启用或禁用所有端点。</p>
<p>#ENDPOINTS JMX CONFIGURATION（JmxEndpointProperties）<br>
management.endpoints.jmx.domain = org.springframework.boot #Endpoints JMX域名。如果设置，则回退到'spring.jmx.default-domain'。<br>
management.endpoints.jmx.exposure.include = * ＃应包含的端点ID或所有的“<em>”。<br>
management.endpoints.jmx.exposure.exclude = ＃应排除的端点ID或所有的'</em>'。<br>
management.endpoints.jmx.static-names = ＃附加的静态属性，附加到表示端点的MBean的所有ObjectName。</p>
<p>#ENDPOINTS WEB CONFIGURATION（WebEndpointProperties）<br>
management.endpoints.web.exposure.include = health，info ＃应包含的端点ID或所有的“<em>”。<br>
management.endpoints.web.exposure.exclude = ＃应排除的端点ID或所有的'</em>'。<br>
management.endpoints.web.base-path = / actuator #Web端点的基本路径。相对于server.servlet.context-path或management.server.servlet.context-path，如果配置了management.server.port。<br>
management.endpoints.web.path-mapping = ＃端点ID与应公开它们的路径之间的映射。</p>
<p>#ENDPOINTS CORS CONFIGURATION（CorsEndpointProperties）<br>
management.endpoints.web.cors.allow-credentials = ＃是否支持凭据。未设置时，不支持凭据。<br>
management.endpoints.web.cors.allowed-headers = ＃逗号分隔的请求中允许的标头列表。'<em>'允许所有标题。<br>
management.endpoints.web.cors.allowed-methods = ＃逗号分隔的允许方法列表。'</em>'允许所有方法。未设置时，默认为GET。<br>
management.endpoints.web.cors.allowed-origins = ＃逗号分隔的原始列表允许。'*'允许所有来源。未设置时，将禁用CORS支持。<br>
management.endpoints.web.cors.exposed-headers = ＃逗号分隔的标题列表，包含在响应中。<br>
management.endpoints.web.cors.max-age = 1800s ＃客户端缓存来自飞行前请求的响应的时间。如果未指定持续时间后缀，则将使用秒。</p>
<p>#AUDIT EVENTS ENDPOINT（AuditEventsEndpoint）<br>
management.endpoint.auditevents.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.auditevents.enabled = true ＃是否启用auditevents端点。</p>
<p>#BEANS ENDPOINT（BeansEndpoint）<br>
management.endpoint.beans.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.beans.enabled = true ＃是否启用beans端点。</p>
<p>#CACHES ENDPOINT（CachesEndpoint）<br>
management.endpoint.caches.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.caches.enabled = true ＃是否启用缓存端点。</p>
<p>＃条件报告ENDPOINT（ConditionsReportEndpoint）<br>
management.endpoint.conditions.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.conditions.enabled = true ＃是否启用条件端点。</p>
<p>#CONFIGURATION PROPERTIES REPORT ENDPOINT（ConfigurationPropertiesReportEndpoint，ConfigurationPropertiesReportEndpointProperties）<br>
management.endpoint.configprops.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.configprops.enabled = true ＃是否启用configprops端点。<br>
management.endpoint.configprops.keys-to-sanitize = password，secret，key，token，。* credentials。*，vcap_services，sun.java.command ＃应该清理的密钥。键可以是属性结尾的简单字符串或正则表达式。</p>
<p>#ENVEST ENDPOINT（EnvironmentEndpoint，EnvironmentEndpointProperties）<br>
management.endpoint.env.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.env.enabled = true ＃是否启用env端点。<br>
management.endpoint.env.keys-to-sanitize = password，secret，key，token，。* credentials。*，vcap_services，sun.java.command ＃应该清理的密钥。键可以是属性结尾的简单字符串或正则表达式。</p>
<p>#FLYWAY ENDPOINT（FlywayEndpoint）<br>
management.endpoint.flyway.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.flyway.enabled = true ＃是否启用flyway端点。</p>
<p>#HEEC ENDPOINT（HealthEndpoint，HealthEndpointProperties）<br>
management.endpoint.health.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.health.enabled = true ＃是否启用运行状况端点。<br>
management.endpoint.health.roles = ＃用于确定是否授权用户显示详细信息的角色。为空时，所有经过身份验证的用户都被授权。<br>
management.endpoint.health.show-details = never ＃何时显示完整的健康详细信息。</p>
<p>#HEAP DUMP ENDPOINT（HeapDumpWebEndpoint）<br>
management.endpoint.heapdump.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.heapdump.enabled = true ＃是否启用heapdump端点。</p>
<p>#HTTP TRACE ENDPOINT（HttpTraceEndpoint）<br>
management.endpoint.httptrace.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.httptrace.enabled = true ＃是否启用httptrace端点。</p>
<p>#INFO ENDPOINT（InfoEndpoint）<br>
info = ＃要添加到信息端点的任意属性。<br>
management.endpoint.info.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.info.enabled = true ＃是否启用信息端点。</p>
<p>#INTEGRATION GRAPH ENDPOINT（IntegrationGraphEndpoint）<br>
management.endpoint.integrationgraph.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.integrationgraph.enabled = true ＃是否启用集成图终结点。</p>
<p>#JOLOKIA ENDPOINT（JolokiaProperties）<br>
management.endpoint.jolokia.config。* = ＃Jolokia设置。有关更多详细信息，请参阅Jolokia的文档。<br>
management.endpoint.jolokia.enabled = true ＃是否启用jolokia端点。</p>
<p>#LIQUIBASE ENDPOINT（LiquibaseEndpoint）<br>
management.endpoint.liquibase.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.liquibase.enabled = true ＃是否启用liquibase端点。</p>
<p>#log FILE ENDPOINT（＃LOG LogFileWebEndpoint，LogFileWebEndpointProperties）<br>
management.endpoint.logfile.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.logfile.enabled = true ＃是否启用日志文件端点。<br>
management.endpoint.logfile.external-file = ＃要访问的外部日志文件。如果日志文件由输出重定向而不是日志记录系统本身写入，则可以使用。</p>
<p>＃LOGGERS ENDPOINT（LoggersEndpoint）<br>
management.endpoint.loggers.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.loggers.enabled = true ＃是否启用记录器端点。</p>
<p>#REQUEST MAPPING ENDPOINT（MappingsEndpoint）<br>
management.endpoint.mappings.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.mappings.enabled = true ＃是否启用映射端点。</p>
<p>#METRICS ENDPOINT（MetricsEndpoint）<br>
management.endpoint.metrics.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.metrics.enabled = true ＃是否启用指标端点。</p>
<p>#PROMETHEUS ENDPOINT（PrometheusScrapeEndpoint）<br>
management.endpoint.prometheus.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.prometheus.enabled = true ＃是否启用prometheus端点。</p>
<p>#STEEDEDED TASKS ENDPOINT（ScheduledTasksEndpoint）<br>
management.endpoint.scheduledtasks.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.scheduledtasks.enabled = true ＃是否启用scheduledtasks端点。</p>
<p>#SESSIONS ENDPOINT（SessionsEndpoint）<br>
management.endpoint.sessions.enabled = true ＃是否启用会话端点。</p>
<p>#SHUTDOWN ENDPOINT（ShutdownEndpoint）<br>
management.endpoint.shutdown.enabled = false ＃是否启用关闭端点。</p>
<p>#THREAD DUMP ENDPOINT（ThreadDumpEndpoint）<br>
management.endpoint.threaddump.cache.time-to-live = 0ms ＃可以缓存响应的最长时间。<br>
management.endpoint.threaddump.enabled = true ＃是否启用threaddump端点。</p>
<p>＃HEALTH INDICATORS<br>
management.health.db.enabled = true ＃是否启用数据库运行状况检查。<br>
management.health.cassandra.enabled = true ＃是否启用Cassandra运行状况检查。<br>
management.health.couchbase.enabled = true ＃是否启用Couchbase运行状况检查。<br>
management.health.defaults.enabled = true ＃是否启用默认健康指标。<br>
management.health.diskspace.enabled = true ＃是否启用磁盘空间运行状况检查。<br>
management.health.diskspace.path = ＃用于计算可用磁盘空间的路径。<br>
management.health.diskspace.threshold = 10MB＃应该可用的最小磁盘空间。<br>
management.health.elasticsearch.enabled = true ＃是否启用Elasticsearch运行状况检查。<br>
management.health.elasticsearch.indices = ＃逗号分隔的索引名称。<br>
management.health.elasticsearch.response-timeout = 100ms ＃等待集群响应的时间。<br>
management.health.influxdb.enabled = true ＃是否启用InfluxDB运行状况检查。<br>
management.health.jms.enabled = true ＃是否启用JMS运行状况检查。<br>
management.health.ldap.enabled = true ＃是否启用LDAP运行状况检查。<br>
management.health.mail.enabled = true＃是否启用邮件健康检查。<br>
management.health.mongo.enabled = true ＃是否启用MongoDB运行状况检查。<br>
management.health.neo4j.enabled = true ＃是否启用Neo4j运行状况检查。<br>
management.health.rabbit.enabled = true ＃是否启用RabbitMQ运行状况检查。<br>
management.health.redis.enabled = true ＃是否启用Redis运行状况检查。<br>
management.health.solr.enabled = true ＃是否启用Solr运行状况检查。<br>
management.health.status.http-mapping = ＃将健康状态映射到HTTP状态代码。默认情况下，已注册的运行状况映射到合理的默认值（例如，UP映射到200）。<br>
management.health.status.order = DOWN，OUT_OF_SERVICE，UP，UNKNOWN ＃以逗号分隔的健康状态列表，按严重程度排序。</p>
<p>#HTTP TRACING（HttpTraceProperties）<br>
management.trace.http.enabled = true ＃是否启用HTTP请求 - 响应跟踪。<br>
management.trace.http.include =请求标头，响应标头，cookie，错误＃要包含在跟踪中的项目。</p>
<p>#INFO CONTRIBUTORS（InfoContributorProperties）<br>
management.info.build.enabled = true ＃是否启用构建信息。<br>
management.info.defaults.enabled = true ＃是否启用默认信息贡献者。<br>
management.info.env.enabled = true ＃是否启用环境信息。<br>
management.info.git.enabled = true ＃是否启用git信息。<br>
management.info.git.mode = simple ＃用于公开git信息的模式。</p>
<p>#METRICS<br>
management.metrics.distribution.maximum-expected-value。* = ＃预计将以指定名称开始计量ID的最大值。<br>
management.metrics.distribution.minimum-expected-value。* = ＃预计将以指定名称开始的仪表ID的最小值。<br>
management.metrics.distribution.percentiles。* = ＃特定计算的非可聚合百分位数，用于以指定名称开始的仪表ID发送到后端。<br>
＃以指定名称开头的仪表ID的特定SLA边界。最长的比赛获胜。management.metrics.enable。* =management.metrics.distribution.percentiles-histogram。* = ＃是否以指定名称开头的米ID应发布百分位直方图。<br>
management.metrics.distribution.sla。* =<br>
＃是否应启用以指定名称开头的仪表ID。最长的匹配获胜，关键的“all”也可以用于配置所有的米。<br>
management.metrics.export.appoptics.api-token = #AppOptics API令牌。<br>
management.metrics.export.appoptics.batch-size = 500 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.appoptics.connect-timeout = 5s ＃对此后端的请求的连接超时。<br>
management.metrics.export.appoptics.enabled= true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.appoptics.host-tag = instance ＃将指标发送到AppOptics时将映射到“@host”的标记。<br>
management.metrics.export.appoptics.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.appoptics.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.appoptics.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.appoptics.uri = https://api.appoptics.com/v1/measurements# 将指标发送到的URI。<br>
management.metrics.export.atlas.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.atlas.config-refresh-frequency = 10s ＃从LWC服务刷新配置设置的频率。<br>
management.metrics.export.atlas.config-time-to-live = 150s #LWC服务订阅的生存时间。<br>
management.metrics.export.atlas.config-uri = http：// localhost：7101 / lwc / api / v1 / expressions / local-dev #Atlas LWC端点的URI，用于检索当前订阅。<br>
management.metrics.export.atlas.connect-timeout = 1s＃对此后端的请求的连接超时。<br>
management.metrics.export.atlas.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.atlas.eval-uri = http：// localhost：7101 / lwc / api / v1 / evaluate ＃用于评估订阅数据的Atlas LWC端点的URI。<br>
management.metrics.export.atlas.lwc-enabled = false ＃是否启用流式传输到Atlas LWC。<br>
management.metrics.export.atlas.meter-time-to-live = 15m ＃没有任何活动的米的生存时间。在此期限之后，仪表将被视为已过期且不会报告。<br>
management.metrics.export.atlas.num-threads = 2＃指标发布计划程序使用的线程数。<br>
management.metrics.export.atlas.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.atlas.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.atlas.uri = http：// localhost：7101 / api / v1 / publish #Atlas服务器的URI。<br>
management.metrics.export.datadog.api-key = ＃Datadog API密钥。<br>
management.metrics.export.datadog.application-key = ＃Datadog应用程序密钥。不是严格要求，但通过向Datadog发送仪表描述，类型和基本单位来改进Datadog体验。<br>
management.metrics.export.datadog.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.datadog.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.datadog.descriptions = true ＃是否将描述元数据发布到Datadog。将其关闭以最小化发送的元数据量。<br>
management.metrics.export.datadog.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.datadog.host-tag = instance＃将指标发送到Datadog时将映射到“主机”的标记。<br>
management.metrics.export.datadog.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.datadog.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.datadog.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.datadog.uri = https://app.datadoghq.com#management.metrics.export.dynatrace.api-token =#idex将指标发送到。如果需要将指标发布到到Datadog的内部代理，则可以使用此方法定义代理的位置。<br>
#Dynatrace身份验证令牌。<br>
management.metrics.export.dynatrace.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.dynatrace.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.dynatrace.device-id = 将度量标准导出到Dynatrace的自定义设备的ID。<br>
management.metrics.export.dynatrace.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.dynatrace.num-threads = 2＃指标发布计划程序使用的线程数。<br>
management.metrics.export.dynatrace.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.dynatrace.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.dynatrace.technology-type = java ＃导出的指标的技术类型。用于在Dynatrace UI中对逻辑技术名称下的度量标准进行分组。<br>
management.metrics.export.dynatrace.uri = 将指标发送到的URI。应该用于SaaS，自我管理的实例或通过内部代理途径。<br>
management.metrics.export.elastic.auto-create-index = true＃是否自动创建索引（如果不存在）。<br>
management.metrics.export.elastic.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.elastic.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.elastic.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.elastic.host = http：// localhost：9200 ＃将指标导出到的主机。<br>
management.metrics.export.elastic.index = metrics ＃将指标导出到的索引。<br>
management.metrics.export.elastic.index-date-format＃时间戳字段的名称。= yyyy-MM ＃用于滚动索引的索引日期格式。附加到索引名称后面加一个' - '。<br>
management.metrics.export.elastic.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.elastic.password = ＃弹性服务器的登录密码。<br>
management.metrics.export.elastic.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.elastic.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.elastic.timestamp-field-name = @timestamp management.metrics.export.elastic.user-name =<br>
＃弹性服务器的登录用户。<br>
management.metrics.export.ganglia.addressing-mode = multicast ＃UDP寻址模式，单播或多播。<br>
management.metrics.export.ganglia.duration- units =毫秒＃用于报告持续时间的基本时间单位。<br>
management.metrics.export.ganglia.enabled = true ＃是否启用向Ganglia导出指标。<br>
management.metrics.export.ganglia.host = localhost ＃Ganglia服务器的主机，用于接收导出的指标。<br>
management.metrics.export.ganglia.port = 8649 ＃Ganglia服务器端口，用于接收导出的指标。<br>
management.metrics.export.ganglia.protocol-version = 3.1 ＃Ganglia协议版本。必须是3.1或3.0。<br>
management.metrics.export.ganglia.rate- units = seconds ＃用于报告费率的基本时间单位。<br>
management.metrics.export.ganglia.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.ganglia.time-to-live = 1 ＃生活在Ganglia上的指标的时间。将多播生存时间设置为大于主机之间的跳数（路由器）的数量。<br>
management.metrics.export.graphite.duration-units =毫秒＃用于报告持续时间的基本时间单位。<br>
management.metrics.export.graphite.enabled = true＃是否启用将指标导出到Graphite。<br>
management.metrics.export.graphite.host = localhost ＃Graphite服务器的主机，用于接收导出的指标。<br>
management.metrics.export.graphite.port = 2004 ＃Graphite服务器的端口，用于接收导出的指标。<br>
management.metrics.export.graphite.protocol = pickled ＃在将数据发送到Graphite时使用的协议。<br>
management.metrics.export.graphite.rate-units = seconds ＃用于报告费率的基本时间单位。<br>
management.metrics.export.graphite.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.graphite.tags-as-prefix =＃对于默认命名约定，将指定的标记键转换为度量标准前缀的一部分。<br>
management.metrics.export.humio.api-token = ＃Humio API令牌。<br>
management.metrics.export.humio.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.humio.connect-timeout = 5s ＃对此后端的请求的连接超时。<br>
management.metrics.export.humio.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.humio.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.humio.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.humio.repository = sandbox ＃要将指标发布到的存储库的名称。<br>
management.metrics.export.humio.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.humio.tags。* = ＃Humio标签，用于描述将存储指标的数据源。Humio标签是与Micrometer标签不同的概念。千分尺的标签用于沿尺寸边界划分度量。<br>
management.metrics.export.humio.uri = https://cloud.humio.com#idex将指标发送到。如果您需要将指标发布到Humio的内部代理，您可以使用此方法定义代理的位置。<br>
management.metrics.export.influx.auto-create-db = true ＃在尝试向其发布指标之前，是否创建Influx数据库是否存在。<br>
management.metrics.export.influx.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.influx.compressed = true ＃是否对发布到Influx的度量批次启用GZIP压缩。<br>
management.metrics.export.influx.connect-timeout = 1s＃对此后端的请求的连接超时。<br>
management.metrics.export.influx.consistency = one ＃为每个点写一致性。<br>
management.metrics.export.influx.db = mydb ＃将指标发送到Influx时将映射到“主机”的标记。<br>
management.metrics.export.influx.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.influx.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.influx.password = ＃Influx服务器的登录密码。<br>
management.metrics.export.influx.read-timeout = 10s＃读取此后端请求的超时时间。<br>
management.metrics.export.influx.retention-duration = ＃Influx应在当前数据库中保留数据的时间段。<br>
management.metrics.export.influx.retention-shard-duration = ＃分片组覆盖的时间范围。<br>
management.metrics.export.influx.retention-policy = ＃要使用的保留策略（如果未指定，则Influx写入DEFAULT保留策略）。<br>
management.metrics.export.influx.retention-replication-factor = ＃在群集中存储了多少份数据副本。<br>
management.metrics.export.influx.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.influx.uri = http：// localhost：8086 ＃Influx服务器的URI。<br>
management.metrics.export.influx.user-name = ＃Influx服务器的登录用户。<br>
management.metrics.export.jmx.domain = metrics ＃Metrics JMX域名。<br>
management.metrics.export.jmx.enabled = true ＃是否已启用将度量标准导出到JMX。<br>
management.metrics.export.jmx.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.kairos.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.kairos.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.kairos.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.kairos.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.kairos.password = #KairosDB服务器的登录密码。<br>
management.metrics.export.kairos.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.kairos.step = 1m＃要使用的步长（即报告频率）。<br>
management.metrics.export.kairos.uri = localhost：8080 / api / v1 /  datapoints #KairosDB服务器的URI。<br>
management.metrics.export.kairos.user-name = #KairosDB服务器的登录用户。<br>
management.metrics.export.newrelic.account-id = ＃新Relic帐户ID。<br>
management.metrics.export.newrelic.api-key = #New Relic API密钥。<br>
management.metrics.export.newrelic.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.newrelic.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.newrelic.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.newrelic.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.newrelic.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.newrelic.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.newrelic.uri = https：//insights-collector.newrelic.com #idex 将指标发送到。<br>
management.metrics.export.prometheus.descriptions = true＃是否将发布描述作为scrape有效负载的一部分启用到Prometheus。将其关闭以最小化每次刮擦发送的数据量。<br>
management.metrics.export.prometheus.enabled = true ＃是否启用将指标导出到Prometheus。<br>
management.metrics.export.prometheus.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.prometheus.pushgateway.base-url = localhost：9091 ＃Pushgateway的基本URL。<br>
management.metrics.export.prometheus.pushgateway.enabled = false ＃通过Prometheus Pushgateway启用发布。<br>
management.metrics.export.prometheus.pushgateway.grouping-key =＃为推送的指标分组键。<br>
management.metrics.export.prometheus.pushgateway.job = ＃此应用程序实例的作业标识符。<br>
management.metrics.export.prometheus.pushgateway.push-rate = 1m ＃用于推送指标的频率。<br>
management.metrics.export.prometheus.pushgateway.shutdown-operation = ＃应该在关机时执行的操作。<br>
management.metrics.export.signalfx.access-token = #SignalFX访问令牌。<br>
management.metrics.export.signalfx.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.signalfx.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.signalfx.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.signalfx.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.signalfx.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.signalfx.source = ＃唯一标识正在向SignalFx发布指标的应用实例。默认为本地主机名。<br>
management.metrics.export.signalfx.step = 10s＃步骤大小（即报告频率）使用。<br>
management.metrics.export.signalfx.uri = https：//ingest.signalfx.com# 将指标发送到的URI。<br>
management.metrics.export.simple.enabled = true ＃在没有任何其他导出器的情况下，是否启用将指标导出到内存后端。<br>
management.metrics.export.simple.mode =累积＃计数模式。<br>
management.metrics.export.simple.step = 1m ＃要使用的步长（即报告频率）。<br>
management.metrics.export.statsd.enabled = true ＃是否启用将度量标准导出到StatsD。<br>
management.metrics.export.statsd.flavor = datadog#StatsD线路协议使用。<br>
management.metrics.export.statsd.host = localhost ＃StatsD服务器的主机，用于接收导出的指标。<br>
management.metrics.export.statsd.max-packet-length = 1400 ＃单个有效负载的总长度应保持在网络的MTU中。<br>
management.metrics.export.statsd.polling-frequency = 10s ＃测量仪表<br>
的频率。轮询仪表时，会重新计算其值，如果值已更改（或者publishUnchangedMeters为true），则会将其发送到StatsD服务器。management.metrics.export.statsd.port = 8125 ＃StatsD服务器的端口，用于接收导出的指标。<br>
management.metrics.export.statsd.publish-不变米= true ＃是否将未更改的计量表发送到StatsD服务器。<br>
management.metrics.export.wavefront.api-token = ＃将指标直接发布到Wavefront API主机时使用的API令牌。<br>
management.metrics.export.wavefront.batch-size = 10000 ＃每个请求用于此后端的度量数。如果找到更多测量值，则将发出多个请求。<br>
management.metrics.export.wavefront.connect-timeout = 1s ＃对此后端的请求的连接超时。<br>
management.metrics.export.wavefront.enabled = true ＃是否启用将度量标准导出到此后端。<br>
management.metrics.export.wavefront.global-prefix =＃全局前缀用于将源自此应用程序的白盒工具的度量标准与在Wavefront UI中查看时源自其他Wavefront集成的度量标准分开。<br>
management.metrics.export.wavefront.num-threads = 2 ＃指标发布计划程序使用的线程数。<br>
management.metrics.export.wavefront.read-timeout = 10s ＃读取此后端请求的超时时间。<br>
management.metrics.export.wavefront.source = ＃应用程序实例的唯一标识符，该实例是发布到Wavefront的度量标准的来源。默认为本地主机名。<br>
management.metrics.export.wavefront.step = 10s ＃要使用的步长（即报告频率）。<br>
management.metrics.export.wavefront.uri = https://longboard.wavefront.com# 将指标发送到的URI。<br>
management.metrics.use-global-registry = true ＃是否应将自动配置的MeterRegistry实现绑定到Metrics上的全局静态注册表。<br>
management.metrics.tags。* = ＃应用于每个仪表的公共标签。<br>
management.metrics.web.client.max-uri-tags = 100 ＃允许的唯一URI标记值的最大数量。达到最大标记值数后，过滤器将拒绝具有其他标记值的度量标准。<br>
management.metrics.web.client.requests-metric-name = http.client.requests ＃已发送请求的度量标准的名称。<br>
management.metrics.web.server.auto-time-requests = true ＃是否应自动为Spring MVC，WebFlux或Jersey处理的请求定时。<br>
management.metrics.web.server.max-uri-tags = 100 ＃允许的唯一URI标记值的最大数量。达到最大标记值数后，过滤器将拒绝具有其他标记值的度量标准。<br>
management.metrics.web.server.requests-metric-name = http.server.requests ＃已接收请求的度量标准的名称。<br>
＃----------------------------------------<br>
#DEDTOOLS PROPERTIES<br>
＃----- -----------------------------------<br>
#DESTOOLS（DevToolsProperties）<br>
spring.devtools.add-properties = true ＃是否启用开发属性默认值。<br>
spring.devtools.livereload.enabled = true ＃是否启用livereload.com兼容服务器。<br>
spring.devtools.livereload.port = 35729 ＃服务器端口。<br>
spring.devtools.restart.additional-exclude = ＃应该从触发完全重启中排除的其他模式。<br>
spring.devtools.restart.additional-paths = ＃要监视更改的其他路径。<br>
spring.devtools.restart.enabled = true ＃是否启用自动重启。<br>
spring.devtools.restart.exclude= META-INF /行家/ **，META-INF /资源/ **，资源/ **，静态/ **，公共/ *<em>，模板/ <strong>，</strong> / <em>的Test.class，</em></em> / * Tests.class，git.properties，META-INF / build-info.properties ＃应该从触发完全重启中排除的模式。<br>
spring.devtools.restart.log-condition-evaluation-delta = true ＃是否在重新启动时记录条件评估增量。<br>
spring.devtools.restart.poll-interval = 1s ＃轮询类路径更改之间等待的时间。<br>
spring.devtools.restart.quiet-period = 400ms ＃触发重启之前没有任何类路径更改所需的安静时间量。<br>
spring.devtools.restart.trigger-file =＃特定文件的名称，当更改时，触发重新启动检查。如果未指定，则任何类路径文件更改都会触发重新启动。<br>
#remote DEVTOOLS（RemoteDevToolsProperties）<br>
spring.devtools.remote.context-path = /。~~ spring-boot！〜＃用于处理远程连接的上下文路径。<br>
spring.devtools.remote.proxy.host = ＃用于连接远程应用程序的代理主机。<br>
spring.devtools.remote.proxy.port = ＃用于连接远程应用程序的代理端口。<br>
spring.devtools.remote.restart.enabled = true ＃是否启用远程重启。<br>
spring.devtools.remote.secret = ＃建立连接所需的共享密钥（启用远程支持所需）。<br>
spring.devtools.remote.secret头名= X-AUTH-TOKEN ＃用于传输共享密钥的HTTP头。<br>
＃----------------------------------------<br>
#TESTING PROPERTIES<br>
＃----- -----------------------------------<br>
spring.test.database.replace = any ＃要替换的现有DataSource的类型。<br>
spring.test.mockmvc.print =默认#MVC 打印选项。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务的数据库设计]]></title>
        <id>https://cm940324.github.io/post/weifuwu-sheji/</id>
        <link href="https://cm940324.github.io/post/weifuwu-sheji/">
        </link>
        <updated>2021-06-17T05:19:26.000Z</updated>
        <content type="html"><![CDATA[<h3 id="单独的数据库">单独的数据库：</h3>
<p>微服务设计的一个关键是数据库设计，基本原则是每个服务都有自己单独的数据库，而且只有微服务本身可以访问这个数据库。它是基于下面三个原因。</p>
<p><strong>优化服务接口</strong>：微服务之间的接口越小越好，最好只有服务调用接口（RPC或消息），没有其他接口。如果微服务不能独享自己的数据库，那么数据库也变成了接口的一部分，这大大拓展了接口范围。</p>
<p><strong>错误诊断</strong>：生产环境中的错误大部分都是和数据库有关的，要么是数据出了问题，要么是数据库的使用方式出了问题。当你不能完全控制数据库的访问时，会有各种各样的错误发生。它可能是别的程序直接连到你的数据库或者是其他部门直接用客户端访问数据库的数据，而这些都是在程序中查不到的，增加了错误排查难度。如果是程序中的问题，只要修改了代码，那么这个错误就不会再有。而上面提到的错误，你永远都没法预测它们什么时候还会再次发生。</p>
<p><strong>性能调优</strong>：性能调优也是一样，你需要对数据库有全权控制才能保证它的性能。如果其他部门一定要访问数据库，而且只是查询的话，那么可以另外创建一份只读数据库，让他们在另一个库中查询，这样才不会影响到你的库。</p>
<p>理想的设计是你的数据库只有你的服务能访问，你也只调用自己数据库中的数据，所有对别的微服务的访问都通过服务调用来实现（请参阅<a href="https://blog.csdn.net/weixin_38748858/article/details/101062272">“微服务之间调用的最佳设计“</a>）。当然，在实际应用中，单纯的服务调用可能不能满足性能或其他要求，不同的微服务都多少需要共享一些数据。</p>
<h3 id="共享数据">共享数据：</h3>
<p>微服务之间的数据共享可以有下四种方式。</p>
<h4 id="静态表">静态表：</h4>
<p>有一些静态的数据库表，例如国家，可能会被很多程序用到，而且程序内部需要对国家这个表做连接（join）生成最终用户展示数据，这样用微服务调用的方式就效率不高，影响性能。一个办法是在每个微服务中配置一个这样的表，它是只读的，这样就可以做数据库连接了。当然你需要保证数据同步。这个方案在多数情况下都是可以接受的，因为以下两点：</p>
<ol>
<li>静态的数据库表结构基本不变：因为一旦表结构变了，你不但要更改所有微服务的数据库表，还要修改所有微服务的程序。</li>
<li>数据库表中的数据变化不频繁：这样数据同步的工作量不大。另外当你同步数据库时总会有延迟，如果数据变化不频繁那么你有很多同步方式可供选择。</li>
</ol>
<h4 id="只读业务数据访问">只读业务数据访问：</h4>
<p>如果你需要读取别的数据库里的动态业务数据， 理想的方式是服务调用。如果你只是调用其他微服务做一些计算，一般情况下性能都是可以接受的。如果你需要做数据的连接，那么你可以用程序代码来做，而不是用SQL语句。如果测试之后性能不能满足要求，那你可以考虑在自己的数据库里建一套只读数据表。数据同步方式大致有两种。如果是事件驱动方式，就用发消息的方式进行同步，如果是RPC方式，就用数据库本身提供的同步方式或者第三方同步软件。<br>
通常情况下，你可能只需要其他数据库的几张表，每张表只需要几个字段。这时，其他数据库是数据的最终来源，控制所有写操作以及相应的业务验证逻辑，我们叫它主表。你的只读库可以叫从表。 当一条数据写入主表后，会发一条广播消息，所有拥有从表的微服务监听消息并更新只读表中的数据。但这时你要特别小心，因为它的危险性要比静态表大得多。第一它的表结构变更会更频繁，而且它的变更完全不受你控制。第二业务数据不像静态表，它是经常更新的，这样对数据同步的要求就比较高。要根据具体的业务需求来决定多大的延迟是可以接受的。<br>
另外它还有两个问题：</p>
<ol>
<li><strong>数据的容量</strong>：数据库中的数据量是影响性能的主要因素。因为这个数据是外来的，不利于掌握它的流量规律，很难进行容量规划，也不能更好地进行性能调优。</li>
<li><strong>接口外泄</strong>: 微服务之间的接口本来只有服务调用接口，这时你可以对内部程序和数据库做任何更改，而不影响其他服务。现在数据库表结构也变成了接口的一部分。接口一旦发布之后，基本是不能更改的，这大大限制了你的灵活性。幸运的是因为另外建了一套表，有了一个缓冲，当主表修改时，从表也许不需要同步更新。</li>
</ol>
<p>除非你能用服务调用（没有本地只读数据库）的方式完成所有功能，不然不管你是用RPC方式还是事件驱动方式进行微服务集成，上面提到的问题都是不可避免的。但是你可以通过合理规划数据库更改，来减少上面问题带来的影响，下面将会详细讲解。</p>
<h4 id="读写业务数据访问">读写业务数据访问：</h4>
<p>这是最复杂的一种情况。一般情况下，你有一个表是主表，而其他表是从表。主表包含主要信息，而且这些主要信息被复制到从表，但微服务会有额外字段需要写入从表。这样本地微服务对从表就既有读也有写的操作。而且主表和从表有一个先后次序的关系。从表的主键来源于主表，因此一定先有主表，再有从表。</p>
<p>假设我们有两个与电影有关的微服务，一个是电影论坛，用户可以发表对电影的评论。另一个是电影商店。“movie”是共享表，左边的一个是电影论坛库，它的“movie”表是主表。右边的是电影商店库，它的“movie”表是从表。它们共享“id”字段（主键）。主表是数据的主要来源，但从表里的“quantity”和“price”字段主表里面没有。主表插入数据后，发消息，从表接到消息，插入一条数据到本地“movie”表。并且从表还会修改表里的“quantity”和“price”字段。在这种情况下，要给每一个字段分配一个唯一源头（微服务），只有源头才有权利主动更改字段，其他微服务只能被动更改（接收源头发出的更改消息之后再改）。在本例子中， “quantity”和“price”字段的源头是右边的表，其他的字段的源头都是左边的表。本例子中“quantity”和“price”只在从表中存在，因此数据写入是单向的，方向是主表到从表。如果主表也需要这些字段，那么它们还要被回写，那数据写入就变成双向的。</p>
<h4 id="直接访问其它数据库">直接访问其它数据库：</h4>
<p>这种方式是要绝对禁止的。生产环境中的许多程序错误和性能问题都是由这种方式产生的。上面的三种方式由于是另外新建了本地只读数据库表，产生了数据库的物理隔离，这样一个数据库的性能问题不会影响到另一个。另外，当主库中的表结构更改时，你可以暂时保持从库中的表不变，这样程序还可以运行。如果直接访问别人的库，主库一修改，别的微服务程序马上就会报错。请参阅ApplicationDatabase。</p>
<h3 id="向后兼容的数据库更新">向后兼容的数据库更新：</h3>
<p>从上面的论述可以看出，数据库表结构的修改是一个影响范围很广的事情。在微服务架构中，共享的表在别的服务中也会有一个只读的拷贝。现在当你要更改表结构时，还需要考虑到对别的微服务的影响。当在单体（Monolithic）架构中，为了保证程序部署能够回滚，数据库的更新是向后兼容的。需要兼容性的另一个原因是支持蓝绿发布（Blue-Green Deployment）。在这种部署方式中，你同时拥有新旧版本的代码，由负载均衡来决定每一个请求指向那个版本。它们可以共享一个数据库（这就要求数据库是向后兼容的），也可以使用不同的数据。数据库的更新简单来讲有以下几种类型：<br>
<strong>增加表或字段</strong>：如果字段可取空值，这个操作是向后兼容的。如果是非空值就要插入一个缺省值。</p>
<p><strong>删除表或字段</strong>：可先暂时保留被删除表或字段，经过几个版本之后再删除。</p>
<p><strong>修改字段名</strong>：新增加一个字段，把数据从旧字段拷贝到新字段，用数据库触发器（或程序）同步旧字段和新字段（供过渡时期使用）。 然后再在几个版本之后把原来的字段删除（请参阅<a href="https://thoughts-on-java.org/update-database-schema-without-downtime/">Update your Database Schema Without Downtime</a>）。</p>
<p><strong>修改表名</strong>：如果数据库支持可更新视图，最简单的办法是先修改表的名字，然后创建一个可更新视图指向原来的表（请参阅<a href="https://martinfowler.com/articles/evodb.html">Evolutionary Database Design</a> ）。如果数据库不支持可更新视图，使用的方法与修改字段名相似，需要创建新的表并做数据同步。</p>
<p><strong>修改字段类型</strong>：与修改字段名几乎相同，只是在拷贝数据时，需要做数据类型转换。</p>
<p>向后兼容的数据库更新的好处是，当程序部署出现问题时，如需进行回滚。只要回滚程序就行了，而不必回滚数据库。回滚时一般只回滚一个版本。凡是需要删除的表或字段在本次部署时都不做修改，等到一个或几个版本之后，确认没有问题了再删除。它的另一个好处就是不会对其他微服务中的共享表产生立刻的直接影响。当本微服务升级后，其他微服务可以评估这些数据库更新带来的影响再决定是否需要做相应的程序或数据库修改。</p>
<h3 id="跨服务事物">跨服务事物：</h3>
<p>微服务的一个难点是如何实现跨服务的事物支持。两阶段提交（Two-Phase Commit）已被证明性能上不能满足需求，现在基本上没有人用。被一致认可的方法叫Saga。它的原理是为事物中的每个操作写一个补偿操作（Compensating Transaction），然后在回滚阶段挨个执行每一个补偿操作。示例如下图，在一个事物中共有3个操作T1，T2，T3。每一个操作要定义一个补偿操作，C1，C2，C3。事物执行时是按照正向顺序先执行T1，当回滚时是按照反向顺序先执行C3。 事物中的每一个操作（正向操作和补偿操作）都被包装成一个命令（Command），Saga执行协调器（Saga Execution Coordinator (SEC)）负责执行所有命令。在执行之前，所有的命令都会按顺序被存入日志中，然后Saga执行协调器从日志中取出命令，依次执行。当某个执行出现错误时，这个错误也被写入日志，并且所有正在执行的命令被停止，开始回滚操作。</p>
<p>Saga放松了对一致性（Consistency）的要求，它能保证的是最终一致性（Eventual Consistency），因此在事物执行过程中数据是不一致的，并且这种不一致会被别的进程看到。在生活中，大多数情况下，我们对一致性的要求并没有那么高，短暂的不一致性是可以接收的。例如银行的转账操作，它们在执行过程中都不是在一个数据库事物里执行的，而是用记账的方式分成两个动作来执行，保证的也是最终一致性。</p>
<p>Saga的原理看起来很简单，但要想正确的实施还是有一定难度的。它的核心问题在于对错误的处理，要把它完全讲明白需要另写一遍文章，我现在只讲一下要点。网络环境是不可靠的，正在执行的命令可能很长时间都没有返回结果，这时，第一，你要设定一个超时。第二，因为你不知道没有返回值的原因是，已经完成了命令但网络出了问题，还是没完成就牺牲了，因此不知道是否要执行补偿操作。这时正确的做法是重试原命令，直到得到完成确认，然后再执行补偿操作。但这对命令有一个要求，那就是这个操作必须是幂等的（Idempotent），也就是说它可以执行多次，但最终结果还是一样的。</p>
<p>另外，有些操作的补偿操作比较容易生成，例如付款操作，你只要把钱款退回就可以了。但有些操作，像发邮件，完成之后就没有办法回到之前的状态了，这时就只能再发一个邮件更正以前的信息。因此补偿操作不一定非要返回到原来的状态，而是抵消掉原来操作产生的效果。</p>
<h3 id="微服务的拆分">微服务的拆分：</h3>
<p>我们原来的程序大多数都是单体程序，但现在要把它拆分成微服务，应该怎样做才能降低对现有应用的影响呢？</p>
<p>假设我们要拆分出来一个微服务叫“client-service”，它需要访问“core client”表。第一步，我们先把程序从原来的代码里拆分出来，变成一个服务. 数据库不动，这个服务仍然指向原来的数据库。其他程序不再直接访问这个服务管理的表，而是通过服务调用或另建共享表来获取数据。</p>
<p>第二步，再把服务的数据库表拆分出来，这时微服务就拥有它自己的数据库了，而不再需要原来的共享数据库了。这时就成了一个真正意义上的的微服务。</p>
<p>上面只讲了拆分一个微服务，如果有多个需要拆分，则需一个一个按照上面讲的方法依次进行。</p>
<p>另外，Martin Fowler在他的文章&quot;Break Monolith into Microservices&quot;里有一个很好的建议。那就是，当你把服务从单体程序里拆分时，不要只想着把代码拆分出来。因为现在的需求可能已经跟原来有所不同，原先的设计可能也不太适用了。而且，技术也已更新，代码也要作相应的改造。更好的办法是重写原来的功能（而不是重写原来的代码），把重点放在拆分业务功能上，而不是拆分代码上，用新的设计和技术来实现这个业务功能。</p>
<h3 id="结论">结论：</h3>
<p>数据库设计是微服务设计的一个关键点，基本原则是每个微服务都有自己单独的数据库，而且只有微服务本身可以访问这个数据库。微服务之间的数据共享可以通过服务调用，或者主、从表的方式实现。在共享数据时，要找到合适的同步方式。在微服务架构中，数据库的修改影响广泛，需要保证这种修改是向后兼容的。实现跨服务事物的标准方法是Saga。当把单体程序拆分成微服务时，可以分步进行，以减少对现有程序的影响。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[两数之和]]></title>
        <id>https://cm940324.github.io/post/twonum/</id>
        <link href="https://cm940324.github.io/post/twonum/">
        </link>
        <updated>2021-06-11T01:50:16.000Z</updated>
        <content type="html"><![CDATA[<p>给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。你可以按任意顺序返回答案。<br>
示例 1：<br>
//输入：nums = [2,7,11,15], target = 9<br>
//输出：[0,1]<br>
//解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。</p>
<p>// 示例 2：<br>
//输入：nums = [3,2,4], target = 6<br>
//输出：[1,2]</p>
<p>// 示例 3：</p>
<p>//输入：nums = [3,3], target = 6<br>
//输出：[0,1]<br>
// 提示：</p>
<p>// 2 &lt;= nums.length &lt;= 104<br>
// -109 &lt;= nums[i] &lt;= 109<br>
// -109 &lt;= target &lt;= 109<br>
// 只会存在一个有效答案</p>
<p>// 进阶：你可以想出一个时间复杂度小于 O(n2) 的算法吗？<br>
// Related Topics 数组 哈希表</p>
<pre><code>class Solution {
    public int[] twoSum(int[] nums, int target) {
        Map&lt;Integer,Integer&gt; map = new HashMap&lt;&gt;();
        for (int i = 1; i &lt;= nums.length; i++) {
            if (map.contains(target - nums[i])){
                return new int[]{map.get(target - nums[i]),i};
            }
            map.put(map.contains(target - nums[i]), i);
        }
        return new int[0];
    }
    
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Data Rest---Paging and Sorting ]]></title>
        <id>https://cm940324.github.io/post/spring-data-rest-learn/</id>
        <link href="https://cm940324.github.io/post/spring-data-rest-learn/">
        </link>
        <updated>2021-06-10T07:11:22.000Z</updated>
        <content type="html"><![CDATA[<h3 id="1-paging">1. Paging</h3>
<p>Spring Data REST能识别含有分页和排序请求的URL，从而返回用户想要的数据，而不是直接返回一大堆数据集合。如果你继承PagingAndSortingRepository&lt;T, ID&gt;并获取实体类的列表集合，例如：</p>
<pre><code>interface PersonRepository extends PagingAndSortingRepository&lt;Person, Long&gt; {}
</code></pre>
<p>那么请求数据分页默认数为20个，也就是说第一次请求为20个数据，并带有分页的参数，如果想要自定义分页的参数，可以采用更改请求的URL参数的办法进行更改：</p>
<p><mark>http://localhost:8080/persons/?size=5</mark></p>
<p>如果要在你自己的查询方法中使用分页，需要在方法的参数中添加一个Pageable参数，这样获得的数据是一页数据(Page)而不是一个列表(List):</p>
<pre><code>@RestResource(path = &quot;nameStartsWith&quot;, rel = &quot;nameStartsWith&quot;)

public PagefindByNameStartsWith(@Param(&quot;name&quot;) String name, Pageable p);
</code></pre>
<p>这样的一个查询方法，会输出到链接：/people/search/nameStartsWith 并且会支持分页，这个原理和Spring Data Jpa的类似。</p>
<h3 id="2-previous-and-next-links">2. Previous and Next Links</h3>
<p>每个分页的response数据返回到前端页面，都有一个prev和next链接，比如在浏览器中请求 localhost:8080/people?size=5 后得到的数据如下：</p>
<pre><code>{
&quot;_links&quot; : {
	&quot;self&quot; : {
		&quot;href&quot; : &quot;http://localhost:8080/persons{&amp;sort,page,size}&quot;, 
	&quot;templated&quot; : true
	},
	&quot;next&quot; : {
		&quot;href&quot; : &quot;http://localhost:8080/persons?page=1&amp;size=5{&amp;sort}&quot;, 
		&quot;templated&quot; : true
	}
},
	&quot;_embedded&quot; : {
		... data ...
	},
	&quot;page&quot; : { ③
	&quot;size&quot; : 5,
	&lt;!-- &quot;totalElements&quot; : 50 --&gt;
	&quot;totalPages&quot; : 10,
	&quot;number&quot; : 0
}
</code></pre>
<p>这两个链接是指向下一级链接(next)和上一级(prev)的链接的地址</p>
<h3 id="3sorting">3.Sorting</h3>
<p>和Paging一样，Spring Data Rest识别含有排序的URL请求参数，实体类对应的同样有一个实体仓库。为了让数据按照自己想要的参数进行排序，可以在URL请求中添加一个name属性，并指定属性的排序方式，指定排序的方向(正向asc,逆向desc),比如：</p>
<pre><code class="language-html">http://localhost:8080/people/search/nameStartsWith?name=K&amp;sort=name,desc
</code></pre>
<p>这样一个语句是使用了定义在PersonRepository中的findByNameStartsWith查询方法进行查询所有Person的姓名中以字母K开头的并以name进行逆向排序的用户。通常为使用多个属性进行排序，往往可以添加sort=PROPERTY自己想要排序的参数进行排序。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[微服务：服务注册发现+ API 网关+配置中心+配置中心+服务跟踪]]></title>
        <id>https://cm940324.github.io/post/weifuwu-ques/</id>
        <link href="https://cm940324.github.io/post/weifuwu-ques/">
        </link>
        <updated>2021-06-07T07:00:17.000Z</updated>
        <content type="html"><![CDATA[<p><strong>服务注册发现</strong></p>
<p>服务注册就是维护一个登记簿，它管理系统内所有的服务地址。当新的服务启动后，它会向登记簿交待自己的地址信息。服务的依赖方直接向登记簿要 Service Provider 地址就行了。当下用于服务注册的工具非常多 ZooKeeper，Consul，Etcd, 还有 Netflix 家的 eureka 等。服务注册有两种:</p>
<p><strong>形式：客户端注册和第三方注册。</strong></p>
<p><strong>客户端注册（zookeeper</strong>）<br>
客户端注册是服务自身要负责注册与注销的工作。当服务启动后向注册中心注册自身，当服务下线时注销自己。期间还需要和注册中心保持心跳。心跳不一定要客户端来做，也可以由注册中心负责（这个过程叫探活）。这种方式的缺点是注册工作与服务耦合在一起，不同语言都要实现一套注册逻辑。</p>
<p><strong>第三方注册（独立的服务 Registrar）</strong></p>
<p>第三方注册由一个独立的服务Registrar负责注册与注销。当服务启动后以某种方式通知Registrar，然后 Registrar 负责向注册中心发起注册工作。同时注册中心要维护与服务之间的心跳，当服务不可用时，向注册中心注销服务。这种方式的缺点是 Registrar 必须是一个高可用的系统则注册工作没法进展。</p>
<p><strong>客户端发现</strong></p>
<p>客户端发现是指客户端负责查询可用服务地址，以及负载均衡的工作。这种方式最方便直接，而且也方便做负载均衡。再者一旦发现某个服务不可用立即换另外一个，非常直接。缺点也在于多语言时的重复工作，每个语言实现相同的逻辑。</p>
<p><strong>服务端发现</strong></p>
<p>服务端发现需要额外的 Router 服务，请求先打到 Router，然后 Router 负责查询服务与负载均衡。这种方式虽然没有客户端发现的缺点，但是它的缺点是保证 Router 的高可用。</p>
<p><strong>API 网关</strong><br>
API Gateway 是一个服务器，也可以说是进入系统的唯一节点。这跟面向对象设计模式中的<br>
Facade 模式很像。API Gateway 封装内部系统的架构，并且提供 API 给各个客户端。它还可能有其他功能，如授权、监控、负载均衡、缓存、请求分片和管理、静态响应处理等。下图展示了一个适应当前架构的 API Gateway。<br>
API Gateway 负责请求转发、合成和协议转换。所有来自客户端的请求都要先经过 API Gateway，然后路由这些请求到对应的微服务。API Gateway 将经常通过调用多个微服务来处理一个请求以及聚合多个服务的结果。它可以在 web 协议与内部使用的非 Web 友好型协议间进行转换，如HTTP 协议、WebSocket 协议。</p>
<p><strong>请求转发</strong></p>
<p>服务转发主要是对客户端的请求安装微服务的负载转发到不同的服务上</p>
<p><strong>响应合并</strong></p>
<p>把业务上需要调用多个服务接口才能完成的工作合并成一次调用对外统一提供服务。</p>
<p><strong>协议转换</strong></p>
<p>重点是支持 SOAP，JMS，Rest 间的协议转换。</p>
<p><strong>数据转换</strong></p>
<p>重点是支持 XML 和 Json 之间的报文格式转换能力（可选）</p>
<p><strong>安全认证</strong></p>
<ol>
<li>
<p>基于 Token 的客户端访问控制和安全策略</p>
</li>
<li>
<p>传输数据和报文加密，到服务端解密，需要在客户端有独立的 SDK 代理包</p>
</li>
<li>
<p>基于 Https 的传输加密，客户端和服务端数字证书支持</p>
</li>
<li>
<p>基于 OAuth2.0 的服务安全认证(授权码，客户端，密码模式等）</p>
</li>
</ol>
<p><strong>配置中心</strong><br>
配置中心一般用作系统的参数配置，它需要满足如下几个要求：高效获取、实时感知、分布式访问。</p>
<p><strong>zookeeper 配置中心</strong></p>
<p>采取数据加载到内存方式解决高效获取的问题，借助 zookeeper 的节点监听机制来实现实时感知。</p>
<p><strong>事件调度（kafka）</strong><br>
消息服务和事件的统一调度，常用用 kafka ，activemq 等。</p>
<p><strong>服务跟踪（starter-sleuth）</strong></p>
<p>随着微服务数量不断增长，需要跟踪一个请求从一个微服务到下一个微服务的传播过程， SpringCloud Sleuth 正是解决这个问题，它在日志中引入唯一 ID，以保证微服务调用之间的一致性，这样你就能跟踪某个请求是如何从一个微服务传递到下一个。</p>
<ol>
<li>
<p>为了实现请求跟踪，当请求发送到分布式系统的入口端点时，只需要服务跟踪框架为该请求创建一个唯一的跟踪标识，同时在分布式系统内部流转的时候，框架始终保持传递该唯一标识，直到返回给请求方为止，这个唯一标识就是前文中提到的 Trace ID。通过 Trace ID 的记录，我们就能将所有请求过程日志关联起来。</p>
</li>
<li>
<p>为了统计各处理单元的时间延迟，当请求达到各个服务组件时，或是处理逻辑到达某个状态时，也通过一个唯一标识来标记它的开始、具体过程以及结束，该标识就是我们前文中提到的 Span ID，对于每个 Span 来说，它必须有开始和结束两个节点，通过记录开始 Span 和结束 Span 的时间戳，就能统计出该 Span 的时间延迟，除了时间戳记录之外，它还可以包含一些其他元数据，比如：事件名称、请求信息等。</p>
</li>
<li>
<p>在快速入门示例中，我们轻松实现了日志级别的跟踪信息接入，这完全归功于spring-cloudstarter-sleuth 组件的实现。在 Spring Boot 应用中，通过在工程中引入 spring-cloud<br>
starter-sleuth 依赖之后， 它会自动的为当前应用构建起各通信通道的跟踪机制，比如：</p>
</li>
</ol>
<ul>
<li>通过诸如 RabbitMQ、Kafka（或者其他任何 Spring Cloud Stream 绑定器实现的消息<br>
中间件）传递的请求。</li>
<li>通过 Zuul 代理传递的请求。</li>
<li>通过 RestTemplate 发起的请求。</li>
</ul>
<p><strong>服务熔断（Hystrix）</strong><br>
在微服务架构中通常会有多个服务层调用，基础服务的故障可能会导致级联故障，进而造成整个系统不可用的情况，这种现象被称为服务雪崩效应。服务雪崩效应是一种因“服务提供者”的不可用导致“服务消费者”的不可用,并将不可用逐渐放大的过程。</p>
<p>熔断器的原理很简单，如同电力过载保护器。它可以实现快速失败，如果它在一段时间内侦测到许多类似的错误，会强迫其以后的多个调用快速失败，不再访问远程服务器，从而防止应用程序</p>
<p>不断地尝试执行可能会失败的操作，使得应用程序继续执行而不用等待修正错误，或者浪费 CPU时间去等到长时间的超时产生。熔断器也可以使应用程序能够诊断错误是否已经修正，如果已经修正，应用程序会再次尝试调用操作。</p>
<p><strong>Hystrix 断路器机制</strong></p>
<p>断路器很好理解, 当 Hystrix Command 请求后端服务失败数量超过一定比例(默认 50%), 断路器会切换到开路状态(Open). 这时所有请求会直接失败而不会发送到后端服务. 断路器保持在开路状态一段时间后(默认 5 秒), 自动切换到半开路状态(HALF-OPEN). 这时会判断下一次请求的返回情况,</p>
<p>如果请求成功, 断路器切回闭路状态(CLOSED), 否则重新切换到开路状态(OPEN). Hystrix 的断路器就像我们家庭电路中的保险丝, 一旦后端服务不可用, 断路器会直接切断请求链, 避免发送大量无效请求影响系统吞吐量, 并且断路器有自我检测并恢复的能力。</p>
<p><strong>API 管理</strong></p>
<p>SwaggerAPI 管理工具。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[hibernate CascadeType属性说明]]></title>
        <id>https://cm940324.github.io/post/hibernate-cascadetype/</id>
        <link href="https://cm940324.github.io/post/hibernate-cascadetype/">
        </link>
        <updated>2021-06-07T06:31:17.000Z</updated>
        <content type="html"><![CDATA[<h3 id="cascade属性-指定级联操作的行为可多选">cascade属性： 指定级联操作的行为(可多选)</h3>
<ul>
<li><strong>CascadeType.PERSIST 级联新增（又称级联保存）：</strong><br>
获取A对象里也同时也重新获取最新的B时的对象。即会重新查询数据库里的最新数据，并且，只有A类新增时，会级联B对象新增。若B对象在数据库存（跟新）在则抛异常（让B变为持久态），对应EntityManager的presist方法,调用JPA规范中的persist()，不适用于Hibernate的save()方法</li>
<li><strong>CascadeType.MERGE 级联合并（又称级联更新）</strong><br>
指A类新增或者变化，会级联B对象（新增或者变化） ，对应EntityManager的merge方法，调用JPA规范中merge()时，不适用于Hibernate的update()方法</li>
<li><strong>CascadeType.REMOVE 级联删除</strong><br>
只有A类删除时，会级联删除B类,即在设置的那一端进行删除时，另一端才会级联删除，对应EntityManager的remove方法，调用JPA规范中的remove()时，适用于Hibernate的delete()方法</li>
<li><strong>CascadeType.REFRESH 级联刷新</strong><br>
获取order（一或多）对象里也同时也重新获取最新的items（多）的对象，对应EntityManager的refresh(object)，调用JPA规范中的refresh()时，适用于Hibernate的flush()方法</li>
<li><strong>CascadeType.ALL</strong><br>
包含所有持久化方法</li>
</ul>
<p><strong>综上：大多数情况用CascadeType.MERGE就能达到级联跟新又不报错，用CascadeType.ALL时要斟酌下CascadeType.REMOVE</strong></p>
]]></content>
    </entry>
</feed>