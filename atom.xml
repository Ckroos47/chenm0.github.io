<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://chenm0.github.io/</id>
    <title>观潮亭</title>
    <updated>2021-12-02T07:30:24.014Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://chenm0.github.io/"/>
    <link rel="self" href="https://chenm0.github.io/atom.xml"/>
    <subtitle>&lt;a href=&quot;https://https://github.com/chenm0/&quot; target=&quot;_blank&quot;&gt;code blog&lt;/a&gt;</subtitle>
    <logo>https://chenm0.github.io/images/avatar.png</logo>
    <icon>https://chenm0.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 观潮亭</rights>
    <entry>
        <title type="html"><![CDATA[对象的finalization机制、finalize方法理解]]></title>
        <id>https://chenm0.github.io/post/finalize/</id>
        <link href="https://chenm0.github.io/post/finalize/">
        </link>
        <updated>2021-12-02T06:17:53.000Z</updated>
        <content type="html"><![CDATA[<h3 id="对象的finalization机制">对象的finalization机制</h3>
<p>Java提供了finalization机制来允许开发人员提供对象销毁之前自定义处理逻辑。垃圾在回收一个对象之前，总会先调用这个对象的finalize()方法，finalize()方法是object类定义的，允许在任何自类中被重写，用于对象被回收时进行资源释放。例如，关闭数据库连接等等。<br>
永远不要主动调用对象的finalize()方法，应该交给回收机制调用，理由如下：</p>
<ol>
<li>finalize()可能导致对象复活</li>
<li>finalize()执行时间没有保障，完全由GC线程决定，极端情况下，若不发生GC，finalize()就不会被调用</li>
<li>糟糕的finalize()会严重影响GC的性能<br>
如果从所有的根节点都无法访问到每个对象，说明对象已不再使用了。一般来说，此对象就应该jie sjhe由于finalize()方法的存在，虚拟机中的对象一般处于三种可能的状态：</li>
<li>可触及的：从根节点开始，可以到达这个对象</li>
<li>可复活的：对象的所有引用都被释放，但是对象可能在finalize()被复活(例如：在finalize()中又有新的引用指向该对象)。</li>
<li>不可触及的，对象的finalize()被调用之后，对象没有复活，那么会进入不可触及的状态。一般不可触及的对象不可能被复活，<B>因为finalize()只会调用一次   </B><br>
以上3种状态，由于finalize()方法的存在，进行区分，只有在对象不可触及的时候才可以被回收。<br>
如何判断一个对象是否可以被回收？</li>
<li>如果objA到GC Roots没有引用链，则进行第一次标记。（这里的标记意思是，对象是不可达的，对象可能是可复活的或者不可触及的。）</li>
<li>进行筛选，判断对象是否需要执行finalize()方法
<ul>
<li>如果对象objA没有重写finalize()方法，或者finalize()方法已经被虚拟机调用过，则虚拟机认 为“没有必要执行finalize()”，objA被判定为不可触及的</li>
<li>如果objA重写了finalize()方法，且还未执行过，那么objA会被插入到F-Queue队列中，由一个虚拟机自动创建的、低优先级的Finalizer线程触发其finalize()方法。</li>
<li>finalize()方法是对象逃脱死亡的最后机会，稍后GC会对F-Queue中的objA对象进行第二次标记，如果objA在finalize()方法中与引用链上的任何一个对象建立了联系（也就是复活了），那么第二次标记时，objA会被移出“即将回收”集合。之后，对象会再次出现没有引用存在的情况，在这个情况下，finalize()方法不会被再次调用，对象会直接变成不可触及状态。因为，一个对象的finalize()方法只会被调用一次。</li>
</ul>
</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[WeakHashMap的理解]]></title>
        <id>https://chenm0.github.io/post/weakhashmap/</id>
        <link href="https://chenm0.github.io/post/weakhashmap/">
        </link>
        <updated>2021-12-02T03:15:19.000Z</updated>
        <content type="html"><![CDATA[<p>WeakHashMap 继承于AbstractMap，实现了Map接口。<br>
和HashMap一样，WeakHashMap 也是一个散列表，它存储的内容也是键值对(key-value)映射，而且键和值都可以是null。<br>
不过WeakHashMap的键是“弱键”。在 WeakHashMap 中，当某个键不再正常使用时，会被从WeakHashMap中被自动移除。更精确地说，对于一个给定的键，其映射的存在并不阻止垃圾回收器对该键的丢弃，这就使该键成为可终止的，被终止，然后被回收。某个键被终止时，它对应的键值对也就从映射中有效地移除了。<br>
这个“弱键”的原理呢？大致上就是，通过WeakReference和ReferenceQueue实现的。 WeakHashMap的key是“弱键”，即是WeakReference类型的；ReferenceQueue是一个队列，它会保存被GC回收的“弱键”。实现步骤是：</p>
<ol>
<li>新建WeakHashMap，将“键值对”添加到WeakHashMap中。实际上，WeakHashMap是通过数组table保存Entry(键值对)；每一个Entry实际上是一个单向链表，即Entry是键值对链表。</li>
<li>当某“弱键”不再被其它对象引用，并被GC回收时。在GC回收该“弱键”时，这个“弱键”也同时会被添加到ReferenceQueue(queue)队列中。</li>
<li>当下一次我们需要操作WeakHashMap时，会先同步table和queue。table中保存了全部的键值对，而queue中保存被GC回收的键值对；同步它们，就是删除table中被GC回收的键值对。</li>
</ol>
<p>这就是“弱键”如何被自动从WeakHashMap中删除的步骤了。</p>
<p>和HashMap一样，WeakHashMap是不同步的。可以使用 Collections.synchronizedMap 方法来构造同步的 WeakHashMap。</p>
<p>既然有WeakHashMap，那么有WeakHashSet吗？  java collections包是没有直接提供WeakHashSet的。<br>
我们可以通过Collections.newSetFromMap(Map&lt;E,Boolean&gt; map)方法可以将任何 Map包装成一个Set。源码如下：</p>
<pre><code>public static &lt;E&gt; Set&lt;E&gt; newSetFromMap(Map&lt;E, Boolean&gt; map) {
        return new SetFromMap&lt;&gt;(map);
    }
 
    /**
     * @serial include
     */
    private static class SetFromMap&lt;E&gt; extends AbstractSet&lt;E&gt;
        implements Set&lt;E&gt;, Serializable
    {
        private final Map&lt;E, Boolean&gt; m;  // The backing map
        private transient Set&lt;E&gt; s;       // Its keySet
 
        SetFromMap(Map&lt;E, Boolean&gt; map) {
            if (!map.isEmpty())
                throw new IllegalArgumentException(&quot;Map is non-empty&quot;);
            m = map;
            s = map.keySet();
        }
 
        public void clear()               {        m.clear(); }
        public int size()                 { return m.size(); }
        public boolean isEmpty()          { return m.isEmpty(); }
        public boolean contains(Object o) { return m.containsKey(o); }
        public boolean remove(Object o)   { return m.remove(o) != null; }
        public boolean add(E e) { return m.put(e, Boolean.TRUE) == null; }
        public Iterator&lt;E&gt; iterator()     { return s.iterator(); }
        public Object[] toArray()         { return s.toArray(); }
        public &lt;T&gt; T[] toArray(T[] a)     { return s.toArray(a); }
        public String toString()          { return s.toString(); }
        public int hashCode()             { return s.hashCode(); }
        public boolean equals(Object o)   { return o == this || s.equals(o); }
        public boolean containsAll(Collection&lt;?&gt; c) {return s.containsAll(c);}
        public boolean removeAll(Collection&lt;?&gt; c)   {return s.removeAll(c);}
        public boolean retainAll(Collection&lt;?&gt; c)   {return s.retainAll(c);}
        ```
        就是对传入的map进行了简单的包装</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[java的垃圾回收]]></title>
        <id>https://chenm0.github.io/post/jvm-junk/</id>
        <link href="https://chenm0.github.io/post/jvm-junk/">
        </link>
        <updated>2021-12-02T01:29:51.000Z</updated>
        <content type="html"><![CDATA[<h3 id="什么是垃圾回收">什么是垃圾回收</h3>
<ul>
<li>垃圾回收(Garbage Collection,GC),顾名思义就是释放垃圾占用的空间，防止内存泄漏。有效的使用可以使用的内存，对内存对中已经死亡的或者长时间没有使用的对象进行清除和回收。</li>
<li>Java 语言出来之前，大家都在拼命的写 C 或者 C++ 的程序，而此时存在一个很大的矛盾，C++ 等语言创建对象要不断的去开辟空间，不用的时候又需要不断的去释放控件，既要写构造函数，又要写析构函数，很多时候都在重复的 allocated，然后不停的析构。于是，有人就提出，能不能写一段程序实现这块功能，每次创建，释放控件的时候复用这段代码，而无需重复的书写呢？</li>
<li>1960年，基于 MIT 的 Lisp 首先提出了垃圾回收的概念，用于处理C语言等不停的析构操作，而这时 Java 还没有出世呢！所以实际上 GC 并不是Java的专利，GC 的历史远远大于 Java 的历史！</li>
</ul>
<h3 id="怎么定义垃圾">怎么定义垃圾</h3>
<p>既然我们要做垃圾回收，首先我们得搞清楚垃圾的定义是什么，哪些内存是需要回收的。</p>
<h5 id="引用计数算法">引用计数算法</h5>
<p>引用计数算法（Reachability Counting）是通过在对象头中分配一个空间来保存该对象被引用的次数（Reference Count）。如果该对象被其它对象引用，则它的引用计数加1，如果删除对该对象的引用，那么它的引用计数就减1，当该对象的引用计数为0时，那么该对象就会被回收。</p>
<pre><code>String m = new String(&quot;jack&quot;);
</code></pre>
<p>先创建一个字符串，这时候&quot;jack&quot;有一个引用，就是 m。<br>
然后将 m 设置为 null，这时候&quot;jack&quot;的引用次数就等于0了，在引用计数算法中，意味着这块内容就需要被回收了<br>
引用计数算法是将垃圾回收分摊到整个应用程序的运行当中了，而不是在进行垃圾收集时，要挂起整个应用的运行，直到对堆中所有对象的处理都结束。因此，采用引用计数的垃圾收集不属于严格意义上的&quot;Stop-The-World&quot;的垃圾收集机制。<br>
看似很美好，但我们知道JVM的垃圾回收就是&quot;Stop-The-World&quot;的，那是什么原因导致我们最终放弃了引用计数算法呢？看下面的例子。</p>
<pre><code>public class ReferenceCountingGC {

public Object instance;

public ReferenceCountingGC(String name){}
}

public static void testGC(){

ReferenceCountingGC a = new ReferenceCountingGC(&quot;objA&quot;);
ReferenceCountingGC b = new ReferenceCountingGC(&quot;objB&quot;);

a.instance = b;
b.instance = a;

a = null;
b = null;
}
</code></pre>
<ol>
<li>定义2个对象</li>
<li>相互引用</li>
<li>置空各自的声明引用</li>
</ol>
<h5 id="可达性分析算法">可达性分析算法</h5>
<p><B><U>可达性分析算法</U></B>（Reachability Analysis）的基本思路是，通过一些被称为引用链（GC Roots）的对象作为起点，从这些节点开始向下搜索，搜索走过的路径被称为（Reference Chain)，当一个对象到 GC Roots 没有任何引用链相连时（即从 GC Roots 节点到该节点不可达），则证明该对象是不可用的。<br>
通过可达性算法，成功解决了引用计数所无法解决的问题-“循环依赖”，只要你无法与 GC Root 建立直接或间接的连接，系统就会判定你为可回收对象。那这样就引申出了另一个问题，哪些属于 GC Root。<br>
####### Java 内存区域<br>
在 Java 语言中，可作为 GC Root 的对象包括以下4种：</p>
<ul>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象</li>
<li>方法区中类静态属性引用的对象</li>
<li>方法区中常量引用的对象</li>
<li>本地方法栈中 JNI（即一般说的 Native 方法）引用的对象</li>
</ul>
<ol>
<li>虚拟机栈（栈帧中的本地变量表）中引用的对象<br>
此时的 s，即为 GC Root，当s置空时，localParameter 对象也断掉了与 GC Root 的引用链，将被回收。</li>
</ol>
<pre><code>public class StackLocalParameter {
public StackLocalParameter(String name){}
}

public static void testGC(){
StackLocalParameter s = new StackLocalParameter(&quot;localParameter&quot;);
s = null;
}
</code></pre>
<ol start="2">
<li>方法区中类静态属性引用的对象<br>
s 为 GC Root，s 置为 null，经过 GC 后，s 所指向的 properties 对象由于无法与 GC Root 建立关系被回收。<br>
而 m 作为类的静态属性，也属于 GC Root，parameter 对象依然与 GC root 建立着连接，所以此时 parameter 对象并不会被回收</li>
</ol>
<pre><code>public class MethodAreaStaicProperties {
public static MethodAreaStaicProperties m;
public MethodAreaStaicProperties(String name){}
}

public static void testGC(){
MethodAreaStaicProperties s = new MethodAreaStaicProperties(&quot;properties&quot;);
s.m = new MethodAreaStaicProperties(&quot;parameter&quot;);
s = null;
}
</code></pre>
<ol start="3">
<li>方法区中常量引用的对象<br>
m 即为方法区中的常量引用，也为 GC Root，s 置为 null 后，final 对象也不会因没有与 GC Root 建立联系而被回收。</li>
</ol>
<pre><code>public class MethodAreaStaicProperties {
public static final MethodAreaStaicProperties m = MethodAreaStaicProperties(&quot;final&quot;);
public MethodAreaStaicProperties(String name){}
}

public static void testGC(){
MethodAreaStaicProperties s = new MethodAreaStaicProperties(&quot;staticProperties&quot;);
s = null;
}
</code></pre>
<h6 id="本地方法栈中引用的对象">本地方法栈中引用的对象</h6>
<p>任何 native 接口都会使用某种本地方法栈，实现的本地方法接口是使用 C 连接模型的话，那么它的本地方法栈就是 C 栈。当线程调用 Java 方法时，虚拟机会创建一个新的栈帧并压入 Java 栈。然而当它调用的是本地方法时，虚拟机会保持 Java 栈不变，不再在线程的 Java 栈中压入新的帧，虚拟机只是简单地动态连接并直接调用指定的本地方法</p>
<h3 id="怎么回收垃圾">怎么回收垃圾</h3>
<p>在确定了哪些垃圾可以被回收后，垃圾收集器要做的事情就是开始进行垃圾回收，但是这里面涉及到一个问题是：如何高效地进行垃圾回收。由于Java虚拟机规范并没有对如何实现垃圾收集器做出明确的规定，因此各个厂商的虚拟机可以采用不同的方式来实现垃圾收集器，这里我们讨论几种常见的垃圾收集算法的核心思想。</p>
<h5 id="标记-清除算法">标记 --- 清除算法</h5>
<figure data-type="image" tabindex="1"><img src="https://chenm0.github.io//post-images/1638411983231.png" alt="" loading="lazy"></figure>
<p>标记清除算法（Mark-Sweep）是最基础的一种垃圾回收算法，它分为2部分，先把内存区域中的这些对象进行标记，哪些属于可回收标记出来，然后把这些垃圾拎出来清理掉。就像上图一样，清理掉的垃圾就变成未使用的内存区域，等待被再次使用。<br>
这逻辑再清晰不过了，并且也很好操作，但它存在一个很大的问题，那就是内存碎片。<br>
上图中等方块的假设是 2M，小一些的是 1M，大一些的是 4M。等我们回收完，内存就会切成了很多段。我们知道开辟内存空间时，需要的是连续的内存区域，这时候我们需要一个 2M的内存区域，其中有2个 1M 是没法用的。这样就导致，其实我们本身还有这么多的内存的，但却用不了。</p>
<h5 id="复制算法">复制算法</h5>
<figure data-type="image" tabindex="2"><img src="https://chenm0.github.io//post-images/1638412127349.png" alt="" loading="lazy"></figure>
<p>复制算法（Copying）是在标记清除算法上演化而来，解决标记清除算法的内存碎片问题。它将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。保证了内存的连续可用，内存分配时也就不用考虑内存碎片等复杂情况，逻辑清晰，运行高效。<br>
上面的图很清楚，也很明显的暴露了另一个问题，合着我这140平的大三房，只能当70平米的小两房来使？代价实在太高。</p>
<h5 id="标记整理算法">标记整理算法</h5>
<figure data-type="image" tabindex="3"><img src="https://chenm0.github.io//post-images/1638412267837.jpg" alt="" loading="lazy"></figure>
<p>标记整理算法（Mark-Compact）标记过程仍然与标记 --- 清除算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，再清理掉端边界以外的内存区域。<br>
标记整理算法一方面在标记-清除算法上做了升级，解决了内存碎片的问题，也规避了复制算法只能利用一半内存区域的弊端。看起来很美好，但从上图可以看到，它对内存变动更频繁，需要整理所有存活对象的引用地址，在效率上比复制算法要差很多。</p>
<p>分代收集算法分代收集算法（Generational Collection）严格来说并不是一种思想或理论，而是融合上述3种基础的算法思想，而产生的针对不同情况所采用不同算法的一套组合拳。对象存活周期的不同将内存划分为几块。一般是把 Java 堆分为新生代和老年代，这样就可以根据各个年代的特点采用最适当的收集算法。在新生代中，每次垃圾收集时都发现有大批对象死去，只有少量存活，那就选用复制算法，只需要付出少量存活对象的复制成本就可以完成收集。而老年代中因为对象存活率高、没有额外空间对它进行分配担保，就必须使用标记-清理或者标记 --- 整理算法来进行回收。so，另一个问题来了，那内存区域到底被分为哪几块，每一块又有什么特别适合什么算法呢？</p>
<h3 id="内存模型与回收策略">内存模型与回收策略</h3>
<figure data-type="image" tabindex="4"><img src="https://chenm0.github.io//post-images/1638412505672.png" alt="" loading="lazy"></figure>
<p>Java 堆（Java Heap）是JVM所管理的内存中最大的一块，堆又是垃圾收集器管理的主要区域，这里我们主要分析一下 Java 堆的结构。</p>
<p>Java 堆主要分为2个区域-年轻代与老年代，其中年轻代又分 Eden 区和 Survivor 区，其中 Survivor 区又分 From 和 To 2个区。可能这时候大家会有疑问，为什么需要 Survivor 区，为什么Survivor 还要分2个区。不着急，我们从头到尾，看看对象到底是怎么来的，而它又是怎么没的。</p>
<h5 id="eden-区">Eden 区</h5>
<p>IBM 公司的专业研究表明，有将近98%的对象是朝生夕死，所以针对这一现状，大多数情况下，对象会在新生代 Eden 区中进行分配，当 Eden 区没有足够空间进行分配时，虚拟机会发起一次 Minor GC，Minor GC 相比 Major GC 更频繁，回收速度也更快。<br>
通过 Minor GC 之后，Eden 会被清空，Eden 区中绝大部分对象会被回收，而那些无需回收的存活对象，将会进到 Survivor 的 From 区（若 From 区不够，则直接进入 Old 区）。</p>
<h5 id="survivor-区">Survivor 区</h5>
<p>Survivor 区相当于是 Eden 区和 Old 区的一个缓冲，类似于我们交通灯中的黄灯。Survivor 又分为2个区，一个是 From 区，一个是 To 区。每次执行 Minor GC，会将 Eden 区和 From 存活的对象放到 Survivor 的 To 区（如果 To 区不够，则直接进入 Old 区）。</p>
<ol>
<li>为啥需要？<br>
不就是新生代到老年代么，直接 Eden 到 Old 不好了吗，为啥要这么复杂。想想如果没有 Survivor 区，Eden 区每进行一次 Minor GC，存活的对象就会被送到老年代，老年代很快就会被填满。而有很多对象虽然一次 Minor GC 没有消灭，但其实也并不会蹦跶多久，或许第二次，第三次就需要被清除。这时候移入老年区，很明显不是一个明智的决定。<br>
所以，Survivor 的存在意义就是减少被送到老年代的对象，进而减少 Major GC 的发生。Survivor 的预筛选保证，只有经历16次 Minor GC 还能在新生代中存活的对象，才会被送到老年代。</li>
<li>为啥需要俩？</li>
</ol>
<p>设置两个 Survivor 区最大的好处就是解决内存碎片化。</p>
<p>我们先假设一下，Survivor 如果只有一个区域会怎样。Minor GC 执行后，Eden 区被清空了，存活的对象放到了 Survivor 区，而之前 Survivor 区中的对象，可能也有一些是需要被清除的。问题来了，这时候我们怎么清除它们？在这种场景下，我们只能标记清除，而我们知道标记清除最大的问题就是内存碎片，在新生代这种经常会消亡的区域，采用标记清除必然会让内存产生严重的碎片化。因为 Survivor 有2个区域，所以每次 Minor GC，会将之前 Eden 区和 From 区中的存活对象复制到 To 区域。第二次 Minor GC 时，From 与 To 职责兑换，这时候会将 Eden 区和 To 区中的存活对象再复制到 From 区域，以此反复。</p>
<p>这种机制最大的好处就是，整个过程中，永远有一个 Survivor space 是空的，另一个非空的 Survivor space 是无碎片的。那么，Survivor 为什么不分更多块呢？比方说分成三个、四个、五个?显然，如果 Survivor 区再细分下去，每一块的空间就会比较小，容易导致 Survivor 区满，两块 Survivor 区可能是经过权衡之后的最佳方案。</p>
<h5 id="old-区">Old 区</h5>
<p>老年代占据着2/3的堆内存空间，只有在 Major GC 的时候才会进行清理，每次 GC 都会触发“Stop-The-World”。内存越大，STW 的时间也越长，所以内存也不仅仅是越大就越好。由于复制算法在对象存活率较高的老年代会进行很多次的复制操作，效率很低，所以老年代这里采用的是标记 --- 整理算法。</p>
<p>除了上述所说，在内存担保机制下，无法安置的对象会直接进到老年代，以下几种情况也会进入老年代</p>
<ol>
<li>大对象<br>
大对象指需要大量连续内存空间的对象，这部分对象不管是不是“朝生夕死”，都会直接进到老年代。这样做主要是为了避免在 Eden 区及2个 Survivor 区之间发生大量的内存复制。当你的系统有非常多“朝生夕死”的大对象时，得注意了。</li>
<li>长期存活对象<br>
虚拟机给每个对象定义了一个对象年龄（Age）计数器。正常情况下对象会不断的在 Survivor 的 From 区与 To 区之间移动，对象在 Survivor 区中没经历一次 Minor GC，年龄就增加1岁。当年龄增加到15岁时，这时候就会被转移到老年代。当然，这里的15，JVM 也支持进行特殊设置。</li>
<li>动态对象年龄<br>
虚拟机并不重视要求对象年龄必须到15岁，才会放入老年区，如果 Survivor 空间中相同年龄所有对象大小的综合大于 Survivor 空间的一般，年龄大于等于该年龄的对象就可以直接进去老年区，无需等你“成年”<br>
这其实有点类似于负载均衡，轮询是负载均衡的一种，保证每台机器都分得同样的请求。看似很均衡，但每台机的硬件不通，健康状况不同，我们还可以基于每台机接受的请求数，或每台机的响应时间等，来调整我们的负载均衡算法。</li>
</ol>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Volatile关键字解析]]></title>
        <id>https://chenm0.github.io/post/volatile/</id>
        <link href="https://chenm0.github.io/post/volatile/">
        </link>
        <updated>2021-11-25T07:23:21.000Z</updated>
        <content type="html"><![CDATA[<pre><code>由于volatile关键字是与java的内存模型有关的，所以需要对内存模型相关的概念和知识有所了解。
</code></pre>
<h3 id="内存模型的相关概念">内存模型的相关概念</h3>
<pre><code>计算机在执行程序时，每条指令都是在CPU中执行的，而在执行指令过程中，势必涉及到数据的读取和写入。由于程序运行过程中的临时数据是存放在主存（物理内存）当中的，这时就存在一个问题，由于CPU执行速度很快，而从内存读取数据和向内存写入数据的过程跟CPU执行指令的速度比起来要慢的多，因此如果任何时候对数据的操作都要通过和内存的交互来进行，会大大降低指令执行的速度。因此在CPU里面就有了&lt;B&gt;高速缓存&lt;/B&gt;。
也就是，当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。举个简单的例子，比如下面的这段代码：
</code></pre>
<pre><code>i = i + 1;
</code></pre>
<pre><code>当线程执行这个语句时，会先从主存当中读取i的值，然后复制一份到高速缓存当中，然后CPU执行指令对i进行加1操作，然后将数据写入高速缓存，最后将高速缓存中i最新的值刷新到主存当中。
这个代码在单线程中运行是没有任何问题的，但是在多线程中运行就会有问题了。在多核CPU中，每条线程可能运行于不同的CPU中，因此每个线程运行时有自己的高速缓存（对单核CPU来说，其实也会出现这种问题，只不过是以线程调度的形式来分别执行的）。
比如同时有2个线程执行这段代码，假如初始时i的值为0，那么我们希望两个线程执行完之后i的值变为2。但是事实会是这样吗？
可能存在下面一种情况：初始时，两个线程分别读取i的值存入各自所在的CPU的高速缓存当中，然后线程1进行加1操作，然后把i的最新值1写入到内存。此时线程2的高速缓存当中i的值还是0，进行加1操作之后，i的值为1，然后线程2把i的值写入内存。
最终结果i的值是1，而不是2。这就是著名的缓存一致性问题。通常称这种被多个线程访问的变量为共享变量。
也就是说，如果一个变量在多个CPU中都存在缓存（一般在多线程编程时才会出现），那么就可能存在缓存不一致的问题。
为了解决缓存不一致性问题，通常来说有以下2种解决方法：
</code></pre>
<ul>
<li>通过在总线加LOCK#锁的方式</li>
<li>通过缓存一致性协议<br>
这2种方式都是硬件层面上提供的方式。<br>
在早期的CPU当中，是通过在总线上加LOCK#锁的形式来解决缓存不一致的问题。因为CPU和其他部件进行通信都是通过总线来进行的，如果对总线加LOCK#锁的话，也就是说阻塞了其他CPU对其他部件访问（如内存），从而使得只能有一个CPU能使用这个变量的内存。比如上面例子中 如果一个线程在执行 i = i +1，如果在执行这段代码的过程中，在总线上发出了LCOK#锁的信号，那么只有等待这段代码完全执行完毕之后，其他CPU才能从变量i所在的内存读取变量，然后进行相应的操作。这样就解决了缓存不一致的问题。<br>
但是上面的方式会有一个问题，由于在锁住总线期间，其他CPU无法访问内存，导致效率低下。<br>
所以就出现了缓存一致性协议。最出名的就是Intel 的MESI协议，MESI协议保证了每个缓存中使用的共享变量的副本是一致的。它核心的思想是：当CPU写数据时，如果发现操作的变量是共享变量，即在其他CPU中也存在该变量的副本，会发出信号通知其他CPU将该变量的缓存行置为无效状态，因此当其他CPU需要读取这个变量时，发现自己缓存中缓存该变量的缓存行是无效的，那么它就会从内存重新读取。<br>
<img src="https://chenm0.github.io//post-images/1637826258727.jpg" alt="" loading="lazy"></li>
</ul>
<h3 id="并发编程中的三个概念">并发编程中的三个概念</h3>
<pre><code>在并发编程中，通常会遇到以下三个问题：原子性问题，可见性问题，有序性问题。
</code></pre>
<ul>
<li>原子性<br>
即一个操作或者多个操作 要么全部执行并且执行的过程不会被任何因素打断，要么就都不执行。<br>
<u>一个很经典的例子就是银行账户转账问题：</u><br>
比如从账户A向账户B转1000元，那么必然包括2个操作：从账户A减去1000元，往账户B加上1000元<br>
试想一下，如果这2个操作不具备原子性，会造成什么样的后果。假如从账户A减去1000元之后，操作突然中止。然后又从B取出了500元，取出500元之后，再执行 往账户B加上1000元 的操作。这样就会导致账户A虽然减去了1000元，但是账户B没有收到这个转过来的1000元。<br>
所以这2个操作必须要具备原子性才能保证不出现一些意外的问题。</li>
<li>可见性<br>
可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。<br>
举个简单的例子：</li>
</ul>
<pre><code>   //线程1执行的代码
int i = 0;
i = 10;
 
//线程2执行的代码
j = i;
</code></pre>
<pre><code>假若执行线程1的是CPU1，执行线程2的是CPU2。由上面的分析可知，当线程1执行 i =10这句时，会先把i的初始值加载到CPU1的高速缓存中，然后赋值为10，那么在CPU1的高速缓存当中i的值变为10了，却没有立即写入到主存当中。
此时线程2执行 j = i，它会先去主存读取i的值并加载到CPU2的缓存当中，注意此时内存当中i的值还是0，那么就会使得j的值为0，而不是10.
这就是可见性问题，线程1对变量i修改了之后，线程2没有立即看到线程1修改的值。
</code></pre>
<ul>
<li>有序性<br>
即程序执行的顺序按照代码的先后顺序执行：</li>
</ul>
<pre><code>int i = 0;              
boolean flag = false;
i = 1;                //语句1  
flag = true;  
</code></pre>
<pre><code>上面代码定义了一个int型变量，定义了一个boolean类型变量，然后分别对两个变量进行赋值操作。从代码顺序上看，语句1是在语句2前面的，那么JVM在真正执行这段代码的时候会保证语句1一定会在语句2前面执行吗？不一定，为什么呢？这里可能会发生指令重排序（Instruction Reorder）。
下面解释一下什么是指令重排序，一般来说，处理器为了提高程序运行效率，可能会对输入代码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最终执行结果和代码顺序执行的结果是一致的。
比如上面的代码中，语句1和语句2谁先执行对最终的程序结果并没有影响，那么就有可能在执行过程中，语句2先执行而语句1后执行。
虽然处理器会对指令进行重排序，但是它会保证程序最终结果会和代码顺序执行结果相同，因为处理器在进行重排序时是会考虑指令之间的数据依赖性，如果一个指令Instruction 2必须用到Instruction 1的结果，那么处理器会保证Instruction 1会在Instruction 2之前执行。
虽然重排序不会影响单个线程内程序执行的结果，但是多线程呢？
</code></pre>
<pre><code>//线程1:
context = loadContext();   //语句1
inited = true;             //语句2
 
//线程2:
while(!inited ){
  sleep()
}
doSomethingwithconfig(context);
</code></pre>
<pre><code>上面代码中，由于语句1和语句2没有数据依赖性，因此可能会被重排序。假如发生了重排序，在线程1执行过程中先执行语句2，而此是线程2会以为初始化工作已经完成，那么就会跳出while循环，去执行doSomethingwithconfig(context)方法，而此时context并没有被初始化，就会导致程序出错。

从上面可以看出，指令重排序不会影响单个线程的执行，但是会影响到线程并发执行的正确性。
也就是说，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有被保证，就有可能会导致程序运行不正确。
</code></pre>
<h3 id="java内存模型">JAVA内存模型</h3>
<pre><code>下面研究一下JAVA内存模型提供了哪些保证以及在java中提供了哪些方法和机制保证了多线程编程时的程序执行正确性。
在Java虚拟机规范中试图定义一种Java内存模型（Java Memory Model，JMM）来屏蔽各个硬件平台和操作系统的内存访问差异，以实现让Java程序在各种平台下都能达到一致的内存访问效果。那么Java内存模型规定了哪些东西呢，它定义了程序中变量的访问规则，往大一点说是定义了程序执行的次序。注意，为了获得较好的执行性能，Java内存模型并没有限制执行引擎使用处理器的寄存器或者高速缓存来提升指令执行速度，也没有限制编译器对指令进行重排序。也就是说，在java内存模型中，也会存在缓存一致性问题和指令重排序的问题。
Java内存模型规定所有的变量都是存在主存当中（类似于前面说的物理内存），每个线程都有自己的工作内存（类似于前面的高速缓存）。线程对变量的所有操作都必须在工作内存中进行，而不能直接对主存进行操作。并且每个线程不能访问其他线程的工作内存。
那么Java语言 本身对 原子性、可见性以及有序性提供了哪些保证呢？
</code></pre>
<ul>
<li>原子性<br>
在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。</li>
</ul>
<pre><code>x = 10;         //语句1
y = x;         //语句2
x++;           //语句3
x = x + 1;     //语句4
</code></pre>
<pre><code>上述代码的操作只有语句1是原子性操作，其他三个语句都不是原子性操作。

语句1是直接将数值10赋值给x，也就是说线程执行这个语句的会直接将数值10写入到工作内存中。
语句2实际上包含2个操作，它先要去读取x的值，再将x的值写入工作内存，虽然读取x的值以及 将x的值写入工作内存 这2个操作都是原子性操作，但是合起来就不是原子性操作了。
同样的，x++和 x = x+1包括3个操作：读取x的值，进行加1操作，写入新的值。

所以上面4个语句只有语句1的操作具备原子性。也就是说，只有简单的读取、赋值（而且必须是将数字赋值给某个变量，变量之间的相互赋值不是原子操作）才是原子操作。
不过这里有一点需要注意：在32位平台下，对64位数据的读取和赋值是需要通过两个操作来完成的，不能保证其原子性。但是好像在最新的JDK中，JVM已经保证对64位数据的读取和赋值也是原子性操作了。
从上面可以看出，Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。
</code></pre>
<ul>
<li>
<p>可见性<br>
对于可见性，Java提供了volatile关键字来保证可见性。<br>
当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。<br>
而普通的共享变量不能保证可见性，因为普通共享变量被修改之后，什么时候被写入主存是不确定的，当其他线程去读取时，此时内存中可能还是原来的旧值，因此无法保证可见性。<br>
另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。</p>
</li>
<li>
<p>有序性<br>
在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。<br>
在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。<br>
另外， <em><strong>Java内存模型具备一些先天的“有序性”，即不需要通过任何手段就能够得到保证的有序性，这个通常也称为 happens-before 原则。如果两个操作的执行次序无法从happens-before原则推导出来，那么它们就不能保证它们的有序性，虚拟机可以随意地对它们进行重排序。</strong></em><br>
happens-before原则（先行发生原则)：</p>
<ul>
<li>程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作</li>
<li>锁定规则：一个unLock操作先行发生于后面对同一个锁额lock操作</li>
<li>volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作</li>
<li>传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C</li>
<li>线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作</li>
<li>线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生</li>
<li>线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行</li>
<li>对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始<br>
前4条规则是比较重要的，后4条规则都是显而易见的。<br>
第二条规则也比较容易理解，也就是说无论在单线程中还是多线程中，同一个锁如果出于被锁定的状态，那么必须先对锁进行了释放操作，后面才能继续进行lock操作。<br>
第三条规则是一条比较重要的规则，也是后文将要重点讲述的内容。直观地解释就是，如果一个线程先去写一个变量，然后一个线程去进行读取，那么写入操作肯定会先行发生于读操作。<br>
第四条规则实际上就是体现happens-before原则具备传递性。</li>
</ul>
</li>
</ul>
<h3 id="深入剖析volatile关键字">深入剖析volatile关键字</h3>
<h5 id="volatile关键字的两层语义">volatile关键字的两层语义</h5>
<p>一旦一个共享变量（类的成员变量、类的静态成员变量）被volatile修饰之后，那么就具备了两层语义：</p>
<ul>
<li>保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。</li>
<li>禁止进行指令重排序。</li>
</ul>
<pre><code>//线程1
boolean stop = false;
while(!stop){
    doSomething();
}
 
//线程2
stop = true;
</code></pre>
<p><B>假如线程1先执行，线程2后执行</B><br>
这段代码会完全运行正确么？即一定会将线程中断么？不一定，也许在大多数时候，这个代码能够把线程中断，但是也有可能会导致无法中断线程（虽然这个可能性很小，但是只要一旦发生这种情况就会造成死循环了）。<br>
每个线程在运行过程中都有自己的工作内存，那么线程1在运行的时候，会将stop变量的值拷贝一份放在自己的工作内存当中。<br>
那么当线程2更改了stop变量的值之后，但是还没来得及写入主存当中，线程2转去做其他事情了，那么线程1由于不知道线程2对stop变量的更改，因此还会一直循环下去。<br>
但是用volatile修饰之后就变得不一样了：<br>
- 使用volatile关键字会强制将修改的值立即写入主存；<br>
- 使用volatile关键字的话，当线程2进行修改时，会导致线程1的工作内存中缓存变量stop的缓存行无效（反映到硬件层的话，就是CPU的L1或者L2缓存中对应的缓存行无效）；<br>
- 由于线程1的工作内存中缓存变量stop的缓存行无效，所以线程1再次读取变量stop的值时会去主存读取。<br>
那么在线程2修改stop值时（当然这里包括2个操作，修改线程2工作内存中的值，然后将修改后的值写入内存），会使得线程1的工作内存中缓存变量stop的缓存行无效，然后线程1读取时，发现自己的缓存行无效，它会等待缓存行对应的主存地址被更新之后，然后去对应的主存读取最新的值。那么线程1读取到的就是最新的正确的值。</p>
<h5 id="volatile保证原子性吗">volatile保证原子性吗？</h5>
<pre><code>从上面知道volatile关键字保证了操作的可见性，但是volatile能保证对变量的操作是原子性吗？
</code></pre>
<pre><code>    public class Test {
    public volatile int inc = 0;
     
    public void increase() {
        inc++;
    }
     
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
         
        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<pre><code>运行它会发现每次运行结果都不一致，都是一个小于10000的数字。
这里面就有一个误区，volatile关键字能保证可见性没有错，但是上面的程序错在没能保证原子性。可见性只能保证每次读取的是最新的值，但是volatile没办法保证对变量的操作的原子性。
而自增操作是不具备原子性的，它包括读取变量的原始值、进行加1操作、写入工作内存。那么就是说自增操作的三个子操作可能会分割开执行，就有可能导致下面这种情况出现：
假如某个时刻变量inc的值为10，
线程1对变量进行自增操作，线程1先读取了变量inc的原始值，然后线程1被阻塞了；
然后线程2对变量进行自增操作，线程2也去读取变量inc的原始值，由于线程1只是对变量inc进行读取操作，而没有对变量进行修改操作，所以不会导致线程2的工作内存中缓存变量inc的缓存行无效，所以线程2会直接去主存读取inc的值，发现inc的值时10，然后进行加1操作，并把11写入工作内存，最后写入主存。
那么两个线程分别进行了一次自增操作后，inc只增加了1。
需要注意：线程1对变量进行读取操作之后，被阻塞了的话，并没有对inc值进行修改。然后虽然volatile能保证线程2对变量inc的值读取是从内存中读取的，但是线程1没有进行修改，所以线程2根本就不会看到修改的值。
根源就在这里，自增操作不是原子性操作，而且volatile也无法保证对变量的任何操作都是原子性的。
把上面的代码改成以下任何一种都可以达到效果：
- 采用synchronized：
</code></pre>
<pre><code>public class Test {
    public  int inc = 0;
    
    public synchronized void increase() {
        inc++;
    }
    
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
        
        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<pre><code>-   采用Lock：
</code></pre>
<pre><code>public class Test {
    public  int inc = 0;
    Lock lock = new ReentrantLock();
    
    public  void increase() {
        lock.lock();
        try {
            inc++;
        } finally{
            lock.unlock();
        }
    }
    
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
        
        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<pre><code>-   采用AtomicInteger：
</code></pre>
<pre><code>public class Test {
    public  AtomicInteger inc = new AtomicInteger();
     
    public  void increase() {
        inc.getAndIncrement();
    }
    
    public static void main(String[] args) {
        final Test test = new Test();
        for(int i=0;i&lt;10;i++){
            new Thread(){
                public void run() {
                    for(int j=0;j&lt;1000;j++)
                        test.increase();
                };
            }.start();
        }
        
        while(Thread.activeCount()&gt;1)  //保证前面的线程都执行完
            Thread.yield();
        System.out.println(test.inc);
    }
}
</code></pre>
<pre><code>在java 1.5的java.util.concurrent.atomic包下提供了一些原子操作类，即对基本数据类型的 自增（加1操作），自减（减1操作）、以及加法操作（加一个数），减法操作（减一个数）进行了封装，保证这些操作是原子性操作。atomic是利用CAS来实现原子性操作的（Compare And Swap），CAS实际上是利用处理器提供的CMPXCHG指令实现的，而处理器执行CMPXCHG指令是一个原子性操作。
</code></pre>
<ul>
<li>volatile能保证有序性吗？<br>
volatile能在一定程度上保证有序性<br>
volatile关键字禁止指令重排序有两层意思：<br>
(1) 当程序执行到volatile变量的读操作或者写操作时，在其前面的操作的更改肯定全部已经进行，且结果已经对后面的操作可见；在其后面的操作肯定还没有进行<br>
(2) 在进行指令优化时，不能将在对volatile变量访问的语句放在其后面执行，也不能把volatile变量后面的语句放到其前面执行</li>
</ul>
<pre><code>//x、y为非volatile变量
//flag为volatile变量
 
x = 2;        //语句1
y = 0;        //语句2
flag = true;  //语句3
x = 4;         //语句4
y = -1;       //语句5
</code></pre>
<pre><code>由于flag变量为volatile变量，那么在进行指令重排序的过程的时候，不会将语句3放到语句1、语句2前面，也不会讲语句3放到语句4、语句5后面。但是要注意语句1和语句2的顺序、语句4和语句5的顺序是不作任何保证的。
并且volatile关键字能保证，执行到语句3时，语句1和语句2必定是执行完毕了的，且语句1和语句2的执行结果对语句3、语句4、语句5是可见的。
</code></pre>
<ul>
<li>volatile的原理和实现机制<br>
volatile到底如何保证可见性和禁止指令重排序的。<br>
下面这段话摘自《深入理解Java虚拟机》：</li>
</ul>
<p>“观察加入volatile关键字和没有加入volatile关键字时所生成的汇编代码发现，加入volatile关键字时，会多出一个lock前缀指令”</p>
<pre><code>lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能：
- 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；
- 它会强制将对缓存的修改操作立即写入主存；
- 如果是写操作，它会导致其他CPU中对应的缓存行无效。
</code></pre>
<h3 id="使用volatile关键字的场景">使用volatile关键字的场景</h3>
<pre><code>synchronized关键字是防止多个线程同时执行一段代码，那么就会很影响程序执行效率，而volatile关键字在某些情况下性能要优于synchronized，但是要注意volatile关键字是无法替代synchronized关键字的，因为volatile关键字无法保证操作的原子性。通常来说，使用volatile必须具备以下2个条件：
-   对变量的写操作不依赖于当前值
-   该变量没有包含在具有其他变量的不变式中
&lt;B&gt;实际上，这些条件表明，可以被写入 volatile 变量的这些有效值独立于任何程序的状态，包括变量的当前状态。上面的2个条件需要保证操作是原子性操作，才能保证使用volatile关键字的程序在并发时能够正确执行。&lt;/B&gt;
下面列举几个Java中使用volatile的几个场景。
-   状态标记量
</code></pre>
<pre><code>volatile boolean flag = false;
 
while(!flag){
    doSomething();
}
 
public void setFlag() {
    flag = true;
}
</code></pre>
<pre><code>volatile boolean inited = false;
//线程1:
context = loadContext();  
inited = true;            
 
//线程2:
while(!inited ){
sleep()
}
doSomethingwithconfig(context);
</code></pre>
<pre><code>-   double check
</code></pre>
<pre><code>class Singleton{
    private volatile static Singleton instance = null;
     
    private Singleton() {
         
    }
     
    public static Singleton getInstance() {
        if(instance==null) {
            synchronized (Singleton.class) {
                if(instance==null)
                    instance = new Singleton();
            }
        }
        return instance;
    }
}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Spring Cloud Gateway]]></title>
        <id>https://chenm0.github.io/post/spring-cloud-gateway/</id>
        <link href="https://chenm0.github.io/post/spring-cloud-gateway/">
        </link>
        <updated>2021-11-05T02:48:36.000Z</updated>
        <content type="html"><![CDATA[<h3 id="功能特征">功能特征</h3>
<p>基于Spring Framework 5, Project Reactor 和 Spring Boot 2.0 进行构建；</p>
<ul>
<li>动态路由：能够匹配任何请求属性；</li>
<li>集成 Spring Cloud 服务发现功能；</li>
<li>可以对路由指定 Predicate（断言）和 Filter（过滤器）；</li>
<li>易于编写的 Predicate（断言）和 Filter（过滤器）；</li>
<li>集成Hystrix的断路器功能；</li>
<li>请求限流功能；</li>
<li>支持路径重写</li>
</ul>
<figure data-type="image" tabindex="1"><img src="https://chenm0.github.io//post-images/1636080636945.jpg" alt="" loading="lazy"></figure>
<p>上图中是核心的流程图，最主要的就是Route、Predicates 和 Filters 作用于特定路由。</p>
<ol>
<li>Route：<strong>路由是网关的基本构件</strong>。它由ID、目标URI、谓词集合和过滤器集合定义。如果聚合谓词为真，则匹配路由。</li>
<li>Predicate：<strong>参照Java8的新特性Predicate</strong>。这允许开发人员匹配HTTP请求中的任何内容，比如头或参数。</li>
<li>Filter：可以在发送下游请求之前或之后修改请求和响应。</li>
</ol>
<p>** 我们为什么选择Gateway？**<br>
一方面因为Zuul已经进入了维护阶段，而且Gateway是SpringCloud团队研发的，是亲儿子产品，值得信赖。而且很多功能Zuul都没有；用起来也非常的简单便捷。<br>
Gateway是基于异步非阻塞(NIO)模型上进行开发的，性能方面不需要担心。虽然Netflix 早就发布了最新的 Zuul 2.x，但 Spring Cloud 貌似没有整合计划。而且Netflix相关组件都宣布进入维护期；不知前景如何？</p>
<h3 id="工作原理">工作原理</h3>
<p><img src="https://chenm0.github.io//post-images/1636080815399.jpg" alt="" loading="lazy"><br>
客户端向 Spring Cloud Gateway 发出请求。然后在 Gateway Handler Mapping 中找到与请求相匹配的路由，将其发送到 Gateway Web Handler。Handler 再通过指 定的过滤器链来将请求发送到我们实际的服务执行业务逻辑，然后返回。过滤器之间用虚线分开是因为过滤器可能会在发送代理请求之前（“pre”）或之后（“post”）执行业务逻辑。<br>
Filter在“pre”类型的过滤器可以做参数校验、权限校验、流量监控、日志输出、协议转换等，在“post”类型的过滤器中可以做响应内容、响应头的修改，日志的输出，流量监控等有着非常重要的作用。<br>
** 核心逻辑就是路由转发，执行过滤器链。**<br>
在上面的处理过程中，有一个重要的点就是讲请求和路由进行匹配，这时候就需要用到predicate，它是决定了一个请求走哪一个路由。</p>
<h3 id="predicate简介">predicate简介</h3>
<p>Predicate来自于java8的接口。Predicate接受一个输入参数，返回一个布尔值结果。该接口包含多种默认方法来将Predicate组合成其他复杂的逻辑（比如：与，或，非）。可以用于接口请求参数校验、判断新老数据是否有变化需要进行更新操作。add--与、or--或、negate--非。Spring Cloud Gateway内置了许多Predict,这些Predict的源码在org.springframework.cloud.gateway.handler.predicate包中<br>
<img src="https://chenm0.github.io//post-images/1636081078455.jpg" alt="" loading="lazy"><br>
在上图中，有很多类型的Predicate,比如说时间类型的Predicated（AfterRoutePredicateFactory BeforeRoutePredicateFactory BetweenRoutePredicateFactory），当只有满足特定时间要求的请求会进入到此predicate中，并交由router处理；cookie类型的CookieRoutePredicateFactory，指定的cookie满足正则匹配，才会进入此router;以及host、method、path、querparam、remoteaddr类型的predicate，每一种predicate都会对当前的客户端请求进行判断，是否满足当前的要求，如果满足则交给当前请求处理。如果有很多个Predicate，并且一个请求满足多个Predicate，则按照配置的顺序第一个生效。</p>
<ol>
<li>After Route Predicate Factory<br>
After Route Predicate Factory使用的是时间作为匹配规则，只要当前时间大于设定时间，路由才会匹配请求。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:    
        gateway:      
            routes:      
            - id: after_route        
              uri: http://www.google.com        
              predicates:        
              - After=2018-12-25T14:33:47.789+08:00
</code></pre>
<p><u>这个路由规则会在东8区的2018-12-25 14:33:47后，将请求都转跳到google。</u></p>
<ol start="2">
<li>Before Route Predicate Factory<br>
Before Route Predicate Factory也是使用时间作为匹配规则，只要当前时间小于设定时间，路由才会匹配请求。 application.yml：<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:    
        gateway:      
            routes:      
            - id: before_route        
              uri: http://www.google.com        
              predicates:        
              - Before=2018-12-25T14:33:47.789+08:00
</code></pre>
<p><u>这个路由规则会在东8区的2018-12-25 14:33:47前，将请求都转跳到google。</u></p>
<ol start="3">
<li>Between Route Predicate Factory<br>
Between Route Predicate Factory也是使用两个时间作为匹配规则，只要当前时间大于第一个设定时间，并小于第二个设定时间，路由才会匹配请求。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:   
        gateway:      
            routes:      
            - id: between_route        
              uri: http://www.google.com        
              predicates:        
              - Between=2018-12-25T14:33:47.789+08:00, 2018-12-26T14:33:47.789+08:
</code></pre>
<p><u>这个路由规则会在东8区的2018-12-25 14:33:47到2018-12-26 14:33:47之间，将请求都转跳到google。</u></p>
<ol start="4">
<li>Cookie Route Predicate Factory<br>
Cookie Route Predicate Factory使用的是cookie名字和正则表达式的value作为两个输入参数，请求的cookie需要匹配cookie名和符合其中value的正则。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring: 
    cloud:    
        gateway:  
            routes:      
            - id: cookie_route       
              uri: http://www.google.com        
              predicates:        
              - Cookie=cookiename, cookievalue
</code></pre>
<p><u>路由匹配请求存在cookie名为cookiename，cookie内容匹配cookievalue的，将请求转发到google。</u></p>
<ol start="5">
<li>Header Route Predicate Factory<br>
Header Route Predicate Factory，与Cookie Route Predicate Factory类似，也是两个参数，一个header的name，一个是正则匹配的value。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:    
        gateway:     
            routes:      
            - id: header_route        
              uri: http://www.google.com        
              predicates:        
              - Header=X-Request-Id, \d+
</code></pre>
<p><u>路由匹配存在名为X-Request-Id，内容为数字的header的请求，将请求转发到google。</u></p>
<ol start="6">
<li>Host Route Predicate Factory<br>
Host Route Predicate Factory使用的是host的列表作为参数，host使用Ant style匹配。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:    
        gateway:      
            routes:      
            - id: host_route        
              uri: http://www.google.com        
              predicates:        
              - Host=**.somehost.org,**.anotherhost.org
</code></pre>
<p><u>路由会匹配Host诸如：www.somehost.org 或 beta.somehost.org或www.anotherhost.org等请求。</u></p>
<ol start="7">
<li>Method Route Predicate Factory<br>
Method Route Predicate Factory是通过HTTP的method来匹配路由。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:    
        gateway:      
            routes:      
            - id: method_route        
              uri: http://www.google.com        
              predicates:        
              - Method=GET
</code></pre>
<p>路由会匹配到所有GET方法的请求。</p>
<ol start="8">
<li>Path Route Predicate Factory<br>
Path Route Predicate Factory使用的是path列表作为参数，使用Spring的PathMatcher匹配path，可以设置可选变量。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:    
        gateway:      
            routes:      
            - id: host_route        
              uri: http://www.google.com       
              predicates:        
              - Path=/foo/{segment},/bar/{segment}
</code></pre>
<p><u>上面路由可以匹配诸如：/foo/1 或 /foo/bar 或 /bar/baz等 其中的segment变量可以通过下面方式获取：</u></p>
<pre><code>PathMatchInfo variables = exchange.getAttribute(URI_TEMPLATE_VARIABLES_ATTRIBUTE);
Map&lt;String, String&gt; uriVariables = variables.getUriVariables();
String segment = uriVariables.get(&quot;segment&quot;);
</code></pre>
<p>在后续的GatewayFilter Factories就可以做对应的操作了</p>
<ol start="9">
<li>Query Route Predicate Factory<br>
Query Route Predicate Factory可以通过一个或两个参数来匹配路由，一个是查询的name，一个是查询的正则value。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
    cloud:    
        gateway:      
            routes:      
            - id: host_route        
              uri: http://www.google.com       
              predicates:        
              - Path=/foo/{segment},/bar/{segment}
</code></pre>
<p><u>路由会匹配所有包含baz查询参数的请求。</u></p>
<pre><code class="language-text">spring:  
	cloud:    
		gateway:      
			routes:      
			- id: query_route       
              uri: http://www.google.com        
              predicates:       
              - Query=foo, ba.
</code></pre>
<p><u>路由会匹配所有包含foo，并且foo的内容为诸如：bar或baz等符合ba.正则规则的请求。</u><br>
10.  RemoteAddr Route Predicate Factory<br>
RemoteAddr Route Predicate Factory通过无类别域间路由(IPv4 or IPv6)列表匹配路由。<br>
** application.yml：**</p>
<pre><code class="language-text">spring:  
	cloud:    
		gateway:    
        	routes:      
        	- id: remoteaddr_route        
        	  uri: http://www.google.com        
        	  predicates:        
        	  - RemoteAddr=192.168.1.1/24
</code></pre>
<p><u>上面路由就会匹配RemoteAddr诸如192.168.1.10等请求。</u><br>
RemoteAddr Route Predicate Factory默认情况下，使用的是请求的remote address。但是如果Spring Cloud Gateway是部署在其他的代理后面的，如Nginx，则Spring Cloud Gateway获取请求的remote address是其他代理的ip，而不是真实客户端的ip。<br>
考虑到这种情况，你可以自定义获取remote address的处理器RemoteAddressResolver。当然Spring Cloud Gateway也提供了基于X-Forwarded-For请求头的XForwardedRemoteAddressResolver。 熟悉Http代理协议的，都知道X-Forwarded-For头信息做什么的，不熟悉的可以自己谷歌了解一下。<br>
XForwardedRemoteAddressResolver提供了两个静态方法获取它的实例： XForwardedRemoteAddressResolver::trustAll得到的RemoteAddressResolver总是获取X-Forwarded-For的第一个ip地址作为remote address，这种方式就比较容易被伪装的请求欺骗，模拟请求很容易通过设置初始的X-Forwarded-For头信息，就可以欺骗到gateway。<br>
XForwardedRemoteAddressResolver::maxTrustedIndex得到的RemoteAddressResolver则会在X-Forwarded-For信息里面，从右到左选择信任最多maxTrustedIndex个ip，因为X-Forwarded-For是越往右是越接近gateway的代理机器ip，所以是越往右的ip，信任度是越高的。 那么如果前面只是挡了一层Nginx的话，如果只需要Nginx前面客户端的ip，则maxTrustedIndex取1，就可以比较安全地获取真实客户端ip。</p>
<pre><code>使用java的配置： &lt;u&gt;GatewayConfig.java：&lt;/u&gt;
</code></pre>
<pre><code>RemoteAddressResolver resolver = XForwardedRemoteAddressResolver.maxTrustedIndex(1);
...
    .route(&quot;direct-route&quot;, r -&gt; r.remoteAddr(&quot;10.1.1.1&quot;, &quot;10.10.1.1/24&quot;)        .uri(&quot;http://www.google.com&quot;)
    .route(&quot;proxied-route&quot;,r -&gt; r.remoteAddr(resolver,  &quot;10.10.1.1&quot;, &quot;10.10.1.1/24&quot;)        .uri(&quot;http://www.google.com&quot;))
</code></pre>
<h3 id="gatewayfilter-工厂介绍">GatewayFilter 工厂介绍</h3>
<p>Route filters可以通过一些方式修改HTTP请求的输入和输出，针对某些特殊的场景，Spring Cloud Gateway已经内置了很多不同功能的GatewayFilter Factories。</p>
<ol>
<li>AddRequestHeader GatewayFilter Factory<br>
AddRequestHeader GatewayFilter Factory通过配置name和value可以增加请求的header。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
	cloud:    
		gateway:   
        	routes: 
            - id: add_request_header_route  
              uri: http://www.google.com  
              filters:
              - AddRequestHeader=X-Request-Foo, Bar
</code></pre>
<p><u>对匹配的请求，会额外添加X-Request-Foo:Bar的header。</u></p>
<ol start="2">
<li>AddRequestParameter GatewayFilter Factory<br>
AddRequestParameter GatewayFilter Factory通过配置name和value可以增加请求的参数。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
	cloud:  
    	gateway:   
        	routes:      
        	- id: add_request_parameter_route     
              uri: http://www.google.com     
              filters:       
              - AddRequestParameter=foo, bar
</code></pre>
<p><u>对匹配的请求，会额外添加foo=bar的请求参数。</u></p>
<ol start="3">
<li>AddResponseHeader GatewayFilter Factory<br>
AddResponseHeader GatewayFilter Factory通过配置name和value可以增加响应的header。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
	cloud:   
    	gateway:  
        	routes:      
        	- id: add_request_header_route    
              uri: http://www.google.com     
              filters:        
              - AddResponseHeader=X-Response-Foo, Bar
</code></pre>
<p><u>对匹配的请求，响应返回时会额外添加X-Response-Foo:Bar的header返回。</u></p>
<ol start="4">
<li>Hystrix GatewayFilter Factory<br>
Hystrix是Netflix实现的断路器模式工具包，The Hystrix GatewayFilter就是将断路器使用在gateway的路由上，目的是保护你的服务避免级联故障，以及在下游失败时可以降级返回。<br>
项目里面引入spring-cloud-starter-netflix-hystrix依赖，并提供HystrixCommand的名字，即可生效Hystrix GatewayFilter。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:  
	cloud:    
		gateway:      
			routes:     
        	- id: hystrix_route      
              uri: http://www.google.com     
              filters:        
              - Hystrix=myCommandName
</code></pre>
<p><u>那么剩下的过滤器，就会包装在名为myCommandName的HystrixCommand中运行。</u><br>
Hystrix过滤器也是通过配置可以参数fallbackUri，来支持路由熔断后的降级处理，降级后，请求会跳过fallbackUri配置的路径，目前只支持forward:的URI协议。<br>
** application.yml：**</p>
<pre><code class="language-text">spring:
  cloud:
    gateway:
      routes:
      - id: hystrix_route
        uri: lb://backing-service:8088
        predicates:
        - Path=/consumingserviceendpoint
        filters:
        - name: Hystrix
          args:
            name: fallbackcmd
            fallbackUri: forward:/incaseoffailureusethis
</code></pre>
<p><u>当Hystrix降级后就会将请求转发到/incaseoffailureusethis。</u><br>
整个流程其实是用fallbackUri将请求跳转到gateway内部的controller或者handler，然而也可以通过以下的方式将请求转发到外部的服务<br>
** application.yml：**</p>
<pre><code class="language-text">spring:
  cloud:
    gateway:
      routes:
      - id: ingredients
        uri: lb://ingredients
        predicates:
        - Path=//ingredients/**
        filters:
        - name: Hystrix
          args:
            name: fetchIngredients
            fallbackUri: forward:/fallback
      - id: ingredients-fallback
        uri: http://localhost:9994
        predicates:
        - Path=/fallback
</code></pre>
<p><u>以上的例子，gateway降级后就会将请求转发到http://localhost:9994。</u><br>
Hystrix Gateway filter在转发降级请求时，会将造成降级的异常设置在ServerWebExchangeUtils.HYSTRIX_EXECUTION_EXCEPTION_ATTR属性中，在处理降级时也可以用到。<br>
比如下一节讲到的FallbackHeaders GatewayFilter Factory，就会通过上面的方式拿到异常信息，设置到降级转发请求的header上，来告知降级下游异常信息。<br>
通过下面配置可以设置Hystrix的全局超时信息：<br>
** application.yml：**</p>
<pre><code class="language-text">hystrix.command.fallbackcmd.execution.isolation.thread.timeoutInMilliseconds: 5000
</code></pre>
<ol start="5">
<li>FallbackHeaders GatewayFilter Factory<br>
FallbackHeaders GatewayFilter Factory可以将Hystrix执行的异常信息添加到外部请求的fallbackUriheader上。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:
  cloud:
    gateway:
      routes:
      - id: ingredients
        uri: lb://ingredients
        predicates:
        - Path=//ingredients/**
        filters:
        - name: Hystrix
          args:
            name: fetchIngredients
            fallbackUri: forward:/fallback
      - id: ingredients-fallback
        uri: http://localhost:9994
        predicates:
        - Path=/fallback
        filters:
        - name: FallbackHeaders
          args:
            executionExceptionTypeHeaderName: Test-Header
</code></pre>
<p>你也可以使用默认的header，也可以像上面一下配置修改header的名字：</p>
<pre><code>executionExceptionTypeHeaderName (&quot;Execution-Exception-Type&quot;)

executionExceptionMessageHeaderName (&quot;Execution-Exception-Message&quot;)

rootCauseExceptionTypeHeaderName (&quot;Root-Cause-Exception-Type&quot;)

rootCauseExceptionMessageHeaderName (&quot;Root-Cause-Exception-Message&quot;)
</code></pre>
<ol start="6">
<li>PrefixPath GatewayFilter Factory<br>
The PrefixPath GatewayFilter Factor通过设置prefix参数来路径前缀<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:
  cloud:
    gateway:
      routes:
      - id: ingredients
        uri: lb://ingredients
        predicates:
        - Path=//ingredients/**
        filters:
        - name: Hystrix
          args:
            name: fetchIngredients
            fallbackUri: forward:/fallback
      - id: ingredients-fallback
        uri: http://localhost:9994
        predicates:
        - Path=/fallback
        filters:
        - name: FallbackHeaders
          args:
            executionExceptionTypeHeaderName: Test-Header
</code></pre>
<p><u>如果一个请求是/hello，通过上面路由，就会将请求修改为/mypath/hello。</u></p>
<ol start="7">
<li>PreserveHostHeader GatewayFilter Factory<br>
PreserveHostHeader GatewayFilter Factory会保留原始请求的host头信息，并原封不动的转发出去，而不是被gateway的http客户端重置。<br>
** application.yml：**</li>
</ol>
<pre><code class="language-text">spring:
  cloud:
    gateway:
      routes:
      - id: preserve_host_route
        uri: http://www.google.com
        filters:
        - PreserveHostHeader
</code></pre>
<ol start="8">
<li>RequestRateLimiter GatewayFilter Factory<br>
RequestRateLimiter GatewayFilter Factory使用RateLimiter来决定当前请求是否允许通过，如果不允许，则默认返回状态码HTTP 429 - Too Many Requests。<br>
RequestRateLimiter GatewayFilter可以使用一个可选参数keyResolver来做速率限制keyResolver是KeyResolver接口的一个实现bean，在配置里面，通过SpEL表达式#{@myKeyResolver}来管理bean的名字myKeyResolver。</li>
</ol>
<pre><code>KeyResolver.java.

public interface KeyResolver {
	Mono&lt;String&gt; resolve(ServerWebExchange exchange);
}
</code></pre>
<p>** KeyResolver接口允许你使用不同的策略来得出限制请求的key，未来，官方也会推出一些KeyResolver的不同实现。 **<br>
KeyResolver默认实现是PrincipalNameKeyResolver，通过ServerWebExchange中获取Principal，并以Principal.getName()作为限流的key。<br>
如果KeyResolver拿不到key，请求默认都会被限制，你也可以自己配置spring.cloud.gateway.filter.request-rate-limiter.deny-empty-key：是否允许空key，spring.cloud.gateway.filter.request-rate-limiter.empty-key-status-code ：空key时返回的状态码。</p>
<p>RequestRateLimiter不支持捷径配置，如下面的配置是非法的</p>
<pre><code>application.properties.

# INVALID SHORTCUT CONFIGURATION
spring.cloud.gateway.routes[0].filters[0]=RequestRateLimiter=2, 2, #{@userkeyresolver}
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[maven-assembly-plugin插件]]></title>
        <id>https://chenm0.github.io/post/maven-assembly-plugin/</id>
        <link href="https://chenm0.github.io/post/maven-assembly-plugin/">
        </link>
        <updated>2021-11-05T01:41:22.000Z</updated>
        <content type="html"><![CDATA[<h3 id="一-assembly-是什么意思">一. Assembly 是什么意思？</h3>
<figure data-type="image" tabindex="1"><img src="https://chenm0.github.io//post-images/1636076532479.png" alt="" loading="lazy"></figure>
<h3 id="二-maven-assembly-plugin是什么">二. maven-assembly-plugin是什么？</h3>
<p><code>它是maven中针对打包任务而提供的标准插件。</code></p>
<h3 id="三-maven-assembly-plugin插件的作用">三. maven-assembly-plugin插件的作用？</h3>
<p><strong>摘自官网：</strong> http://maven.apache.org/plugins/maven-assembly-plugin/<br>
<strong>英文原文：</strong> The Assembly Plugin for Maven is primarily intended to allow users to aggregate the project output along with its dependencies, modules, site documentation, and other files into a single distributable archive.<br>
<strong>中文翻译：</strong> Assembly 插件的主要作用是，允许用户将项目输出与它的依赖项、模块、站点文档、和其他文件一起组装成一个可分发的归档文件。</p>
<h3 id="四maven-assembly-plugin插件在maven项目中如何使用即使用步骤">四.maven-assembly-plugin插件在maven项目中如何使用（即使用步骤）？</h3>
<ol>
<li>需要指定一个Assembly描述符文件。该文件指定了打包格式，包含的文件/过滤的文件等信息，可以同时指定多个描述符文件，打包成不同的格式。</li>
<li>在Maven工程的pom.xml文件里配置maven-assembly-plugin插件，引入Assembly描述符文件。</li>
</ol>
<h3 id="五-maven项目中assembly描述符文件详解">五. maven项目中Assembly描述符文件详解</h3>
<p>示例：</p>
<pre><code>&lt;?xml version=&quot;1.0&quot; encoding=&quot;utf-8&quot;?&gt;
&lt;assembly
​    xmlns=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2&quot;
​    xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot;
​    xsi:schemaLocation=&quot;http://maven.apache.org/plugins/maven-assembly-plugin/assembly/1.1.2 http://maven.apache.org/xsd/assembly-1.1.2.xsd&quot;&gt;

​    &lt;!-- id 标识符，添加到生成文件名称的后缀符。如果指定 id 的话（这里指定的是项目的版本），目标文件则是 ${artifactId}-${id}.jar。【如terminal-dispatch-5.0.0.0.jar】 --&gt;
​    &lt;id&gt;${project.version}&lt;/id&gt;

​    &lt;!-- 指定打包格式。maven-assembly-plugin插件支持的打包格式有zip、tar、tar.gz (or tgz)、tar.bz2 (or tbz2)、jar、dir、war，可以同时指定多个打包格式 --&gt;
​    &lt;formats&gt;
​        &lt;format&gt;jar&lt;/format&gt;
​    &lt;/formats&gt;
​    
​    &lt;!-- 指定打的包是否包含打包层目录（比如finalName是terminal-dispatch，当值为true，所有文件被放在包内的terminal-dispatch目录下，否则直接放在包的根目录下）--&gt;
​    &lt;includeBaseDirectory&gt;true&lt;/includeBaseDirectory&gt;

​    &lt;!-- 指定将工程依赖的包打到包里的指定目录下 --&gt;
​    &lt;dependencySets&gt;
​        &lt;dependencySet&gt;
​            &lt;useProjectArtifact&gt;true&lt;/useProjectArtifact&gt; &lt;!-- 指定打包时是否包含工程自身生成的jar包 --&gt;
​            &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt; &lt;!-- 指定将这些依赖包打到包里lib目录下 --&gt;
​            &lt;scope&gt;runtime&lt;/scope&gt; &lt;!-- 用于管理依赖的部署，runtime表示只在运行时使用 --&gt;
​        &lt;/dependencySet&gt;
​    &lt;/dependencySets&gt;

​    &lt;!-- 指定要包含的文件集，可以定义多个fileSet --&gt;
​    &lt;fileSets&gt;
​        &lt;fileSet&gt;
​            &lt;directory&gt;src/main/script/linux/bin&lt;/directory&gt; &lt;!-- 指定归档文件（要打的jar包）要包含的目录（下的文件及文件夹） --&gt;
​            &lt;outputDirectory&gt;bin&lt;/outputDirectory&gt; &lt;!-- 指定要将当前目录（&lt;directory&gt;标签中的目录放在归档文件（要打的jar包）bin目录下） --&gt;
​            &lt;includes&gt;
​                &lt;include&gt;terminal-dispatch&lt;/include&gt; &lt;!-- 精确控制要包含的文件，&lt;exclude&gt;用于精确控制要排除的文件  --&gt;
​                &lt;include&gt;server&lt;/include&gt;
​            &lt;/includes&gt;
​            &lt;fileMode&gt;0755&lt;/fileMode&gt; &lt;!-- 设置文件 UNIX 属性，是一种读写权限 --&gt;
​       &lt;/fileSet&gt;        
​        &lt;fileSet&gt;
​            &lt;directory&gt;src/main/resources&lt;/directory&gt;
​            &lt;outputDirectory&gt;conf&lt;/outputDirectory&gt;
​            &lt;includes&gt;
​                &lt;include&gt;config.properties&lt;/include&gt;
​                &lt;include&gt;logback.xml&lt;/include&gt;
​            &lt;/includes&gt;
​            &lt;fileMode&gt;0644&lt;/fileMode&gt;
​        &lt;/fileSet&gt;
​        &lt;fileSet&gt;
​            &lt;directory&gt;src/main/script/conf&lt;/directory&gt;
​            &lt;outputDirectory&gt;conf&lt;/outputDirectory&gt;
​            &lt;includes&gt;
​                &lt;include&gt;wrapper.conf&lt;/include&gt;
​            &lt;/includes&gt;
​            &lt;fileMode&gt;0644&lt;/fileMode&gt;
​        &lt;/fileSet&gt;
​        &lt;fileSet&gt;
​            &lt;directory&gt;src/main/script/linux/lib&lt;/directory&gt;
​            &lt;outputDirectory&gt;lib&lt;/outputDirectory&gt;
​            &lt;includes&gt;
​                &lt;include&gt;libwrapper.so&lt;/include&gt;
​                &lt;include&gt;wrapper.jar&lt;/include&gt;
​            &lt;/includes&gt;
​            &lt;fileMode&gt;0755&lt;/fileMode&gt;
​        &lt;/fileSet&gt;
​    &lt;/fileSets&gt;
&lt;/assembly&gt;
</code></pre>
<ol>
<li><includeBaseDirectory>true</includeBaseDirectory>标签作用？<br>
指定打的包是否包含打包层目录，比如finalName是terminal-dispatch，当值为true，所有文件被放在包内的terminal-dispatch目录下，否则直接放在包的根目录下</li>
<li><fileMode>0755</fileMode>标签作用？<br>
设置文件的unix属性，好像是一种读写权限的设定，linux的内容，我没有深究，不是特别懂，暂时不多说。</li>
</ol>
<p>1<br>
compile<br>
缺省值，适用于所有阶段，会随着项目一起发布</p>
<p>2<br>
provided<br>
类似compile，期望JDK、容器或使用者会提供这个依赖。如servlet.jar</p>
<p>3<br>
runtime<br>
只在运行时使用，如JDBC驱动，适用运行和测试阶段</p>
<p>4<br>
test<br>
只在测试时使用，用于编译和运行测试代码。不会随项目发布</p>
<p>5<br>
system<br>
类似provided，需要显式提供包含依赖的jar，Maven不会在Repository中查找它</p>
<h3 id="六-maven中的pomxml配置引入assembly描述符文件">六. maven中的pom.xml配置(引入assembly描述符文件)</h3>
<pre><code class="language-javascript">&lt;build&gt;
    &lt;plugins&gt;
       &lt;plugin&gt;
       　　&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;
　　　　　　&lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;
　　　　　　&lt;version&gt;2.4&lt;/version&gt;
　　　　　　　　&lt;executions&gt;
　　　　　　　　　　&lt;execution&gt; &lt;!--执行器 mvn assembly:assembly--&gt;
　　　　　　　　　　　　&lt;id&gt;make-zip&lt;/id&gt; &lt;!--名字任意 --&gt;
　　　　　　　　　　　　&lt;phase&gt;package&lt;/phase&gt; &lt;!-- 绑定到package生命周期阶段上 --&gt;
　　　　　　　　　　　　&lt;goals&gt;
　　　　　　　　　　　　　　&lt;goal&gt;single&lt;/goal&gt; &lt;!-- 该打包任务只运行一次 --&gt;
　　　　　　　　　　　　&lt;/goals&gt;
　　　　　　　　　　　　&lt;configuration&gt;
　　　　　　　　　　　　　　&lt;descriptors
　　　　　　　　　　　　　　　　&lt;descriptor&gt;src/main/script/assembly.xml&lt;/descriptor&gt; 
　　　　　　　　　　　　　　&lt;/descriptors&gt;
　　　　　　　　　　&lt;/configuration&gt;
　　　　　　　　&lt;/execution&gt;
　　　　　　&lt;/executions&gt;
　　　　&lt;/plugin&gt;
    &lt;plugins&gt;
&lt;/build&gt;
</code></pre>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[《计算机组成与设计》学习笔记——第1章]]></title>
        <id>https://chenm0.github.io/post/computer-organization-design-note/</id>
        <link href="https://chenm0.github.io/post/computer-organization-design-note/">
        </link>
        <updated>2021-09-09T06:01:26.000Z</updated>
        <content type="html"><![CDATA[<h3 id="第1章-计算机概要与技术">第1章 计算机概要与技术</h3>
<h5 id="英译">英译：</h5>
<pre><code>World Wide Web (www)--- 万维网

Personal Computer (PC) --- 个人计算机

Embedded computer --- 嵌入式计算机

Personal Mobile Device(PMD) --- 个人移动设备

Cloud computing --- 云计算

Warehouse Scale Computer (WSC) --- 仓储规模计算机

Software as a Service (SAAS) --- 软件即服务

Multicore microprocessor --- 多核微处理器

acronym --- 首字母缩略词

Random Access Memory (RAM) --- 随机访问存储器

Central Process Unit (CPU)--- 中央处理单元

Moore's Law --- 摩尔定律

abstraction --- 抽象

common case fast --- 加速大概率事件

parallel performance --- 并行性能

pipeline --- 流水线

prediction --- 预测

hierarchy of memory --- 存储器层次

dependable --- 可靠性

system software --- 系统软件

compiler --- 编译程序

binary digit --- 二进制位

bit --- 位

Instruction --- 指令

assembler --- 汇编程序

assembly language --- 汇编语言

machine language --- 机器语言

high-level programming language --- 高级编程语言

input device --- 输入设备

output device --- 输出设备

Liquid Crystal Display (LCD) --- 液晶显示

active matrix display --- 动态矩阵显示

pixel --- 像素

bit map --- 位图

intergrated circuit --- 集成电路

chip --- 芯片

datapath --- 数据通路

control --- 控制器

Graphic Processor Unit (GPU) --- 图形处理器单元

memory --- 内存

Dynamic Random Access Memory (DRAM) --- 动态随机访问存储器

cache memory --- 缓存

Static Random Access Memory (SRAM) --- 静态随机访问存储器

instruction set architecture --- 指令集体系结构

architecture --- 体系结构

Application Binary Inteface (ABI) --- 应用二进制接口

implementation --- 实现

volatile memory --- 易失性存储器

nonvolatile memory --- 非易失性存储器

main memory 或 primary memory --- 主存储器

secondary memory --- 二级存储器

magnetic disk --- 磁盘

flash memory --- 闪存

hard disk --- 硬盘

Local Area Network (LAN) --- 局域网

Wide Area Network (WAN) --- 广域网

</code></pre>
<h5 id="11-引言">1.1  引言</h5>
<p>计算机主要分为以下三类应用及各自的特性：</p>
<ul>
<li><strong>个人计算机：</strong> 用于个人使用的计算机，通常包含图形显示器、键盘和鼠标等。个人计算机强调对单用户提供良好的性能，价格低廉，通常运行第三方软件</li>
<li><strong>服务器：</strong> 用于位多用户运行大型程序的计算机，通常由多个用户并行使用，并且一般通过网络访问。通常情况下，当发生故障时，服务器比个人计算机恢复的代价高的多，因此服务器更加强调可靠性。</li>
<li><strong>嵌入式计算机：</strong> 嵌入到其他设备中的计算机，一般运行预定义的一个或者一组应用程序。嵌入式计算系统的设计目标是运行单一应用程序或者一组相关的应用程序，并且通常和硬件集成在一起以单一系统的方式一并交付用户。在面向消费者的嵌入式应用中（如数字家电）一般通过简单设计来获得可靠性——其重点在于尽可能地保证一项功能的正常运转。</li>
</ul>
<p>后PC时代，在硬件上，由个人移动设备和云计算分别替代了PC和传统的服务器；而通过云计算实现的软件即服务（SAAS) 是软件工业的革命：</p>
<ul>
<li><strong>个人移动设备：</strong> 连接到网络上的小型无线设备。PMD由电池供电，通过下载App的方式安装软件。智能手机和平板电脑是典型的PMD</li>
<li><strong>云计算：</strong> 依赖于称为仓储规模计算机（WSC）的巨型数据中心，在网络上提供服务的大服务器集群，一些运营商根据应用需求出租不同数量的服务器。</li>
<li><strong>软件即服务：</strong> 在网络上以服务的方式提供软件和数据。其运行方式通常不是在本地设备上运行所有的二进制代码，而是通过诸如运行在本地客户端的浏览器等小程序登录到远程服务器上执行。典型的例子是Web搜索和社交网络。</li>
</ul>
<p>硬件和软件如何对程序性能造成影响：</p>
<table>
<thead>
<tr>
<th style="text-align:center">软件和硬件组成元素</th>
<th style="text-align:center">该元素如何影响性能</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">算法</td>
<td style="text-align:center">决定了源码级语句的数量和I/O操作的数量</td>
</tr>
<tr>
<td style="text-align:center">编程语言、编译器和体系结构</td>
<td style="text-align:center">决定了每条源码级语句对应的计算机指令数量</td>
</tr>
<tr>
<td style="text-align:center">处理器和存储系统</td>
<td style="text-align:center">决定了指令的执行速度</td>
</tr>
<tr>
<td style="text-align:center">I/O系统（硬件和操作系统）</td>
<td style="text-align:center">决定了I/O操作可能的执行速度</td>
</tr>
</tbody>
</table>
<h5 id="12-计算机系统结构中的8个伟大思想">1.2  计算机系统结构中的8个伟大思想</h5>
<ul>
<li><strong>面向摩尔定律的设计：</strong> 计算机设计者必须预测其设计完成时的工艺水平，而不是设计开始时的</li>
<li><strong>使用抽象简化设计：</strong> 用抽象来表示不同的设计层次提高硬件和软件生产率，在高层次中看不到的低层次的细节，只能看到一个简化的模型</li>
<li><strong>加速大概率事件：</strong> 加速大概率事件远比小概率事件更能提高性能</li>
<li><strong>通过并行提高性能：</strong> 通过并行执行操作来提高性能</li>
<li><strong>通过流水线提高性能：</strong> 流水线是特别的并行性场景，可以想象成一系列水管，其中每一块代表一个流水级</li>
<li><strong>通过预测提高性能：</strong> 在某些情况下，如果假定从误删除恢复执行代价不高并且预测的准确率相对较高，则通过猜测的方式提前开始某些操作。（预测先行）</li>
<li><strong>存储器层次：</strong> 可以把存储器层次想象成一个堆叠的三角形，该形状表示速度、价格和容量；越靠近顶端，存储器速度越快、每位价格越高；底层宽度越大，存储器容量越大</li>
<li><strong>通过冗余提高可靠性：</strong> 冗余部件可以替代失效部件并可以帮助检测错误（容灾策略）</li>
</ul>
<h5 id="13-程序概念入门">1.3 程序概念入门</h5>
<p>硬件和软件层次图简化：</p>
<figure data-type="image" tabindex="1"><img src="https://chenm0.github.io//post-images/1631171219535.jpg" alt="" loading="lazy"></figure>
<ul>
<li><strong>系统软件：</strong> 提供常用服务的软件，包括操作系统、编译程序、加载程序和汇编程序等</li>
</ul>
<p>系统软件中，有两种是现代计算机系统中必须的：</p>
<ul>
<li><strong>操作系统：</strong> 是用户程序与硬件之间的接口，为了使程序更好地在计算机上运行而管理计算机上运行而管理计算机资源的监控程序</li>
<li><strong>编译程序：</strong> 将高级语言翻译为计算机所能识别的机器语言的程序</li>
</ul>
<p>对于计算机来说，最简单的信号就是“通” 和 “断” ，所以计算机只用0和1两个来表示，每个0或1就是一个二进制位，使用数字既表述指令又表示数据是计算机的基础。为符合人类的思维方式，发明了助记符，随后开发了一种称为汇编程序的软件自动将助记符翻译为二进制，但仍需要写出计算机执行的每条命令，要求要像计算机一样思考，于是便出现了高级编程语言。使用高级编程语言有三点好处：</p>
<ol>
<li>可以用更自然的语言来思考</li>
<li>简明性</li>
<li>独立性</li>
</ol>
<h5 id="14-硬件概念入门">1.4 硬件概念入门</h5>
<p>组成计算机的5个经典组件是 <mark>输入、输出、存储器、数据通路（也称运算器）和控制器</mark>，数据通路和控制器通常合成为处理器。其中两个关键部件是<strong>输入设备</strong>和<strong>输出设备</strong>，输入设备是为计算机提供信息的装置，如键盘；输出设备是将计算结果输出给用户（如显示器）或其他计算机装置。<br>
处理器从存储器中得到指令和数据，输入部件将数据写入存储器，输出部件从内存中读出数据，控制器向数据通路、存储器、输入和输出部件发出信号。</p>
<p><strong>液晶显示（LCD）的原理：</strong><br>
LCD并非光源，而是控制光的传输。通过电流控制位于两层垂直的偏光板之间的棒状液态分子团形成的转动螺旋线，来弯曲来自显示器后方的光线和少量反射光线（在不施加任何电压的情况下，液晶处于初始状态，并将入射光扭转90度，施加电压时，则不再弯曲，光线不能通过）。<br>
现在的大多数LCD显示器采用<mark>动态矩阵</mark>显示技术，使用晶体管控制单个像素上光线的传输。每个像素都由晶体管精确地控制电流，使图像更清晰。还有一个红 - 绿 - 蓝屏决定三种颜色分量的强度，每个点需要3个晶体管开关。</p>
<p>图像由像素矩阵组成，可以表示成二进制位的矩阵，称为“位图”。计算机硬件采用光栅刷新缓冲区（帧缓冲区）来保存位图以支持图像，每个像素的二进制值以刷新频率读出到显示设备。<br>
而后PC时代使用接触敏感的显示设备替代了键盘和鼠标，拥有良好的用户界面，用户可以直接指向感兴趣的内容。<br>
触摸屏的原理是电容感应。绝缘玻璃上覆盖一层透明的导体，人的手指接触到屏幕范围时，由于人是导体，将会使屏幕的电场发生变化，进而导致电容的变化。这种技术允许同时接触多个点，可提供非常好的用户界面。</p>
<p>根据Apple iPad2平板电脑的例子，可以看出I/O是该设备的主要部分，包括一个电容性多触电的LCD、前置摄像头、后置摄像头、麦克风、耳机插孔、扬声器、加速计、陀螺仪、Wi-Fi网络和蓝牙网络。而数据通路、控制器、存储器只占一小部分。<br>
在Apple iPad2的逻辑主板上由下列设备构成：</p>
<ul>
<li><strong>集成电路</strong> ：也叫芯片，一种将几十个至几百万个晶体管连接起来的设备</li>
<li><strong>中央处理器单元（CPU）</strong>：也成为处理器 ，包括数据通路和控制器
<ul>
<li><em>数据通路</em>：是处理器中执行算术操作的部分</li>
<li><em>控制器</em>：处理器中根据程序的指令指挥数据通路、存储器和I/O设备的部分</li>
</ul>
</li>
</ul>
<p><strong>关于存储器</strong><br>
计算机中的存储器设计体现了八大思想中的存储器层次，分为两种类型：<mark>易失性存储器和非易失性存储器</mark>，易失性存储器被称为主存储器，非易失性存储器被称为二级存储器。<br>
易失性存储器在计算机中有两种存储器</p>
<ul>
<li><strong>内存</strong>：程序运行时的存储空间，同时也用于保存程序运行时所需的数据。
<ul>
<li><em>DRAM</em>： 动态随机访问存储器，访问时间大约为50ns，每Gib的价格大约为5～10美元</li>
</ul>
</li>
<li><strong>缓存</strong>：小而快的存储器，一般作为DRAM的缓冲
<ul>
<li><em>SRAM</em>:  静态随机访问存储器，速度更快且不那么密集，但价格比DRAM高<br>
非易失性存储器在PC和个人移动设备中的使用不同，PC中磁盘占据主导地位，而闪存在个人移动设备中替代了磁盘。但闪存具有写100000～1000000次后老化或损坏的弱点，所以文件系统必须记录写操作的数目，而且具备避免存储器损坏的策略。例如：避免移动经常使用的数据。磁盘和闪存的区别如下：<br>
|              |     磁盘      |    闪存     |<br>
| :----------: | :-----------: | :---------: |<br>
|  <strong>易失性</strong>  |   非易失性    |  非易失性   |<br>
| <strong>访问时间</strong> |    5～20ms    |   5～50ms   |<br>
|   <strong>价格</strong>   | 0.05～0.1美元 | 0.75～1美元 |</li>
</ul>
</li>
</ul>
<p>计算机硬件的设计也体现了八大思想中的抽象思想，硬件和底层软件之间的接口是最重要的抽象之一，被称为<mark>指令集体系结构</mark>，这一抽象接口使得同一软件可以由成本不同、性能也不同的实现方法完成。<br>
提供给应用程序员的基本指令集和操作系统接口合称为<mark>应用二进制接口</mark></p>
<ul>
<li><strong>指令集体系结构</strong>：也叫体系结构，是低层次软件和硬件之间的抽象接口，包含需要编写正确运行的机器语言程序所需要的全部信息</li>
<li><strong>应用二进制接口</strong>：用户部分的指令加上应用程序员调用的操作系统接口，定义了二进制层次可移植的计算机的标准</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mybatis动态SQL]]></title>
        <id>https://chenm0.github.io/post/mybatis-sql/</id>
        <link href="https://chenm0.github.io/post/mybatis-sql/">
        </link>
        <updated>2021-09-03T01:24:52.000Z</updated>
        <content type="html"><![CDATA[<p>动态 SQL 是 MyBatis 的强大特性之一。如果你使用过 JDBC 或其它类似的框架，你应该能理解根据不同条件拼接 SQL 语句有多痛苦，例如拼接时要确保不能忘记添加必要的空格，还要注意去掉列表最后一个列名的逗号。利用动态 SQL，可以彻底摆脱这种痛苦。</p>
<p>使用动态 SQL 并非一件易事，但借助可用于任何 SQL 映射语句中的强大的动态 SQL 语言，MyBatis 显著地提升了这一特性的易用性。</p>
<p>如果你之前用过 JSTL 或任何基于类 XML 语言的文本处理器，你对动态 SQL 元素可能会感觉似曾相识。在 MyBatis 之前的版本中，需要花时间了解大量的元素。借助功能强大的基于 OGNL 的表达式，MyBatis 3 替换了之前的大部分元素，大大精简了元素种类，现在要学习的元素种类比原来的一半还要少。</p>
<ul>
<li>if</li>
<li>choose (when, otherwise)</li>
<li>trim (where, set)</li>
<li>foreach</li>
</ul>
<h3 id="if">if</h3>
<p>使用动态 SQL 最常见情景是根据条件包含 where 子句的一部分。比如：</p>
<pre><code>&lt;select id=&quot;findActiveBlogWithTitleLike&quot;
     resultType=&quot;Blog&quot;&gt;
  SELECT * FROM BLOG
  WHERE state = ‘ACTIVE’
  &lt;if test=&quot;title != null&quot;&gt;
    AND title like #{title}
  &lt;/if&gt;
&lt;/select&gt;
</code></pre>
<p>这条语句提供了可选的查找文本功能。如果不传入 “title”，那么所有处于 “ACTIVE” 状态的 BLOG 都会返回；如果传入了 “title” 参数，那么就会对 “title” 一列进行模糊查找并返回对应的 BLOG 结果（“title” 的参数值需要包含查找掩码或通配符字符）。</p>
<p>如果希望通过 “title” 和 “author” 两个参数进行可选搜索该怎么办呢？首先，我想先将语句名称修改成更名副其实的名称；接下来，只需要加入另一个条件即可。</p>
<pre><code>&lt;select id=&quot;findActiveBlogLike&quot;
     resultType=&quot;Blog&quot;&gt;
  SELECT * FROM BLOG WHERE state = ‘ACTIVE’
  &lt;if test=&quot;title != null&quot;&gt;
    AND title like #{title}
  &lt;/if&gt;
  &lt;if test=&quot;author != null and author.name != null&quot;&gt;
    AND author_name like #{author.name}
  &lt;/if&gt;
&lt;/select&gt;
</code></pre>
<h3 id="choose-when-otherwise">choose、when、otherwise</h3>
<p>有时候，我们不想使用所有的条件，而只是想从多个条件中选择一个使用。针对这种情况，MyBatis 提供了 choose 元素，它有点像 Java 中的 switch 语句。</p>
<p>还是上面的例子，但是策略变为：传入了 “title” 就按 “title” 查找，传入了 “author” 就按 “author” 查找的情形。若两者都没有传入，就返回标记为 featured 的 BLOG（这可能是管理员认为，与其返回大量的无意义随机 Blog，还不如返回一些由管理员精选的 Blog）</p>
<pre><code>&lt;select id=&quot;findActiveBlogLike&quot;
     resultType=&quot;Blog&quot;&gt;
  SELECT * FROM BLOG WHERE state = ‘ACTIVE’
  &lt;choose&gt;
    &lt;when test=&quot;title != null&quot;&gt;
      AND title like #{title}
    &lt;/when&gt;
    &lt;when test=&quot;author != null and author.name != null&quot;&gt;
      AND author_name like #{author.name}
    &lt;/when&gt;
    &lt;otherwise&gt;
      AND featured = 1
    &lt;/otherwise&gt;
  &lt;/choose&gt;
&lt;/select&gt;
</code></pre>
<h3 id="trim-where-set">trim、where、set</h3>
<p>前面几个例子已经方便地解决了一个臭名昭著的动态 SQL 问题。现在回到之前的 “if” 示例，这次我们将 “state = ‘ACTIVE’” 设置成动态条件，看看会发生什么。</p>
<pre><code>&lt;select id=&quot;findActiveBlogLike&quot;
     resultType=&quot;Blog&quot;&gt;
  SELECT * FROM BLOG
  WHERE
  &lt;if test=&quot;state != null&quot;&gt;
    state = #{state}
  &lt;/if&gt;
  &lt;if test=&quot;title != null&quot;&gt;
    AND title like #{title}
  &lt;/if&gt;
  &lt;if test=&quot;author != null and author.name != null&quot;&gt;
    AND author_name like #{author.name}
  &lt;/if&gt;
&lt;/select&gt;
</code></pre>
<p>如果没有匹配的条件会怎么样？最终这条 SQL 会变成这样：</p>
<pre><code>SELECT * FROM BLOG
WHERE
</code></pre>
<p>这会导致查询失败。如果匹配的只是第二个条件又会怎样？这条 SQL 会是这样:</p>
<pre><code>SELECT * FROM BLOG
WHERE
AND title like ‘someTitle’
</code></pre>
<p>这个查询也会失败。这个问题不能简单地用条件元素来解决。这个问题是如此的难以解决，以至于解决过的人不会再想碰到这种问题。</p>
<p>MyBatis 有一个简单且适合大多数场景的解决办法。而在其他场景中，可以对其进行自定义以符合需求。而这，只需要一处简单的改动：</p>
<pre><code>&lt;select id=&quot;findActiveBlogLike&quot;
     resultType=&quot;Blog&quot;&gt;
  SELECT * FROM BLOG
  &lt;where&gt;
    &lt;if test=&quot;state != null&quot;&gt;
         state = #{state}
    &lt;/if&gt;
    &lt;if test=&quot;title != null&quot;&gt;
        AND title like #{title}
    &lt;/if&gt;
    &lt;if test=&quot;author != null and author.name != null&quot;&gt;
        AND author_name like #{author.name}
    &lt;/if&gt;
  &lt;/where&gt;
&lt;/select&gt;
</code></pre>
<p><em>where</em> 元素只会在子元素返回任何内容的情况下才插入 “WHERE” 子句。而且，若子句的开头为 “AND” 或 “OR”，<em>where</em> 元素也会将它们去除。</p>
<p>如果 <em>where</em> 元素与你期望的不太一样，你也可以通过自定义 trim 元素来定制 <em>where</em> 元素的功能。比如，和 <em>where</em> 元素等价的自定义 trim 元素为：</p>
<pre><code>&lt;trim prefix=&quot;WHERE&quot; prefixOverrides=&quot;AND |OR &quot;&gt;
  ...
&lt;/trim&gt;
</code></pre>
<p><em>prefixOverrides</em> 属性会忽略通过管道符分隔的文本序列（注意此例中的空格是必要的）。上述例子会移除所有 <em>prefixOverrides</em> 属性中指定的内容，并且插入 <em>prefix</em> 属性中指定的内容。</p>
<p>用于动态更新语句的类似解决方案叫做 <em>set</em>。<em>set</em> 元素可以用于动态包含需要更新的列，忽略其它不更新的列。比如：</p>
<pre><code>&lt;update id=&quot;updateAuthorIfNecessary&quot;&gt;
  update Author
    &lt;set&gt;
      &lt;if test=&quot;username != null&quot;&gt;username=#{username},&lt;/if&gt;
      &lt;if test=&quot;password != null&quot;&gt;password=#{password},&lt;/if&gt;
      &lt;if test=&quot;email != null&quot;&gt;email=#{email},&lt;/if&gt;
      &lt;if test=&quot;bio != null&quot;&gt;bio=#{bio}&lt;/if&gt;
    &lt;/set&gt;
  where id=#{id}
&lt;/update&gt;
</code></pre>
<p>这个例子中，<em>set</em> 元素会动态地在行首插入 SET 关键字，并会删掉额外的逗号（这些逗号是在使用条件语句给列赋值时引入的）。</p>
<p>来看看与 <em>set</em> 元素等价的自定义 <em>trim</em> 元素吧：</p>
<pre><code>&lt;trim prefix=&quot;SET&quot; suffixOverrides=&quot;,&quot;&gt;
  ...
&lt;/trim&gt;
</code></pre>
<p>注意，我们覆盖了后缀值设置，并且自定义了前缀值。</p>
<h3 id="foreach">foreach</h3>
<p>动态 SQL 的另一个常见使用场景是对集合进行遍历（尤其是在构建 IN 条件语句的时候）。比如：</p>
<pre><code>&lt;select id=&quot;selectPostIn&quot; resultType=&quot;domain.blog.Post&quot;&gt;
  SELECT *
  FROM POST P
  WHERE ID in
  &lt;foreach item=&quot;item&quot; index=&quot;index&quot; collection=&quot;list&quot;
      open=&quot;(&quot; separator=&quot;,&quot; close=&quot;)&quot;&gt;
        #{item}
  &lt;/foreach&gt;
&lt;/select&gt;
</code></pre>
<p><em>foreach</em> 元素的功能非常强大，它允许你指定一个集合，声明可以在元素体内使用的集合项（item）和索引（index）变量。它也允许你指定开头与结尾的字符串以及集合项迭代之间的分隔符。这个元素也不会错误地添加多余的分隔符，看它多智能！</p>
<p><strong>提示</strong> 你可以将任何可迭代对象（如 List、Set 等）、Map 对象或者数组对象作为集合参数传递给 <em>foreach</em>。当使用可迭代对象或者数组时，index 是当前迭代的序号，item 的值是本次迭代获取到的元素。当使用 Map 对象（或者 Map.Entry 对象的集合）时，index 是键，item 是值。</p>
<p>至此，我们已经完成了与 XML 配置及映射文件相关的讨论。下一章将详细探讨 Java API，以便你能充分利用已经创建的映射配置。</p>
<h3 id="script">script</h3>
<p>要在带注解的映射器接口类中使用动态 SQL，可以使用 <em>script</em> 元素。比如:</p>
<pre><code>    @Update({&quot;&lt;script&gt;&quot;,
      &quot;update Author&quot;,
      &quot;  &lt;set&gt;&quot;,
      &quot;    &lt;if test='username != null'&gt;username=#{username},&lt;/if&gt;&quot;,
      &quot;    &lt;if test='password != null'&gt;password=#{password},&lt;/if&gt;&quot;,
      &quot;    &lt;if test='email != null'&gt;email=#{email},&lt;/if&gt;&quot;,
      &quot;    &lt;if test='bio != null'&gt;bio=#{bio}&lt;/if&gt;&quot;,
      &quot;  &lt;/set&gt;&quot;,
      &quot;where id=#{id}&quot;,
      &quot;&lt;/script&gt;&quot;})
    void updateAuthorValues(Author author);
</code></pre>
<h3 id="bind">bind</h3>
<p><code>bind</code> 元素允许你在 OGNL 表达式以外创建一个变量，并将其绑定到当前的上下文。比如：</p>
<pre><code>&lt;select id=&quot;selectBlogsLike&quot; resultType=&quot;Blog&quot;&gt;
  &lt;bind name=&quot;pattern&quot; value=&quot;'%' + _parameter.getTitle() + '%'&quot; /&gt;
  SELECT * FROM BLOG
  WHERE title LIKE #{pattern}
&lt;/select&gt;
</code></pre>
<h3 id="多数据库支持">多数据库支持</h3>
<p>如果配置了 databaseIdProvider，你就可以在动态代码中使用名为 “_databaseId” 的变量来为不同的数据库构建特定的语句。比如下面的例子：</p>
<pre><code>&lt;insert id=&quot;insert&quot;&gt;
  &lt;selectKey keyProperty=&quot;id&quot; resultType=&quot;int&quot; order=&quot;BEFORE&quot;&gt;
    &lt;if test=&quot;_databaseId == 'oracle'&quot;&gt;
      select seq_users.nextval from dual
    &lt;/if&gt;
    &lt;if test=&quot;_databaseId == 'db2'&quot;&gt;
      select nextval for seq_users from sysibm.sysdummy1&quot;
    &lt;/if&gt;
  &lt;/selectKey&gt;
  insert into users values (#{id}, #{name})
&lt;/insert&gt;
</code></pre>
<h3 id="动态-sql-中的插入脚本语言">动态 SQL 中的插入脚本语言</h3>
<p>MyBatis 从 3.2 版本开始支持插入脚本语言，这允许你插入一种语言驱动，并基于这种语言来编写动态 SQL 查询语句。</p>
<p>可以通过实现以下接口来插入一种语言：</p>
<pre><code>public interface LanguageDriver {
  ParameterHandler createParameterHandler(MappedStatement mappedStatement, Object parameterObject, BoundSql boundSql);
  SqlSource createSqlSource(Configuration configuration, XNode script, Class&lt;?&gt; parameterType);
  SqlSource createSqlSource(Configuration configuration, String script, Class&lt;?&gt; parameterType);
}
</code></pre>
<p>实现自定义语言驱动后，你就可以在 mybatis-config.xml 文件中将它设置为默认语言：</p>
<pre><code>&lt;typeAliases&gt;
  &lt;typeAlias type=&quot;org.sample.MyLanguageDriver&quot; alias=&quot;myLanguage&quot;/&gt;
&lt;/typeAliases&gt;
&lt;settings&gt;
  &lt;setting name=&quot;defaultScriptingLanguage&quot; value=&quot;myLanguage&quot;/&gt;
&lt;/settings&gt;
</code></pre>
<p>或者，你也可以使用 <code>lang</code> 属性为特定的语句指定语言：</p>
<pre><code>&lt;select id=&quot;selectBlog&quot; lang=&quot;myLanguage&quot;&gt;
  SELECT * FROM BLOG
&lt;/select&gt;
</code></pre>
<p>或者，在你的 mapper 接口上添加 <code>@Lang</code> 注解：</p>
<pre><code>public interface Mapper {
  @Lang(MyLanguageDriver.class)
  @Select(&quot;SELECT * FROM BLOG&quot;)
  List&lt;Blog&gt; selectBlog();
}
</code></pre>
<p><strong>提示</strong> 可以使用 Apache Velocity 作为动态语言，更多细节请参考 MyBatis-Velocity 项目。</p>
<p>你前面看到的所有 xml 标签都由默认 MyBatis 语言提供，而它由语言驱动 <code>org.apache.ibatis.scripting.xmltags.XmlLanguageDriver</code>（别名为 <code>xml</code>）所提供。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Leetcode sql题个人题解方案]]></title>
        <id>https://chenm0.github.io/post/leetcode-sql/</id>
        <link href="https://chenm0.github.io/post/leetcode-sql/">
        </link>
        <updated>2021-08-26T00:03:11.000Z</updated>
        <content type="html"><![CDATA[<h2 id="1-组合两个表">1. 组合两个表</h2>
<p>表1: Person</p>
<pre><code>+-------------+---------+

| 列名         | 类型     |

+-------------+---------+

| PersonId    | int     |

| FirstName   | varchar |

| LastName    | varchar |

+-------------+---------+

PersonId 是上表主键
</code></pre>
<p>表2: <code>Address</code></p>
<pre><code>+-------------+---------+
| 列名         | 类型    |
+-------------+---------+
| AddressId   | int     |
| PersonId    | int     |
| City        | varchar |
| State       | varchar |
+-------------+---------+
AddressId 是上表主键
</code></pre>
<p>编写一个 SQL 查询，满足条件：无论 person 是否有地址信息，都需要基于上述两表提供 person 的以下信息：</p>
<pre><code>FirstName, LastName, City, State
</code></pre>
<h3 id="解答">解答</h3>
<h5 id="思路">思路:</h5>
<p>根据题目要求得知,需要查询的为Person表的FirstName,LastName和Address表的City,State字段,以Person表为主表,Address表的PersonId为外键进行查询,可保证无论Address表中是否有关联的值,Person表都能展示其信息。</p>
<h5 id="答案">答案：</h5>
<p>SELECT p.FirstName,p.LastName,a.City,a.State FROM Person p left join Address a  on  p.PersonId = a.PersonId</p>
<h5 id="重点"><strong>重点：</strong></h5>
<p>连表查询中，主表的内容都会被展示</p>
<h2 id="2第二高的薪水">2.第二高的薪水</h2>
<p>编写一个 SQL 查询，获取 <code>Employee</code> 表中第二高的薪水（Salary） 。</p>
<pre><code>+----+--------+
| Id | Salary |
+----+--------+
| 1  | 100    |
| 2  | 200    |
| 3  | 300    |
+----+--------+
</code></pre>
<p>例如上述 <code>Employee</code> 表，SQL查询应该返回 <code>200</code> 作为第二高的薪水。如果不存在第二高的薪水，那么查询应返回 <code>null</code>。</p>
<pre><code>+---------------------+
| SecondHighestSalary |
+---------------------+
| 200                 |
+---------------------+
</code></pre>
<h3 id="解答-2">解答</h3>
<h5 id="思路-2">思路：</h5>
<p>审题发现几个本题重要的考点：</p>
<p>1.获取第二高的薪水，需要掌握orderby和limit的使用，‘第二高’ 是降序的排序方式，所以需要使用order by  。。 desc。</p>
<pre><code> 			limit y 分句表示: 读取 y 条数据
	  	limit x, y 分句表示: 跳过 x 条数据，读取 y 条数据
      limit y offset x 分句表示: 跳过 x 条数据，读取 y 条数据
      limit n 等价于 limit 0,n
</code></pre>
<p>2.其次需要考虑特殊情况，首先需要去重同样的salary，其次就是如果不存在第二高的薪水，结果应为null，可以有两种解决方式：一种是用临时表，还有一种就是使用IFNULL函数。</p>
<h5 id="答案-2">答案：</h5>
<p>select IFNULL((select distinct Salary from Employee order by Salary desc limit 1,1),null) as SecondHighestSalary;</p>
<h5 id="重点-2"><strong>重点</strong>：</h5>
<p>1.limit的使用</p>
<pre><code>	  	limit y 分句表示: 读取 y 条数据
	  	limit x, y 分句表示: 跳过 x 条数据，读取 y 条数据
      limit y offset x 分句表示: 跳过 x 条数据，读取 y 条数据
      limit n 等价于 limit 0,n
</code></pre>
<p>2.IFNULL和临时表判空的方式</p>
<h2 id="3第n高的薪水">3.第N高的薪水</h2>
<p>编写一个 SQL 查询，获取 <code>Employee</code> 表中第 <em>n</em> 高的薪水（Salary）。</p>
<pre><code>+----+--------+
| Id | Salary |
+----+--------+
| 1  | 100    |
| 2  | 200    |
| 3  | 300    |
+----+--------+
</code></pre>
<p>例如上述 <code>Employee</code> 表，<em>n = 2</em> 时，应返回第二高的薪水 <code>200</code>。如果不存在第 <em>n</em> 高的薪水，那么查询应返回 <code>null</code>。</p>
<pre><code>+------------------------+
| getNthHighestSalary(2) |
+------------------------+
| 200                    |
+------------------------+
</code></pre>
<h3 id="解答-3"><strong>解答</strong></h3>
<h5 id="思路-3"><strong>思路:</strong></h5>
<p>首先对存储过程的语法进行了基本的了解，题目的要求和上一题基本相同，但需要查的位置变成了变量，所以需要在limit后用变量选择跳过的个数</p>
<h5 id="答案-3"><strong>答案：</strong></h5>
<pre><code>CREATE FUNCTION getNthHighestSalary(N INT) RETURNS INT

BEGIN

  set N = N - 1;

  RETURN (

​      \# Write your MySQL query statement below.

​      SELECT IFNULl((SELECT distinct Salary from Employee order by Salary desc limit N,1),null)

  );

END
</code></pre>
<h5 id="重点-3"><strong>重点：</strong></h5>
<p>1.存储结构的基础语法</p>
<pre><code>create procedure sp_name()
begin
.........
end
</code></pre>
<p>2.limit后不能进行运算，所以应该在begin前就将需要跳过的数算好，这里需要跳过的数应为需要查到的位数-1</p>
<h2 id="4分数排名">4.分数排名</h2>
<p>编写一个 SQL 查询来实现分数排名。</p>
<p>如果两个分数相同，则两个分数排名（Rank）相同。请注意，平分后的下一个名次应该是下一个连续的整数值。换句话说，名次之间不应该有“间隔”。</p>
<pre><code>+----+-------+
| Id | Score |
+----+-------+
| 1  | 3.50  |
| 2  | 3.65  |
| 3  | 4.00  |
| 4  | 3.85  |
| 5  | 4.00  |
| 6  | 3.65  |
+----+-------+
</code></pre>
<p>例如，根据上述给定的 <code>Scores</code> 表，你的查询应该返回（按分数从高到低排列）：</p>
<pre><code>+-------+------+
| Score | Rank |
+-------+------+
| 4.00  | 1    |
| 4.00  | 1    |
| 3.85  | 2    |
| 3.65  | 3    |
| 3.65  | 3    |
| 3.50  | 4    |
+-------+------+
</code></pre>
<h3 id="解答-4"><strong>解答</strong></h3>
<h5 id="思路-4"><strong>思路:</strong></h5>
<p>回答此题的前提是需要了解sql的四大排名函数，审题得知，我们需要根据分数的大小降序排列后，对分数进行排名且名次之间无间隔，所以在四大排名函数中应选择<strong>DENSE_RANK()</strong>。</p>
<h5 id="答案-4"><strong>答案:</strong></h5>
<p>select Score,DENSE_RANK() over (order by Score DESC) 'Rank' from Scores;</p>
<h5 id="重点-4"><strong>重点:</strong></h5>
<p>1.sql的四大排名函数：</p>
<ul>
<li>​    ROW_NUMBER()      ----- 每条数据加一个序号，不适合排名，更加适合分页功能</li>
<li>​    RANK()              ---- 排名序号可重复，之后按总数算</li>
<li>​    DENSE_RANK()        ---- 排名序号可重复，之后按序号的后一个继续</li>
<li>​    NTILE()       ----将有序分区中的行分发到指定数目的组中，各个组有编号，分为几个区，一个区会有多少个。<br>
​    所以，按照题目要求，应采取DENSE_RANK()无间隔的排名函数<br>
2.对于 MySQL 解决方案，如果要转义用作列名的保留字，可以在关键字之前和之后使用撇号。例如 <code>Rank</code></li>
</ul>
<h2 id="5连续出现的数字">5.连续出现的数字</h2>
<p>表：<code>Logs</code></p>
<pre><code>+-------------+---------+
| Column Name | Type    |
+-------------+---------+
| id          | int     |
| num         | varchar |
+-------------+---------+
id 是这个表的主键。
</code></pre>
<p>编写一个 SQL 查询，查找所有至少连续出现三次的数字。</p>
<p>返回的结果表中的数据可以按 <strong>任意顺序</strong> 排列。</p>
<p>查询结果格式如下面的例子所示：</p>
<pre><code>Logs 表：
+----+-----+
| Id | Num |
+----+-----+
| 1  | 1   |
| 2  | 1   |
| 3  | 1   |
| 4  | 2   |
| 5  | 1   |
| 6  | 2   |
| 7  | 2   |
+----+-----+

Result 表：
+-----------------+
| ConsecutiveNums |
+-----------------+
| 1               |
+-----------------+
1 是唯一连续出现至少三次的数字。


</code></pre>
<h3 id="解答-5"><strong>解答</strong></h3>
<h5 id="思路-5"><strong>思路:</strong></h5>
<p>本题根据题目要求，需查询出连续出现至少三次的同一个数字，所以distinct函数是一定需要使用的；三次同一个数字的id分别为id，id+1，id+2，而num是相同的，所以需要两个子查询作为筛选条件</p>
<h5 id="答案-5"><strong>答案:</strong></h5>
<pre><code>select distinct Num as ConsecutiveNums from Logs where (Id+1,Num) in (select * from Logs) and (Id+2,Num) in (select * from Logs)
</code></pre>
<h5 id="重点-5"><strong>重点:</strong></h5>
<p>活用子查询</p>
<h2 id="6超过经理收入的员工">6.超过经理收入的员工</h2>
<p><code>Employee</code> 表包含所有员工，他们的经理也属于员工。每个员工都有一个 Id，此外还有一列对应员工的经理的 Id。</p>
<pre><code>+----+-------+--------+-----------+
| Id | Name  | Salary | ManagerId |
+----+-------+--------+-----------+
| 1  | Joe   | 70000  | 3         |
| 2  | Henry | 80000  | 4         |
| 3  | Sam   | 60000  | NULL      |
| 4  | Max   | 90000  | NULL      |
+----+-------+--------+-----------+
</code></pre>
<p>给定 <code>Employee</code> 表，编写一个 SQL 查询，该查询可以获取收入超过他们经理的员工的姓名。在上面的表格中，Joe 是唯一一个收入超过他的经理的员工。</p>
<pre><code>+----------+
| Employee |
+----------+
| Joe      |
+----------+
</code></pre>
<h3 id="解答-6"><strong>解答</strong></h3>
<h5 id="思路-6"><strong>思路:</strong></h5>
<p>本题需要使用子链接或自链接</p>
<h5 id="答案-6"><strong>答案：</strong></h5>
<p>子链接：</p>
<pre><code>select a.Name as Employee from Employee a where a.Salary &gt; 

(select b.Salary from Employee b where b.Id = a.ManagerId) 
</code></pre>
<p>自链接：</p>
<pre><code>select a.Name as Employee from Employee a join Employee b where b.id = a.ManagerId and b.Salary &lt; a.Salary
</code></pre>
<h5 id="重点-6"><strong>重点：</strong></h5>
<p>加强自链接和子链接的使用</p>
<h2 id="7查找重复的电子邮箱">7.查找重复的电子邮箱</h2>
<p>编写一个 SQL 查询，查找 <code>Person</code> 表中所有重复的电子邮箱。</p>
<p><strong>示例：</strong></p>
<pre><code>+----+---------+
| Id | Email   |
+----+---------+
| 1  | a@b.com |
| 2  | c@d.com |
| 3  | a@b.com |
+----+---------+
</code></pre>
<p>根据以上输入，你的查询应返回以下结果：</p>
<pre><code>+---------+
| Email   |
+---------+
| a@b.com |
+---------+
</code></pre>
<p>**说明：**所有电子邮箱都是小写字母。</p>
<h3 id="解答-7"><strong>解答</strong></h3>
<h5 id="思路-7"><strong>思路:</strong></h5>
<p>需要使用group by将结果集归类，然后使用count函数判断是否重复</p>
<h5 id="答案-7"><strong>答案:</strong></h5>
<pre><code>select Email from Person group by Email having count(Email) &gt; 1
</code></pre>
<h5 id="重点-7"><strong>重点:</strong></h5>
<p>group by...having和计数函数的使用</p>
<h2 id="8从不订购的客户">8.从不订购的客户</h2>
<p>某网站包含两个表，Customers 表和 Orders 表。编写一个 SQL 查询，找出所有从不订购任何东西的客户。</p>
<p><code>Customers</code> 表：</p>
<pre><code>+----+-------+
| Id | Name  |
+----+-------+
| 1  | Joe   |
| 2  | Henry |
| 3  | Sam   |
| 4  | Max   |
+----+-------+
</code></pre>
<p><code>Orders</code> 表：</p>
<pre><code>+----+------------+
| Id | CustomerId |
+----+------------+
| 1  | 3          |
| 2  | 1          |
+----+------------+
</code></pre>
<p>例如给定上述表格，你的查询应返回：</p>
<pre><code>+-----------+
| Customers |
+-----------+
| Henry     |
| Max       |
+-----------+
</code></pre>
<h3 id="解答-8"><strong>解答</strong></h3>
<h5 id="思路-8"><strong>思路:</strong></h5>
<p>首先需要连表进行查询，然后需要使用子查询筛选结果</p>
<h5 id="答案-8"><strong>答案:</strong></h5>
<pre><code>select c.Name as Customers from Orders o right join Customers c on c.id = o.CustomerId where c.Id not in (select CustomerId from Orders)
</code></pre>
<h5 id="重点-8"><strong>重点:</strong></h5>
<p>注意关联查询配合子查询</p>
<h2 id="9部门工资最高的员工">9.部门工资最高的员工</h2>
<p><code>Employee</code> 表包含所有员工信息，每个员工有其对应的 Id, salary 和 department Id。</p>
<pre><code>+----+-------+--------+--------------+
| Id | Name  | Salary | DepartmentId |
+----+-------+--------+--------------+
| 1  | Joe   | 70000  | 1            |
| 2  | Jim   | 90000  | 1            |
| 3  | Henry | 80000  | 2            |
| 4  | Sam   | 60000  | 2            |
| 5  | Max   | 90000  | 1            |
+----+-------+--------+--------------+
</code></pre>
<p><code>Department</code> 表包含公司所有部门的信息。</p>
<pre><code>+----+----------+
| Id | Name     |
+----+----------+
| 1  | IT       |
| 2  | Sales    |
+----+----------+

</code></pre>
<p>编写一个 SQL 查询，找出每个部门工资最高的员工。对于上述表，您的 SQL 查询应返回以下行（行的顺序无关紧要）。</p>
<pre><code>+------------+----------+--------+
| Department | Employee | Salary |
+------------+----------+--------+
| IT         | Max      | 90000  |
| IT         | Jim      | 90000  |
| Sales      | Henry    | 80000  |
+------------+----------+--------+
</code></pre>
<p><strong>解释：</strong></p>
<p>Max 和 Jim 在 IT 部门的工资都是最高的，Henry 在销售部的工资最高。</p>
<h3 id="解答-9"><strong>解答</strong></h3>
<h5 id="思路-9"><strong>思路:</strong></h5>
<p>需要应用子查询构建一个临时表，临时表中使用分区和**DENSE_RANK()**函数（因为有并列的情况）进行排序，然后在外层根据排序的序号查询排名第一的结果</p>
<h5 id="答案-9"><strong>答案:</strong></h5>
<pre><code>SELECT s.Department,s.Employee,s.Salary from 
(SELECT
    d.Name as Department,e.Name as Employee,e.Salary as Salary, DENSE_RANK() over (Partition by DepartmentID order by Salary DESC) as rn
    FROM
        Employee e join Department d on e.DepartmentID = d.Id) s
where s.rn = 1
</code></pre>
<h5 id="重点-9"><strong>重点:</strong></h5>
<p>1.Partition by 和 group by的区别<br>
1. group by是分组函数，partition by是分析函数（然后像sum()等是聚合函数）；<br>
2. 在执行顺序上，<br>
以下是常用sql关键字的优先级<br>
<mark>from &gt; where &gt; group by &gt; having &gt; order by</mark><br>
而partition by应用在以上关键字之后，实际上就是在执行完select之后，在所得结果集之上进行partition。<br>
3. partition by相比较于group by，能够在保留全部数据的基础上，只对其中某些字段做分组排序（类似excel中的操作），而group by则只保留参与分组的字段和聚合函数的结果（类似excel中的pivot）<br>
4. 如果在partition结果上聚合，千万注意聚合函数是逐条累计运行结果的！而在group by后的结果集上使用聚合函数，会作用在分组下的所有记录上。<br>
2.活用自查询</p>
<h2 id="10部门工资前三高的所有员工">10.部门工资前三高的所有员工</h2>
<p><code>Employee</code> 表包含所有员工信息，每个员工有其对应的工号 <code>Id</code>，姓名 <code>Name</code>，工资 <code>Salary</code> 和部门编号 <code>DepartmentId</code> 。</p>
<pre><code>+----+-------+--------+--------------+
| Id | Name  | Salary | DepartmentId |
+----+-------+--------+--------------+
| 1  | Joe   | 85000  | 1            |
| 2  | Henry | 80000  | 2            |
| 3  | Sam   | 60000  | 2            |
| 4  | Max   | 90000  | 1            |
| 5  | Janet | 69000  | 1            |
| 6  | Randy | 85000  | 1            |
| 7  | Will  | 70000  | 1            |
+----+-------+--------+--------------+
</code></pre>
<p><code>Department</code> 表包含公司所有部门的信息。</p>
<pre><code>+----+----------+
| Id | Name     |
+----+----------+
| 1  | IT       |
| 2  | Sales    |
+----+----------+
</code></pre>
<p>编写一个 SQL 查询，找出每个部门获得前三高工资的所有员工。例如，根据上述给定的表，查询结果应返回：</p>
<pre><code>+------------+----------+--------+
| Department | Employee | Salary |
+------------+----------+--------+
| IT         | Max      | 90000  |
| IT         | Randy    | 85000  |
| IT         | Joe      | 85000  |
| IT         | Will     | 70000  |
| Sales      | Henry    | 80000  |
| Sales      | Sam      | 60000  |
+------------+----------+--------+
</code></pre>
<p><strong>解释：</strong></p>
<p>IT 部门中，Max 获得了最高的工资，Randy 和 Joe 都拿到了第二高的工资，Will 的工资排第三。销售部门（Sales）只有两名员工，Henry 的工资最高，Sam 的工资排第二。</p>
<h3 id="解答-10"><strong>解答</strong></h3>
<h5 id="思路-10"><strong>思路:</strong></h5>
<p>根据上题的一道扩展问题，可延续上题思路，更改排序的筛选条件</p>
<h5 id="答案-10"><strong>答案:</strong></h5>
<pre><code>SELECT s.Department,s.Employee,S.Salary from 

(SELECT

​    d.Name as Department,e.Name as Employee,e.Salary as Salary, e.DepartmentId as did,DENSE_RANK() over (Partition by DepartmentID order by Salary DESC) as rn

​    FROM

​        Employee e join Department d on e.DepartmentID = d.Id) s

where s.rn &lt;= 3 order by s.did asc,S.Salary DESC
</code></pre>
<h5 id="重点-10"><strong>重点:</strong></h5>
<p>主要思路延续上一题</p>
<h2 id="11-删除重复的电子邮箱">11. 删除重复的电子邮箱</h2>
<p>编写一个 SQL 查询，来删除 Person 表中所有重复的电子邮箱，重复的邮箱里只保留 Id 最小 的那个。</p>
<pre><code>+----+------------------+
| Id | Email            |
+----+------------------+
| 1  | john@example.com |
| 2  | bob@example.com  |
| 3  | john@example.com |
+----+------------------+
Id 是这个表的主键。
</code></pre>
<p>例如，在运行你的查询语句之后，上面的 Person 表应返回以下几行:</p>
<pre><code>+----+------------------+
| Id | Email            |
+----+------------------+
| 1  | john@example.com |
| 2  | bob@example.com  |
+----+------------------+
</code></pre>
<p>提示：</p>
<ul>
<li>执行 SQL 之后，输出是整个 Person 表。</li>
<li>使用 delete 语句。</li>
</ul>
<h3 id="解答-11"><strong>解答</strong></h3>
<h5 id="思路-11"><strong>思路:</strong></h5>
<p>使用自链接筛选比较结果进行删除</p>
<h5 id="答案-11"><strong>答案:</strong></h5>
<pre><code>delete p1 from Person p1 join Person p2 on p1.Email = p2.Email where p1.Id &gt; p2.Id
</code></pre>
<h5 id="重点-11"><strong>重点:</strong></h5>
<p>活用自链接</p>
<h2 id="12上升的温度">12.上升的温度</h2>
<p>表 Weather</p>
<pre><code>+---------------+---------+
| Column Name   | Type    |
+---------------+---------+
| id            | int     |
| recordDate    | date    |
| temperature   | int     |
+---------------+---------+
id 是这个表的主键
该表包含特定日期的温度信息
</code></pre>
<p>编写一个 SQL 查询，来查找与之前（昨天的）日期相比温度更高的所有日期的 id 。<br>
返回结果 不要求顺序 。<br>
查询结果格式如下例：</p>
<pre><code>Weather
+----+------------+-------------+
| id | recordDate | Temperature |
+----+------------+-------------+
| 1  | 2015-01-01 | 10          |
| 2  | 2015-01-02 | 25          |
| 3  | 2015-01-03 | 20          |
| 4  | 2015-01-04 | 30          |
+----+------------+-------------+

Result table:
+----+
| id |
+----+
| 2  |
| 4  |
+----+
2015-01-02 的温度比前一天高（10 -&gt; 25）
2015-01-04 的温度比前一天高（20 -&gt; 30）
</code></pre>
<h3 id="解答-12"><strong>解答</strong></h3>
<h5 id="思路-12"><strong>思路:</strong></h5>
<p>这里需要使用datediff函数来判断前一天，== datediff(日期1, 日期2)： 得到的结果是日期1与日期2相差的天数。 如果日期1比日期2大，结果为正；如果日期1比日期2小，结果为负。==</p>
<h5 id="答案-12"><strong>答案:</strong></h5>
<pre><code>select w1.id from Weather w1,Weather w2 where w1.Temperature &gt; w2.Temperature and datediff(w1.recordDate,w2.recordDate) = 1
</code></pre>
<h5 id="重点-12"><strong>重点:</strong></h5>
<p>== datediff(日期1, 日期2)： 得到的结果是日期1与日期2相差的天数。 如果日期1比日期2大，结果为正；如果日期1比日期2小，结果为负。==</p>
<h2 id="13大的国家">13.大的国家</h2>
<p>这里有张 World 表</p>
<pre><code>+-----------------+------------+------------+--------------+---------------+
| name            | continent  | area       | population   | gdp           |
+-----------------+------------+------------+--------------+---------------+
| Afghanistan     | Asia       | 652230     | 25500100     | 20343000      |
| Albania         | Europe     | 28748      | 2831741      | 12960000      |
| Algeria         | Africa     | 2381741    | 37100000     | 188681000     |
| Andorra         | Europe     | 468        | 78115        | 3712000       |
| Angola          | Africa     | 1246700    | 20609294     | 100990000     |
+-----------------+------------+------------+--------------+---------------+
</code></pre>
<p>如果一个国家的面积超过 300 万平方公里，或者人口超过 2500 万，那么这个国家就是大国家。<br>
编写一个 SQL 查询，输出表中所有大国家的名称、人口和面积。<br>
例如，根据上表，我们应该输出:</p>
<pre><code>+--------------+-------------+--------------+
| name         | population  | area         |
+--------------+-------------+--------------+
| Afghanistan  | 25500100    | 652230       |
| Algeria      | 37100000    | 2381741      |
+--------------+-------------+--------------+
</code></pre>
<h3 id="解答-13"><strong>解答</strong></h3>
<h5 id="思路-13"><strong>思路:</strong></h5>
<p>此题比较简单，使用or进行筛选即可</p>
<h5 id="答案-13"><strong>答案:</strong></h5>
<pre><code>select name,population,area from World where area &gt; 3000000 or population &gt; 25000000
</code></pre>
<h5 id="重点-13"><strong>重点:</strong></h5>
<p>or的使用方式</p>
<h2 id="14-超过5名学生的课">14. 超过5名学生的课</h2>
<p>有一个courses 表 ，有: student (学生) 和 class (课程)。<br>
请列出所有超过或等于5名学生的课。<br>
例如，表：</p>
<pre><code>+---------+------------+
| student | class      |
+---------+------------+
| A       | Math       |
| B       | English    |
| C       | Math       |
| D       | Biology    |
| E       | Math       |
| F       | Computer   |
| G       | Math       |
| H       | Math       |
| I       | Math       |
+---------+------------+
</code></pre>
<p>应该输出:</p>
<pre><code>+---------+
| class   |
+---------+
| Math    |
+---------+
</code></pre>
<p>提示：</p>
<ul>
<li>学生在每个课中不应被重复计算。</li>
</ul>
<h3 id="解答-14"><strong>解答</strong></h3>
<h5 id="思路-14"><strong>思路:</strong></h5>
<p>可使用子查询进行分组之后利用count筛选结果</p>
<h5 id="答案-14"><strong>答案:</strong></h5>
<pre><code>select c.class from (select distinct * from courses) c group by c.class having count(c.class) &gt;=5 
</code></pre>
<h5 id="重点-14"><strong>重点:</strong></h5>
<p>注意提示，需要进行去重操作</p>
<h2 id="15-有趣的电影">15. 有趣的电影</h2>
<p>某城市开了一家新的电影院，吸引了很多人过来看电影。该电影院特别注意用户体验，专门有个 LED显示板做电影推荐，上面公布着影评和相关电影描述。<br>
作为该电影院的信息部主管，您需要编写一个 SQL查询，找出所有影片描述为非 boring (不无聊) 的并且 id 为奇数 的影片，结果请按等级 rating 排列。<br>
例如，下表 cinema:</p>
<pre><code>+---------+-----------+--------------+-----------+
|   id    | movie     |  description |  rating   |
+---------+-----------+--------------+-----------+
|   1     | War       |   great 3D   |   8.9     |
|   2     | Science   |   fiction    |   8.5     |
|   3     | irish     |   boring     |   6.2     |
|   4     | Ice song  |   Fantacy    |   8.6     |
|   5     | House card|   Interesting|   9.1     |
+---------+-----------+--------------+-----------+
</code></pre>
<p>对于上面的例子，则正确的输出是为：</p>
<pre><code>+---------+-----------+--------------+-----------+
|   id    | movie     |  description |  rating   |
+---------+-----------+--------------+-----------+
|   5     | House card|   Interesting|   9.1     |
|   1     | War       |   great 3D   |   8.9     |
+---------+-----------+--------------+-----------+
</code></pre>
<h3 id="解答-15"><strong>解答</strong></h3>
<h5 id="思路-15"><strong>思路:</strong></h5>
<p>奇数可以用取余不等于0的方式计算，“&lt;&gt;”代表的是不等于</p>
<h5 id="答案-15"><strong>答案:</strong></h5>
<pre><code>select id,movie,description,rating from cinema where id % 2 &lt;&gt; 0 and description &lt;&gt; 'boring' order by rating desc
</code></pre>
<h5 id="重点-15"><strong>重点:</strong></h5>
<p>奇数的算法和不等于符号</p>
<h2 id="16-换座位">16. 换座位</h2>
<p>小美是一所中学的信息科技老师，她有一张 seat 座位表，平时用来储存学生名字和与他们相对应的座位 id。<br>
其中纵列的 id 是连续递增的<br>
小美想改变相邻俩学生的座位。<br>
你能不能帮她写一个 SQL query 来输出小美想要的结果呢？<br>
示例：</p>
<pre><code>+---------+---------+
|    id   | student |
+---------+---------+
|    1    | Abbot   |
|    2    | Doris   |
|    3    | Emerson |
|    4    | Green   |
|    5    | Jeames  |
+---------+---------+
</code></pre>
<p>假如数据输入的是上表，则输出结果如下：</p>
<pre><code>+---------+---------+
|    id   | student |
+---------+---------+
|    1    | Doris   |
|    2    | Abbot   |
|    3    | Green   |
|    4    | Emerson |
|    5    | Jeames  |
+---------+---------+
</code></pre>
<p>注意：<br>
如果学生人数是奇数，则不需要改变最后一个同学的座位。</p>
<h3 id="解答-16"><strong>解答</strong></h3>
<h5 id="思路-16"><strong>思路:</strong></h5>
<p>此题涉及到异或运算符的使用，需要对异或运算符有所了解</p>
<h5 id="答案-16"><strong>答案:</strong></h5>
<pre><code>select rank() over (order by ((id-1)^1)) as id,student from seat
</code></pre>
<h5 id="重点-16"><strong>重点:</strong></h5>
<p>^(位异或)的使用方式：<br>
上下运算,按照与的运算规则：0&amp;0=0 ；0&amp;1=1；1&amp;1=0</p>
<h2 id="17-变更性别">17. 变更性别</h2>
<p>给定一个 salary 表，如下所示，有 m = 男性 和 f = 女性 的值。交换所有的 f 和 m 值（例如，将所有 f 值更改为 m，反之亦然）。要求只使用一个更新（Update）语句，并且没有中间的临时表。</p>
<p>注意，您必只能写一个 Update 语句，请不要编写任何 Select 语句。<br>
例如：</p>
<pre><code>| id | name | sex | salary |
|----|------|-----|--------|
| 1  | A    | m   | 2500   |
| 2  | B    | f   | 1500   |
| 3  | C    | m   | 5500   |
| 4  | D    | f   | 500    |
</code></pre>
<p>运行你所编写的更新语句之后，将会得到以下表:</p>
<pre><code>| id | name | sex | salary |
|----|------|-----|--------|
| 1  | A    | f   | 2500   |
| 2  | B    | m   | 1500   |
| 3  | C    | f   | 5500   |
| 4  | D    | m   | 500    |
</code></pre>
<h3 id="解答-17"><strong>解答</strong></h3>
<h5 id="思路-17"><strong>思路:</strong></h5>
<p>此题涉及到sql语句中的if用法</p>
<h5 id="答案-17"><strong>答案:</strong></h5>
<pre><code>update salary set sex = if(sex = 'f','m','f')
</code></pre>
<h5 id="重点-17"><strong>重点:</strong></h5>
<p>在sql的update语句中，if语句类似于三目运算符的作用</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Maven setting]]></title>
        <id>https://chenm0.github.io/post/maven-setting/</id>
        <link href="https://chenm0.github.io/post/maven-setting/">
        </link>
        <updated>2021-08-09T01:16:36.000Z</updated>
        <content type="html"><![CDATA[<?xml version="1.0" encoding="UTF-8"?> 
<p><settings xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
 xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd"></p>
 <!--本地仓库。该值表示构建系统本地仓库的路径。其默认值为~/.m2/repository。 --> 
<p><localRepository>usr/local/maven</localRepository></p>
 <!--Maven是否需要和用户交互以获得输入。如果Maven需要和用户交互以获得输入，则设置成true，反之则应为false。默认为true。--> 
<p><interactiveMode>true</interactiveMode></p>
 <!--Maven是否需要使用plugin-registry.xml文件来管理插件版本。如果需要让Maven使用文件~/.m2/plugin-registry.xml来管理插件版本，则设为true。默认为false。--> 
<p><usePluginRegistry>false</usePluginRegistry></p>
 <!--表示Maven是否需要在离线模式下运行。如果构建系统需要在离线模式下运行，则为true，默认为false。当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，该配置就十分有用。 --> 
<p><offline>false</offline></p>
 <!--当插件的组织Id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。默认情况下该列表包含了org.apache.maven.plugins。 --> 
 <pluginGroups> 
 <!--plugin的组织Id（groupId） --> 
 <pluginGroup>org.codehaus.mojo</pluginGroup> 
 </pluginGroups> 
 <!--用来配置不同的代理，多代理profiles 可以应对笔记本或移动设备的工作环境：通过简单的设置profile id就可以很容易的更换整个代理配置。 --> 
 <proxies> 
 <!--代理元素包含配置代理时需要的信息--> 
 <proxy> 
 <!--代理的唯一定义符，用来区分不同的代理元素。--> 
 <id>myproxy</id> 
 <!--该代理是否是激活的那个。true则激活代理。当我们声明了一组代理，而某个时候只需要激活一个代理的时候，该元素就可以派上用处。 --> 
 <active>true</active> 
 <!--代理的协议。 协议://主机名:端口，分隔成离散的元素以方便配置。--> 
 <protocol>http</protocol> 
 <!--代理的主机名。协议://主机名:端口，分隔成离散的元素以方便配置。 --> 
 <host>proxy.somewhere.com</host> 
 <!--代理的端口。协议://主机名:端口，分隔成离散的元素以方便配置。 --> 
 <port>8080</port> 
 <!--代理的用户名，用户名和密码表示代理服务器认证的登录名和密码。 --> 
 <username>proxyuser</username> 
 <!--代理的密码，用户名和密码表示代理服务器认证的登录名和密码。 --> 
 <password>somepassword</password> 
 <!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定；例子中使用了竖线分隔符，使用逗号分隔也很常见。--> 
 <nonProxyHosts>*.google.com|ibiblio.org</nonProxyHosts> 
 </proxy> 
 </proxies> 
 <!--配置服务端的一些设置。一些设置如安全证书不应该和pom.xml一起分发。这种类型的信息应该存在于构建服务器上的settings.xml文件中。--> 
 <servers> 
 <!--服务器元素包含配置服务器时需要的信息 --> 
 <server> 
 <!--这是server的id（注意不是用户登陆的id），该id与distributionManagement中repository元素的id相匹配。--> 
 <id>server001</id> 
 <!--鉴权用户名。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --> 
 <username>my_login</username> 
 <!--鉴权密码 。鉴权用户名和鉴权密码表示服务器认证所需要的登录名和密码。 --> 
 <password>my_password</password> 
 <!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是/home/hudson/.ssh/id_dsa）以及如果需要的话，一个密语。将来passphrase和password元素可能会被提取到外部，但目前它们必须在settings.xml文件以纯文本的形式声明。 --> 
 <privateKey>${usr.home}/.ssh/id_dsa</privateKey> 
 <!--鉴权时使用的私钥密码。--> 
 <passphrase>some_passphrase</passphrase> 
 <!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --> 
 <filePermissions>664</filePermissions> 
 <!--目录被创建时的权限。 --> 
 <directoryPermissions>775</directoryPermissions> 
 <!--传输层额外的配置项 --> 
 <configuration></configuration> 
 </server> 
 </servers> 
 <!--为仓库列表配置的下载镜像列表。 --> 
 <mirrors> 
 <!--给定仓库的下载镜像。 --> 
 <mirror> 
 <!--该镜像的唯一标识符。id用来区分不同的mirror元素。 --> 
 <id>planetmirror.com</id> 
 <!--镜像名称 --> 
 <name>PlanetMirror Australia</name> 
 <!--该镜像的URL。构建系统会优先考虑使用该URL，而非使用默认的服务器URL。 --> 
 <url>http://downloads.planetmirror.com/pub/maven2</url> 
 <!--被镜像的服务器的id。例如，如果我们要设置了一个Maven中央仓库（http://repo1.maven.org/maven2）的镜像，就需要将该元素设置成central。这必须和中央仓库的id central完全一致。--> 
 <mirrorOf>central</mirrorOf> 
 </mirror> 
 </mirrors> 
 <!--根据环境参数来调整构建配置的列表。settings.xml中的profile元素是pom.xml中profile元素的裁剪版本。它包含了id，activation, repositories, pluginRepositories和 properties元素。这里的profile元素只包含这五个子元素是因为这里只关心构建系统这个整体（这正是settings.xml文件的角色定位），而非单独的项目对象模型设置。如果一个settings中的profile被激活，它的值会覆盖任何其它定义在POM中或者profile.xml中的带有相同id的profile。 --> 
 <profiles> 
 <!--根据环境参数来调整的构件的配置--> 
 <profile> 
 <!--该配置的唯一标识符。 --> 
 <id>test</id> 
 <!--自动触发profile的条件逻辑。Activation是profile的开启钥匙。如POM中的profile一样，profile的力量来自于它能够在某些特定的环境中自动使用某些特定的值；这些环境通过activation元素指定。activation元素并不是激活profile的唯一方式。settings.xml文件中的activeProfile元素可以包含profile的id。profile也可以通过在命令行，使用-P标记和逗号分隔的列表来显式的激活（如，-P test）。--> 
 <activation> 
 <!--profile默认是否激活的标识--> 
 <activeByDefault>false</activeByDefault> 
 <!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--> 
 <jdk>1.5</jdk> 
 <!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--> 
 <os> 
 <!--激活profile的操作系统的名字 --> 
 <name>Windows XP</name> 
 <!--激活profile的操作系统所属家族(如 'windows') --> 
 <family>Windows</family> 
 <!--激活profile的操作系统体系结构 --> 
 <arch>x86</arch> 
 <!--激活profile的操作系统版本--> 
 <version>5.1.2600</version> 
 </os> 
 <!--如果Maven检测到某一个属性（其值可以在POM中通过${名称}引用），其拥有对应的名称和值，Profile就会被激活。如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--> 
 <property> 
 <!--激活profile的属性的名称--> 
 <name>mavenVersion</name> 
 <!--激活profile的属性的值 --> 
 <value>2.0.3</value> 
 </property> 
 <!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--> 
 <file> 
 <!--如果指定的文件存在，则激活profile。 --> 
 <exists>/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/</exists> 
 <!--如果指定的文件不存在，则激活profile。--> 
 <missing>/usr/local/hudson/hudson-home/jobs/maven-guide-zh-to-production/workspace/</missing> 
 </file> 
 </activation> 
 <!--对应profile的扩展属性列表。Maven属性和Ant中的属性一样，可以用来存放一些值。这些值可以在POM中的任何地方使用标记${X}来使用，这里X是指属性的名称。属性有五种不同的形式，并且都能在settings.xml文件中访问。 
 1. env.X: 在一个变量前加上"env."的前缀，会返回一个shell环境变量。例如,"env.PATH"指代了$path环境变量（在Windows上是%PATH%）。 
 2. project.x：指代了POM中对应的元素值。 
 3. settings.x: 指代了settings.xml中对应元素的值。 
 4. Java System Properties: 所有可通过java.lang.System.getProperties()访问的属性都能在POM中使用该形式访问， 
 如/usr/lib/jvm/java-1.6.0-openjdk-1.6.0.0/jre。 
 5. x: 在<properties/>元素中，或者外部文件中设置，以${someVar}的形式使用。 --> 
 <properties> 
 <user.install>/ebs1/build-machine/usr/local/hudson/hudson-home/jobs/maven-guide-</user.install> 
 </properties> 
 <!--远程仓库列表，它是Maven用来填充构建系统本地仓库所使用的一组远程项目。 --> 
 <repositories> 
 <!--包含需要连接到远程仓库的信息 --> 
 <repository> 
 <!--远程仓库唯一标识--> 
 <id>codehausSnapshots</id> 
 <!--远程仓库名称 --> 
 <name>Codehaus Snapshots</name> 
 <!--如何处理远程仓库里发布版本的下载--> 
 <releases> 
 <!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。 --> 
 <enabled>false</enabled> 
 <!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --> 
 <updatePolicy>always</updatePolicy> 
 <!--当Maven验证构件校验文件失败时该怎么做-ignore（忽略），fail（失败），或者warn（警告）。--> 
 <checksumPolicy>warn</checksumPolicy> 
 </releases> 
 <!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素--> 
 <snapshots> 
 <enabled/><updatePolicy/><checksumPolicy/> 
 </snapshots> 
 <!--远程仓库URL，按protocol://hostname/path形式 --> 
 <url>http://snapshots.maven.codehaus.org/maven2</url> 
 <!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --> 
 <layout>default</layout> 
 </repository> 
 </repositories> 
 <!--发现插件的远程仓库列表。仓库是两种主要构件的家。第一种构件被用作其它构件的依赖。这是中央仓库中存储的大部分构件类型。另外一种构件类型是插件。Maven插件是一种特殊类型的构件。由于这个原因，插件仓库独立于其它仓库。pluginRepositories元素的结构和repositories元素的结构类似。每个pluginRepository元素指定一个Maven可以用来寻找新插件的远程地址。--> 
 <pluginRepositories> 
 <!--包含需要连接到远程插件仓库的信息.参见profiles/profile/repositories/repository元素的说明--> 
 <pluginRepository> 
 <releases> 
 <enabled/><updatePolicy/><checksumPolicy/> 
 </releases> 
 <snapshots> 
 <enabled/><updatePolicy/><checksumPolicy/> 
 </snapshots> 
 <id/><name/><url/><layout/> 
 </pluginRepository> 
 </pluginRepositories> 
 <!--手动激活profiles的列表，按照profile被应用的顺序定义activeProfile。 该元素包含了一组activeProfile元素，每个activeProfile都含有一个profile id。任何在activeProfile中定义的profile id，不论环境设置如何，其对应的 
 profile都会被激活。如果没有匹配的profile，则什么都不会发生。例如，env-test是一个activeProfile，则在pom.xml（或者profile.xml）中对应id的profile会被激活。如果运行过程中找不到这样一个profile，Maven则会像往常一样运行。 --> 
 <activeProfiles> 
 <!-- --> 
 <activeProfile>env-test</activeProfile> 
 </activeProfiles> 
 </profile> 
 </profiles> 
</settings> 
]]></content>
    </entry>
</feed>